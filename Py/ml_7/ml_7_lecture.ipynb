{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-7 Оптимизация гиперпараметров модели\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Базовая оптимизация](#2)\n",
    "- [3. Продвинутая оптимизация](#3)\n",
    "- [4. Практика](#4)\n",
    "- [5. Итоги](#5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение <a class=\"anchor\" id=1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Итак, как мы уже неоднократно упоминали ранее, в машинном обучении есть два типа параметров.\n",
    "\n",
    "**Внутренние** (параметры модели)\n",
    "\n",
    "Подбираются во время обучения и определяют, как использовать входные данные для получения необходимого результата.\n",
    "\n",
    "Например, это веса (коэффициенты уравнения) в линейной/логистической регрессии.\n",
    "\n",
    "**Внешние** (параметры алгоритма)\n",
    "\n",
    "Их принято называть `гиперпараметрами`. Внешние параметры могут быть произвольно установлены перед началом обучения и контролируют внутреннюю работу обучающего алгоритма.\n",
    "\n",
    "Например, это параметр регуляризации в линейной/логистической регрессии.\n",
    "\n",
    "`Гиперпараметры` отвечают за сложность взаимосвязи между входными признаками и целевой переменной, поэтому сильно влияют на модель и качество прогнозирования.\n",
    "\n",
    "Продемонстрируем это на примере задачи регрессии с помощью двух графиков работы алгоритма случайного леса, построенного на основе `5`, `100` деревьев (`n_estimators = [5, 100]`):\n",
    "\n",
    "<img src=ml7_img1.png>\n",
    "\n",
    "Видим, что при 100 деревьях модель находит более сложную закономерность в данных и точность соответственно будет выше, чем при 5.\n",
    "\n",
    "Каждый алгоритм МО имеет набор гиперпараметров, которые определяют, как именно он строит модель на обучающей выборке. Например, в модуле ML-2 для повышения эффективности модели мы уже рассматривали подбор параметра регуляризации `alpha` для алгоритма линейной регрессии `Ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20057/1676261705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mridge_lr_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Обучаем модель предсказывать логарифм целевого признака\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mridge_lr_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Делаем предсказание для каждой из выборок\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled_poly' is not defined"
     ]
    }
   ],
   "source": [
    "#Создаем список из 20 возможных значений от 0.001 до 10\n",
    "alpha_list = np.linspace(0.01, 10, 20)\n",
    "#Создаем пустые списки, в которые будем добавлять результаты \n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for alpha in alpha_list:\n",
    "    #Создаем объект класса линейная регрессия с L2-регуляризацией\n",
    "    ridge_lr_poly = linear_model.Ridge(alpha=alpha, max_iter=10000)\n",
    "    #Обучаем модель предсказывать логарифм целевого признака\n",
    "    ridge_lr_poly.fit(X_train_scaled_poly, y_train_log)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    #Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "    y_train_predict_poly = np.exp(ridge_lr_poly.predict(X_train_scaled_poly))\n",
    "    y_test_predict_poly = np.exp(ridge_lr_poly.predict(X_test_scaled_poly))\n",
    "    #Рассчитываем метрику для двух выборок и добавляем их в списки\n",
    "    train_scores.append(metrics.mean_absolute_error(y_train, y_train_predict_poly))\n",
    "    test_scores.append(metrics.mean_absolute_error(y_test, y_test_predict_poly))\n",
    " \n",
    "#Визуализируем изменение R^2 в зависимости от alpha\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость\n",
    "ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки\n",
    "ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки\n",
    "ax.set_xlabel('Alpha') #название оси абсцисс\n",
    "ax.set_ylabel('MAE') #название оси ординат\n",
    "ax.set_xticks(alpha_list) #метки по оси абцисс\n",
    "ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс\n",
    "ax.legend(); #отображение легенды"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml7_img2.png>\n",
    "\n",
    "Наилучшее значение метрики соответствует `alpha = 0.01` (кстати, можно попробовать перебрать значения `alpha < 0.01`).\n",
    "\n",
    "В данном случае мы просто воспользовались циклом for и перебрали некоторые заданные значения alpha, хотя, по всей видимости, не самые оптимальные. Поэтому подобранные эмпирическим путём значения гиперпараметров с большей вероятностью дадут низкую прогностическую эффективность.\n",
    "\n",
    "Также рассмотренный метод визуализации зависимости метрики от гиперпараметра позволяет выбрать только один внешний параметр, в данном случае — `alpha`. А что делать, если у нас не один, а несколько? \n",
    "\n",
    "Например, вспомним основные внешние параметры `DecisionTreeClassifier`:\n",
    "\n",
    "* `criterion` — критерий информативности. Может быть равен `'gini'` — критерий Джини — и `'entropy'` — энтропия Шеннона.\n",
    "* `max_depth` — максимальная глубина дерева. По умолчанию `None`, глубина дерева не ограничена.\n",
    "* `max_features` — максимальное число признаков, по которым ищется лучшее разбиение в дереве. По умолчанию `None`, то есть обучение производится на всех признаках.\n",
    "* `min_samples_leaf` — минимальное число объектов в листе. По умолчанию — `1`.\n",
    "\n",
    "Мы, конечно, можем сделать кучу вложенных циклов. Однако, поскольку поиск оптимальных значений гиперпараметров является общераспространенной задачей МО, библиотека `scikit`-`learn` и другие предлагают методы, позволяющие её решить.\n",
    "\n",
    "Тщательный подбор гиперпараметров гарантирует, что модель покажет максимально возможную точность на обучающих данных, **но это совершенно не означает хороший результат на тестовых или новых данных.**\n",
    "\n",
    "Поиск оптимальных значений гиперпараметров модели является сложной задачей, обязательной почти для всех моделей и наборов данных. Однако важно понимать смысл гиперпараметров перед их подбором."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Базовая оптимизация <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "В базовой оптимизации, предоставляемой библиотекой `sklearn`, есть два основных метода — `grid search` и `random search`. С ними мы сейчас и познакомимся. Оба используются при решении реальных задач, поэтому важно разобраться, как они устроены. \n",
    "\n",
    "Наиболее часто используемый метод — это **поиск по сетке** (`grid search`), который по сути является попыткой перебрать все возможные комбинации заданных гиперпараметров. Мы указываем список значений для различных гиперпараметров, и, ориентируясь на нашу метрику, оцениваем эффективность модели для каждого их сочетания, чтобы получить оптимальную комбинацию значений.\n",
    "\n",
    "Допустим, мы хотим подобрать гиперпараметры `min_samples_leaf` и `max_depth` для алгоритма `DecisionTreeClassifier`. Зададим списки их значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = [3, 5, 8, 9]\n",
    "max_depth = [4, 5, 6, 7, 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку нам нужно перебрать четыре различных значения для `min_samples_leaf` и пять — для `max_depth`, то получается всего `4*5=20` комбинаций. Модель будет обучена 20 раз; столько же раз будет рассчитана метрика.\n",
    "\n",
    "Сетка выглядит следующим образом:\n",
    "\n",
    "<img src=ml7_img3.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОПАСНОСТЬ ПЕРЕОБУЧЕНИЯ И УТЕЧКИ ДАННЫХ\n",
    "\n",
    "Для того, чтобы выбрать оптимальные значения гиперпараметров, мы ориентируемся на выбранную метрику, рассчитанную на тестовой выборке. Мы делали это для подбора гиперпараметра регуляризации `alpha`, но является ли это надёжным подходом?\n",
    "\n",
    ">Эту проблему мы уже обсуждали в модуле ML-5 «Валидация и оценка качества моделей».\n",
    "\n",
    "Давайте вспомним: мы перебираем множество значений гиперпараметров и выбираем ту комбинацию значений, которая даёт наилучшую точность на тестовых данных. **Однако это совсем не означает, что на новых данных мы получим такой же результат**. \n",
    "\n",
    "Поскольку мы использовали тестовый набор для настройки гиперпараметров, мы больше не можем использовать его для оценки качества модели. Теперь в этих целях нам необходим независимый набор данных, то есть набор, который не использовался для построения модели и настройки её гиперпараметров.\n",
    "\n",
    "Следовательно, надо разбить данные на **три части**: **обучающую** для построения модели, проверочную (**валидационную**) для выбора гиперпараметров модели, а также **тестовую** для оценки качества модели и выбранных гиперпараметров. \n",
    "\n",
    "<img src=ml7_img4.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наличие всех трёх наборов данных критически важно для использования МО. Любой подбор гиперпараметров, сделанный на тестовых данных, «сливает» модели информацию, содержащуюся в них, и может привести к неправильной оценке качества модели. Такая проблема относится к категории утечки данных, которую мы уже тоже затрагивали в модуле по валидации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Рассмотренный метод разбиения данных на обучающий, проверочный и тестовый наборы является вполне рабочим и относительно широко используемым, но весьма чувствителен к равномерности разбиения данных. \n",
    "\n",
    "Для лучшей оценки обобщающей способности вместо одного разбиения данных на обучающий и проверочный наборы мы можем воспользоваться перекрёстной проверкой, то есть **кросс-валидацией** (`cross` `validation`). В таком случае качество модели оценивается для каждой комбинации гиперпараметров по всем разбиениям кросс-валидации. \n",
    "\n",
    "<img src=ml7_img5.png>\n",
    "\n",
    ">Пояснение к рисунку. Предположим, что у нас есть `n` комбинаций гиперпараметров. Берём первую комбинацию и обучаем на них первую модель с помощью кросс-валидации с 10 фолдами (`cv=10`), затем рассчитываем метрику как среднее по всем разбиениям. Так проделываем для каждой комбинации и выбираем ту, при которой наша метрика наилучшая. В итоге мы обучим `n*cv` моделей, но выберем один набор гиперпараметров, который и будет использоваться для обучения итоговой модели на всей обучающей выборке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCHCV\n",
    "\n",
    "Поскольку поиск по сетке с кросс-валидацией является весьма распространённым методом настройки гиперпараметров, библиотека `scikit`-`learn` предлагает класс `GridSearchCV`, в котором осуществляется именно такой вариант.\n",
    "\n",
    "## Файл `ML-7.Optimization_of_hyperparameters.ipynb`\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Продвинутая оптимизация <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Практика <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Итоги <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
