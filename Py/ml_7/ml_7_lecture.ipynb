{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-7 Оптимизация гиперпараметров модели\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Базовая оптимизация](#2)\n",
    "- [2.1 GridSearch](#2-1)\n",
    "- [2.2 RandomSearch](#2-2)\n",
    "- [2.3 Рекомендации по настройкам](#2-3)\n",
    "- [3. Продвинутая оптимизация](#3)\n",
    "- [3.1 HUPEROPT](#3-1)\n",
    "- [3.2 OPTUNA](#3-2)\n",
    "- [4. Практика](#4)\n",
    "- [5. Итоги](#5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение <a class=\"anchor\" id=1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Итак, как мы уже неоднократно упоминали ранее, в машинном обучении есть два типа параметров.\n",
    "\n",
    "**Внутренние** (параметры модели)\n",
    "\n",
    "Подбираются во время обучения и определяют, как использовать входные данные для получения необходимого результата.\n",
    "\n",
    "Например, это веса (коэффициенты уравнения) в линейной/логистической регрессии.\n",
    "\n",
    "**Внешние** (параметры алгоритма)\n",
    "\n",
    "Их принято называть `гиперпараметрами`. Внешние параметры могут быть произвольно установлены перед началом обучения и контролируют внутреннюю работу обучающего алгоритма.\n",
    "\n",
    "Например, это параметр регуляризации в линейной/логистической регрессии.\n",
    "\n",
    "`Гиперпараметры` отвечают за сложность взаимосвязи между входными признаками и целевой переменной, поэтому сильно влияют на модель и качество прогнозирования.\n",
    "\n",
    "Продемонстрируем это на примере задачи регрессии с помощью двух графиков работы алгоритма случайного леса, построенного на основе `5`, `100` деревьев (`n_estimators = [5, 100]`):\n",
    "\n",
    "<img src=ml7_img1.png>\n",
    "\n",
    "Видим, что при 100 деревьях модель находит более сложную закономерность в данных и точность соответственно будет выше, чем при 5.\n",
    "\n",
    "Каждый алгоритм МО имеет набор гиперпараметров, которые определяют, как именно он строит модель на обучающей выборке. Например, в модуле ML-2 для повышения эффективности модели мы уже рассматривали подбор параметра регуляризации `alpha` для алгоритма линейной регрессии `Ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20057/1676261705.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mridge_lr_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Обучаем модель предсказывать логарифм целевого признака\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mridge_lr_poly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Делаем предсказание для каждой из выборок\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled_poly' is not defined"
     ]
    }
   ],
   "source": [
    "#Создаем список из 20 возможных значений от 0.001 до 10\n",
    "alpha_list = np.linspace(0.01, 10, 20)\n",
    "#Создаем пустые списки, в которые будем добавлять результаты \n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for alpha in alpha_list:\n",
    "    #Создаем объект класса линейная регрессия с L2-регуляризацией\n",
    "    ridge_lr_poly = linear_model.Ridge(alpha=alpha, max_iter=10000)\n",
    "    #Обучаем модель предсказывать логарифм целевого признака\n",
    "    ridge_lr_poly.fit(X_train_scaled_poly, y_train_log)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    #Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "    y_train_predict_poly = np.exp(ridge_lr_poly.predict(X_train_scaled_poly))\n",
    "    y_test_predict_poly = np.exp(ridge_lr_poly.predict(X_test_scaled_poly))\n",
    "    #Рассчитываем метрику для двух выборок и добавляем их в списки\n",
    "    train_scores.append(metrics.mean_absolute_error(y_train, y_train_predict_poly))\n",
    "    test_scores.append(metrics.mean_absolute_error(y_test, y_test_predict_poly))\n",
    " \n",
    "#Визуализируем изменение R^2 в зависимости от alpha\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость\n",
    "ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки\n",
    "ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки\n",
    "ax.set_xlabel('Alpha') #название оси абсцисс\n",
    "ax.set_ylabel('MAE') #название оси ординат\n",
    "ax.set_xticks(alpha_list) #метки по оси абцисс\n",
    "ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс\n",
    "ax.legend(); #отображение легенды"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml7_img2.png>\n",
    "\n",
    "Наилучшее значение метрики соответствует `alpha = 0.01` (кстати, можно попробовать перебрать значения `alpha < 0.01`).\n",
    "\n",
    "В данном случае мы просто воспользовались циклом for и перебрали некоторые заданные значения alpha, хотя, по всей видимости, не самые оптимальные. Поэтому подобранные эмпирическим путём значения гиперпараметров с большей вероятностью дадут низкую прогностическую эффективность.\n",
    "\n",
    "Также рассмотренный метод визуализации зависимости метрики от гиперпараметра позволяет выбрать только один внешний параметр, в данном случае — `alpha`. А что делать, если у нас не один, а несколько? \n",
    "\n",
    "Например, вспомним основные внешние параметры `DecisionTreeClassifier`:\n",
    "\n",
    "* `criterion` — критерий информативности. Может быть равен `'gini'` — критерий Джини — и `'entropy'` — энтропия Шеннона.\n",
    "* `max_depth` — максимальная глубина дерева. По умолчанию `None`, глубина дерева не ограничена.\n",
    "* `max_features` — максимальное число признаков, по которым ищется лучшее разбиение в дереве. По умолчанию `None`, то есть обучение производится на всех признаках.\n",
    "* `min_samples_leaf` — минимальное число объектов в листе. По умолчанию — `1`.\n",
    "\n",
    "Мы, конечно, можем сделать кучу вложенных циклов. Однако, поскольку поиск оптимальных значений гиперпараметров является общераспространенной задачей МО, библиотека `scikit`-`learn` и другие предлагают методы, позволяющие её решить.\n",
    "\n",
    "Тщательный подбор гиперпараметров гарантирует, что модель покажет максимально возможную точность на обучающих данных, **но это совершенно не означает хороший результат на тестовых или новых данных.**\n",
    "\n",
    "Поиск оптимальных значений гиперпараметров модели является сложной задачей, обязательной почти для всех моделей и наборов данных. Однако важно понимать смысл гиперпараметров перед их подбором."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Базовая оптимизация <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "В базовой оптимизации, предоставляемой библиотекой `sklearn`, есть два основных метода — `grid search` и `random search`. С ними мы сейчас и познакомимся. Оба используются при решении реальных задач, поэтому важно разобраться, как они устроены. \n",
    "\n",
    "Наиболее часто используемый метод — это **поиск по сетке** (`grid search`), который по сути является попыткой перебрать все возможные комбинации заданных гиперпараметров. Мы указываем список значений для различных гиперпараметров, и, ориентируясь на нашу метрику, оцениваем эффективность модели для каждого их сочетания, чтобы получить оптимальную комбинацию значений.\n",
    "\n",
    "Допустим, мы хотим подобрать гиперпараметры `min_samples_leaf` и `max_depth` для алгоритма `DecisionTreeClassifier`. Зададим списки их значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = [3, 5, 8, 9]\n",
    "max_depth = [4, 5, 6, 7, 8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку нам нужно перебрать четыре различных значения для `min_samples_leaf` и пять — для `max_depth`, то получается всего `4*5=20` комбинаций. Модель будет обучена 20 раз; столько же раз будет рассчитана метрика.\n",
    "\n",
    "Сетка выглядит следующим образом:\n",
    "\n",
    "<img src=ml7_img3.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ОПАСНОСТЬ ПЕРЕОБУЧЕНИЯ И УТЕЧКИ ДАННЫХ\n",
    "\n",
    "Для того, чтобы выбрать оптимальные значения гиперпараметров, мы ориентируемся на выбранную метрику, рассчитанную на тестовой выборке. Мы делали это для подбора гиперпараметра регуляризации `alpha`, но является ли это надёжным подходом?\n",
    "\n",
    ">Эту проблему мы уже обсуждали в модуле ML-5 «Валидация и оценка качества моделей».\n",
    "\n",
    "Давайте вспомним: мы перебираем множество значений гиперпараметров и выбираем ту комбинацию значений, которая даёт наилучшую точность на тестовых данных. **Однако это совсем не означает, что на новых данных мы получим такой же результат**. \n",
    "\n",
    "Поскольку мы использовали тестовый набор для настройки гиперпараметров, мы больше не можем использовать его для оценки качества модели. Теперь в этих целях нам необходим независимый набор данных, то есть набор, который не использовался для построения модели и настройки её гиперпараметров.\n",
    "\n",
    "Следовательно, надо разбить данные на **три части**: **обучающую** для построения модели, проверочную (**валидационную**) для выбора гиперпараметров модели, а также **тестовую** для оценки качества модели и выбранных гиперпараметров. \n",
    "\n",
    "<img src=ml7_img4.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наличие всех трёх наборов данных критически важно для использования МО. Любой подбор гиперпараметров, сделанный на тестовых данных, «сливает» модели информацию, содержащуюся в них, и может привести к неправильной оценке качества модели. Такая проблема относится к категории утечки данных, которую мы уже тоже затрагивали в модуле по валидации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Рассмотренный метод разбиения данных на обучающий, проверочный и тестовый наборы является вполне рабочим и относительно широко используемым, но весьма чувствителен к равномерности разбиения данных. \n",
    "\n",
    "Для лучшей оценки обобщающей способности вместо одного разбиения данных на обучающий и проверочный наборы мы можем воспользоваться перекрёстной проверкой, то есть **кросс-валидацией** (`cross` `validation`). В таком случае качество модели оценивается для каждой комбинации гиперпараметров по всем разбиениям кросс-валидации. \n",
    "\n",
    "<img src=ml7_img5.png>\n",
    "\n",
    ">Пояснение к рисунку. Предположим, что у нас есть `n` комбинаций гиперпараметров. Берём первую комбинацию и обучаем на них первую модель с помощью кросс-валидации с 10 фолдами (`cv=10`), затем рассчитываем метрику как среднее по всем разбиениям. Так проделываем для каждой комбинации и выбираем ту, при которой наша метрика наилучшая. В итоге мы обучим `n*cv` моделей, но выберем один набор гиперпараметров, который и будет использоваться для обучения итоговой модели на всей обучающей выборке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRIDSEARCHCV\n",
    "\n",
    "Поскольку поиск по сетке с кросс-валидацией является весьма распространённым методом настройки гиперпараметров, библиотека `scikit`-`learn` предлагает класс `GridSearchCV`, в котором осуществляется именно такой вариант.\n",
    "\n",
    "## Файл `ML-7.Optimization_of_hyperparameters.ipynb`\n",
    "\n",
    "Основные параметры `GridSearchCV`:\n",
    "\n",
    "* `estimator` — алгоритм, который будем оптимизировать;\n",
    "* `param_grid` — словарь или список словарей. Словарь с именами гиперпараметров (в формате строки (`str`), например, '`max_depth`') в качестве ключей и списками параметров (например, `[5, 8, 10]`) в качестве значений. Итого: `{'max_depth': [5, 8, 10] }`.\n",
    "\n",
    "Также можно передать список таких словарей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {'max_depth': [5, 8, 10],\n",
    "               'min_samples_leaf': [7, 8, 9] } #первый словарь \n",
    "              {'n_estimators': [100, 200, 300], \n",
    "               'max_depth': [5, 8, 10] } #второй словарь \n",
    "             ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таком случае каждый словарь в списке перебирается отдельно и последовательно. Это позволяет выполнять поиск по любой последовательности настроек параметров.\n",
    "\n",
    "* `scoring` — по умолчанию используется score-функция заданного алгоритма:\n",
    "\n",
    "* * для классификации — `sklearn.metrics.accuracy_score`;\n",
    "\n",
    "* * для регрессии — `sklearn.metrics.r2_score`;\n",
    "\n",
    ">Возможно выбрать любую другую в зависимости от условий задачи. Различные варианты смотрите [здесь.](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
    "\n",
    "* `cv` — количество фолдов в кросс-валидации, по умолчанию используется 5.\n",
    "\n",
    "* `n_jobs` — количество ядер для распараллеливания расчёта. -1 использует все существующие ядра."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтобы воспользоваться классом `GridSearchCV`, необходимо:\n",
    "\n",
    "1. Импортировать библиотеку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Указать искомые гиперпараметры в виде словаря  `param_grid`: ключами словаря являются имена настраиваемых гиперпараметров, а значениями – тестируемые настройки гиперпараметров. Мы рассмотрим сетку из:\n",
    "\n",
    "* '`penalty`' — тип регуляризации. Может принимать значения `l1`,  `l2`, '`elasticnet`' или `None` (отсутствие регуляризации);\n",
    "* '`solver`' — алгоритм оптимизации, может принимать значения '`newton`-`cg`', '`lbfgs`', \n",
    "* '`liblinear`', '`sag`', '`saga`', по умолчанию — '`lbfgs`'.\n",
    "\n",
    "Важно помнить, что выбор алгоритма оптимизации зависит от выбранного типа штрафа:\n",
    "\n",
    "<img src=ml7_img6.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l2', 'none'] ,#тип регурялизации\n",
    "                  'solver': ['lbfgs', 'saga'] #алгоритм оптимизации\n",
    "                  }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Вызвать класс `GridSearchCV` и передать модель (`LogisticRegression`), сетку искомых параметров (`param_grid`), а также число фолдов, которые мы хотим использовать в кросс-валидации, и `n_jobs = -1`, чтобы использовать все доступные ядра для расчётов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=1, #генератор случайных чисел\n",
    "        max_iter=1000 #количество итераций на сходимость\n",
    "    ), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_scaled, y_train) \n",
    "#Затраченное время: 1min 4s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Созданный нами объект `grid_search` аналогичен классификатору, поэтому мы можем вызвать стандартные методы `fit`, `predict` и `score` от его имени. Однако, когда мы вызываем `fit()`, он запускает кросс-валидацию для каждой комбинации гиперпараметров, указанных в `param_grid`:\n",
    "\n",
    ">`GridSearchCV` включает в себя не только поиск лучших параметров, но и автоматическое построение новой модели на всём обучающем наборе данных с использованием параметров, которые дают наилучшее значение метрики при кросс-валидации.\n",
    "\n",
    "Наилучшая найденная комбинация гиперпараметров сохраняется в атрибуте `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Наилучшие значения параметров: {}\".format(grid_search.best_params_))\n",
    "# Наилучшие значения гиперпараметров: {'penalty': 'none', 'solver': 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наилучшая метрика:\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Либо можем посмотреть любую другую метрику, воспользовавшись методом `predict()` и передав предсказанные значения в функцию для расчёта метрики (например, `f1_score()`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    " \n",
    "# accuracy на тестовом наборе: 0.84\n",
    "# f1_score на тестовом наборе: 0.64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрик не изменились, но это значит лишь, что мы не нашли комбинацию внешних параметров лучше, чем заданы по умолчанию. Это неудивительно, и достаточно часто исходные  гиперпараметры дают неплохой результат, но это не повод останавливаться!\n",
    "\n",
    "Попробуем расширить сетку гиперпараметров и проделаем те же шаги:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `RANDOMIZEDSEARCHCV` <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Альтернативным подходом подбора различных комбинаций гиперпараметров в библиотеке `scikit`-`learn` является `RandomizedSearchCV`. \n",
    "\n",
    "Рандомизированный поиск работает почти так же, как решётчатый поиск, но он гораздо экономичнее и эффективнее по времени, потому что мы можем задать количество подбираемых комбинаций, а не брать все возможные.\n",
    "\n",
    "<img src=ml7_img7.png>\n",
    "\n",
    "На этой картинке изображено принципиальное различие двух методов: \n",
    "\n",
    "* В `GridSearchCV` сетка задаётся вручную, перебираются различные значения гиперпараметров с каким-то шагом, в итоге получается что-то похожее на «красивую» сетку слева на картинке. Однако минимум функции (белое пятно) мы так и не обнаруживаем — а ведь он где-то рядом, возможно, просто между подобранными нами комбинациями.\n",
    "\n",
    "* `RandomizedSearchCV` выбирает `n` (количество задаем сами) случайных точек/комбинаций из заданных нами последовательностей. Как следствие, мы можем перебирать не все возможные точки, а только часть из них, тем самым управляя скоростью работы перебора."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры `RandomizedSearchCV` аналогичны `GridSearchCV`, за исключением `n_iter`:\n",
    "\n",
    "* `estimator` — алгоритм, который будем оптимизировать;\n",
    "\n",
    "* `param_grid` — словарь или список словарей.\n",
    "\n",
    ">Примечание. В ранних версиях `sklearn` данный параметр был обозначен как `param_grid`.\n",
    "\n",
    "* `scoring` — по умолчанию используется score-функция заданного алгоритма:\n",
    "\n",
    "* * для классификации — `sklearn.metrics.accuracy_score`;\n",
    "\n",
    "* * для регрессии — `sklearn.metrics.r2_score`;\n",
    "\n",
    "* `cv` — количество фолдов в кросс-валидации, по умолчанию используется 5.\n",
    "\n",
    "* `n_jobs` — количество ядер для распараллеливания расчёта. -1 использует все существующие ядра.\n",
    "\n",
    "* `n_iter` — количество комбинаций на расчёт. От этого параметра напрямую зависит время оптимизации и качество модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РЕКОМЕНДАЦИИ ПО НАСТРОЙКЕ ГИПЕРПАРАМЕТРОВ АНСАМБЛЕЙ НАД РЕШАЮЩИМИ ДЕРЕВЬЯМИ <a class=\"anchor\" id=2-3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "## АЛГОРИТМ СЛУЧАЙНОГО ЛЕСА (`RANDOMFOREST`)\n",
    "\n",
    "* `n_estimators` — число итераций (количество деревьев). Частично работает правило «чем больше, тем лучше», но иногда это не имеет особого смысла и сильно увеличивает затраты, поэтому стоит пробовать обучать сотни деревьев [100,200, 300, 400]. Если нет изменений, то оставить минимальное — 100.\n",
    "\n",
    "* `max_depth` — максимальная глубина дерева. В случайном лесе строятся «сильные» деревья, каждое из которых даёт полноценный прогноз, поэтому глубина деревьем может быть достаточно большой. Стоит следить за переобучением.\n",
    "\n",
    "* `max_features` — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения;\n",
    "\n",
    "* `subsample` — доля выборки, которая будет использоваться для обучения каждого алгоритма — дерева.\n",
    "\n",
    "## АЛГОРИТМ ГРАДИЕНТНОГО БУСТИНГА (`GRADIENTBOOSTING`)\n",
    "\n",
    "* `n_estimators` — число итераций (количество деревьев) : хотя ошибка на обучении монотонно стремится к нулю, ошибка на контроле, как правило, начинает увеличиваться после определенной итерации. Оптимальное число итераций можно выбирать, например, по отложенной выборке или с помощью кросс-валидации.\n",
    "\n",
    "* `learning_rate` — темп обучения (0;1]:\n",
    "\n",
    ">На практике оказывается, что градиентный бустинг очень быстро строит композицию, ошибка которой на обучении выходит на асимптоту (достигает предела), после чего начинает настраиваться на шум и переобучаться. Параметр `learning_rate` контролирует, насколько сильно каждое дерево будет пытаться исправить ошибки предыдущих деревьев. Более высокая скорость обучения означает, что каждое дерево может внести более сильные корректировки. Как правило, чем меньше темп обучения, тем лучше качество итоговой композиции.\n",
    "\n",
    "* `max_depth` — максимальная глубина дерева. Используется для борьбы с переобучением. Рекомендуется устанавливать не более 5.\n",
    "\n",
    "* `max_features` — максимальное количество признаков, учитываемых алгоритмом при поиске лучшего разделения.\n",
    "\n",
    "* `subsample` — доля выборки, которая будет использоваться для обучения каждого алгоритма. Это ещё один способ улучшения качества градиентного бустинга. Таким образом вносится рандомизация в процесс обучения базовых алгоритмов, что снижает уровень шума в обучении, а также повышает эффективность вычислений. \n",
    "\n",
    "<img src=ml7_img8.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное отличие техник `Bagging` и `Boosting` состоит в параллельном и последовательном построении деревьев соответственно.\n",
    "\n",
    "Основные параметры градиентного бустинга деревьев — это количество деревьев (`n_estimators`) и скорость обучения (`learning_rate`), контролирующие степень вклада каждого дерева в устранение ошибок предыдущих деревьев. Эти два параметра тесно взаимосвязаны, поскольку более низкое значение `learning_rate` означает, что для построения модели аналогичной сложности необходимо большее количество деревьев.\n",
    "\n",
    ">В отличие от случайного леса, в котором более высокое значение `n_estimators` всегда дает лучшее качество, увеличение значения `n_estimators` в градиентном бустинге даёт более сложную модель, что может привести к переобучению. При всём этом случайный лес, в отличие от градиентного бустинга, использует глубокие деревья, способные сформировать полноценный прогноз. \n",
    "\n",
    "Общепринятая практика для бустинга — подгонять `n_estimators` в зависимости от бюджета времени и памяти, а затем подбирать различные значения `learning_rate`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Продвинутая оптимизация <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Один из способов  — это **байесовская оптимизация**. Она отличается от случайного поиска или поиска по сетке тем, что учитывает предыдущие результаты, а не выбирает комбинации из вариантов, не имеющих информации о прошлых оценках. Во многих случаях это позволяет найти лучшие значения гиперпараметров модели за меньшее количество времени. Таким образом, мы получаем и более быструю оптимизацию, и более качественный результат. Это два желаемых результата, особенно когда мы работаем с настройкой гиперпараметров моделей МО.\n",
    "\n",
    "Существует несколько разных алгоритмов для этого типа оптимизации, но особенно используемым является `Tree-Structured Parzen Estimators` (`TPE`).\n",
    "\n",
    "## TREE-STRUCTURED PARZEN ESTIMATORS (`TPE`)\n",
    "\n",
    "1. На каждой итерации алгоритм `TPE` учитывает информацию о прошлых опробованных комбинациях гиперпараметров и только потом принимает решение, какой набор следует попробовать дальше. \n",
    "\n",
    "Чтобы приступить к использованию `TPE`, необходимо выполнить несколько итераций с помощью случайного поиска. \n",
    "\n",
    "2. На следующем шаге происходит разделение собранных наборов на две группы:\n",
    "\n",
    "* в первую группу входят наборы, дающие наилучшие результаты после оценки;\n",
    "* во вторую — все остальные.\n",
    "\n",
    "\n",
    "На изображении ниже: первая группа — **красные** точки находятся в области минимума целевой функции; вторая группа — **синие** точки, все остальные.\n",
    "\n",
    "<img src=ml7_img9.png>\n",
    "\n",
    ">Основная цель алгоритма — найти набор гиперпараметров, который с большей вероятностью будет в первой группе и с меньшей вероятностью во второй группе. Таким образом, для принятия следующего решения используется целое распределение наилучших комбинаций — **красные точки на графике**.\n",
    "\n",
    "3. Далее `TPE` моделирует вероятности правдоподобия для каждой из групп, используя **формулу Байеса**:\n",
    "\n",
    "<img src=ml7_img10.png>\n",
    "\n",
    "4. Затем, используя вероятность правдоподобия из первой группы, отбирается набор комбинаций, которые с большей вероятностью попадут в первую группу и с меньшей вероятностью — во вторую. \n",
    "\n",
    "<img src=ml7_img11.png>\n",
    "\n",
    "5. **Шаги 2-4**  будет выполняться до тех пор, пока не будет достигнуто максимальное количество итераций. \n",
    "\n",
    "В итоге мы найдём наилучшую комбинацию гиперпараметров."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `HYPEROPT`<a class=\"anchor\" id=3-1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "`Hyperopt` — это библиотека `Python` с открытым исходным кодом на основе байесовской оптимизации, в которой реализован алгоритм `Tree-Structured Parzen Estimators` (`TPE`).\n",
    "\n",
    "Три шага для использования `Hyperopt`:\n",
    "\n",
    "1. Задание пространства поиска гиперпараметров. \n",
    "\n",
    "Объявляем список гиперпараметров, тип распределения и его границы.\n",
    "\n",
    "Основные типы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.choice(label, options) #равновероятный выбор из множества\n",
    "\n",
    "hp.randint(label, upper) #случайное целое число; random seed, например \n",
    "\n",
    "hp.uniform(label, low, high) #равномерное непрерывное распределение\n",
    "\n",
    "hp.normal(label, mu, sigma) #нормальное непрерывное распределение\n",
    "\n",
    "hp.lognormal(mu, sigma) #логнормальное непрерывное распределение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте для:\n",
    "\n",
    "* **категориальных** — `hp.choice`;\n",
    "\n",
    "* **целочисленных** —  `hp.randit`, `hp.quniform`;\n",
    "\n",
    "* **непрерывных** — аналогично целочисленным и `hp.normal`, `hp.uniform`, `hp.lognormal`, `hp.loguniform`.\n",
    "\n",
    "2. Задание целевой функции. \n",
    "\n",
    "Создаём модель МО, передаём ей данные и оцениваем её на основе выбранной метрики. Можем минимизировать/максимизировать значение метрики.\n",
    "\n",
    "3. Задание алгоритма поиска:\n",
    "\n",
    "* `Random Search`.\n",
    "\n",
    "* `Tree of Parzen Estimators `(`TPE`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные ссылки: \n",
    "\n",
    "* [Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms](https://lms.skillfactory.ru/assets/courseware/v1/32710b2c3069452833036ea0e4da10fe/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/bergstra_hyperopt.pdf)\n",
    "\n",
    "* [Hyperopt на GitHub](https://github.com/hyperopt/hyperopt/)\n",
    "\n",
    "* [Байесовский ниндзя (Хабр)](https://habr.com/ru/post/494242/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем библиотеку\n",
    "!pip install hyperopt\n",
    "или\n",
    "!conda install -c conda-forge hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Версия Hyperopt : 0.2.7\n"
     ]
    }
   ],
   "source": [
    "#делаем импорт и выведем версию библиотеки\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# fmin - основная функция, она будет минимизировать наш функционал\n",
    "# tpe - алгоритм оптимизации\n",
    "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
    "# trails - используется для логирования результатов\n",
    "\n",
    "print(\"Версия Hyperopt : {}\".format(hyperopt.__version__))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интерфейс `Hyperopt` отличается от `Grid` или `RandomizedSearch`, поэтому нам нужно создать функцию для минимизации. Она должна принимать словарь значений гиперпараметров и возвращать значение целевой функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5647/2114224617.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# зафксируем random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mhyperopt_rf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# функция получает комбинацию гиперпараметров в \"params\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     params = {'n_estimators': int(params['n_estimators']), \n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train_scaled, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    # score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# начинаем подбор гиперпараметров\n",
    "%%time\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n",
    "#100%|██████████| 20/20 [01:10<00:00,  3.50s/it, best loss: -0.7986892215038526]\n",
    "#Наилучшие значения гиперпараметров {'max_depth': 24.0, 'min_samples_leaf': 2.0, 'n_estimators': 153.0}\n",
    "#CPU times: user 1min 10s, sys: 183 ms, total: 1min 10s\n",
    "#Wall time: 1min 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test_scaled, y_test)))\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "\n",
    "#f1_score на обучающем наборе: 0.80\n",
    "#accuracy на тестовом наборе: 0.86\n",
    "#f1_score на тестовом наборе: 0.68"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем продолжить поиск гиперпараметров, чтобы получить лучшие результаты.\n",
    "\n",
    "Для байесовских оптимизаторов это возможно, так как они ориентируются на прошлые результаты: предыдущие входные данные для целевой функции и результирующие потери.\n",
    "\n",
    "`Hyperopt` продолжит поиск с того места, где он остановился, если мы передадим ему объект `Trials`, который уже содержит информацию о предыдущих запусках.\n",
    "\n",
    "**Всегда сохраняйте свои предыдущие результаты!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если необходимо продолжить подбор, \n",
    "# то увеличиваем max_evals(должен быть строго больше, чем на предыдущих итерациях) \n",
    "# и используем старый trials\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=23, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.RandomState(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n",
    "#100%|██████████| 3/3 [00:08<00:00,  2.89s/it, best loss: -0.7986892215038526]\n",
    "#Наилучшие значения гиперпараметров {'max_depth': 24.0, 'min_samples_leaf': 2.0, 'n_estimators': 153.0}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что `Hyperopt` смог улучшить нашу метрику, причём за меньшее время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисуем, как менялась точность при различных гиперпараметрах\n",
    "tpe_results=np.array([[x['result']['loss'],\n",
    "                      x['misc']['vals']['max_depth'][0],\n",
    "                      x['misc']['vals']['n_estimators'][0]] for x in trials.trials])\n",
    "\n",
    "tpe_results_df=pd.DataFrame(tpe_results,\n",
    "                           columns=['score', 'max_depth', 'n_estimators'])\n",
    "# тепловая карта в данном случае не очень наглядна, возьмем линейный график\n",
    "tpe_results_df.plot(subplots=True,figsize=(10, 10));\n",
    "\n",
    "#array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f2883875490>,\n",
    "       #<matplotlib.axes._subplots.AxesSubplot object at 0x7f28838d9d90>,\n",
    "       #<matplotlib.axes._subplots.AxesSubplot object at 0x7f288412bf90>],"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml7_img12.jpeg>\n",
    "\n",
    "По графикам видно, что лучшая точность достигается именно в `best_params`. Однако заметьте, что метрика отрицательная, так как нам необходимо максимизировать нашу метрику, в то время как `Hyperopt` может только минимизировать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA <a class=\"anchor\" id=3-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "[Сайт Optuna](https://optuna.org/)\n",
    "\n",
    "`Optuna` — это достаточно новый фреймворк/библиотека, разработанный специально для оптимизации гиперпараметров. Помимо байесовских алгоритмов, есть возможность удаления плохих комбинаций из рассмотрения. По умолчанию алгоритм удаляет комбинации, в которых модель даёт качество ниже медианы из уже рассмотренных. Optuna помогает  быстрее находить лучшие гиперпараметры и работает с большинством современных известных библиотек `ML`, таких как `scikit`-`learn`, `xgboost`, `PyTorch`, `TensorFlow`, `skorch`, `lightgbm`, `Keras`, `fast-ai `и другими."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Три шага для использования `Optuna`: \n",
    "\n",
    "**1. Задание пространства поиска гиперпараметров.**\n",
    "\n",
    ">Основные функции:\n",
    ">\n",
    ">* `suggest_categorical(name, choices)` — для категориальных гиперпараметров;\n",
    ">* `suggest_int(name,low,high,step=1,log=False)` — для целочисленных гиперпараметров;\n",
    ">* `suggest_float(name,low,high,step=None,log=False)` — для непрерывных гиперпараметров;\n",
    ">* `suggest_uniform(name,low,high)` — для целочисленных и непрерывных гиперпараметров.\n",
    ">\n",
    ">С помощью необязательных аргументов `step` и `log` можно дискретизировать или взять логарифм целочисленных и непрерывных параметров.\n",
    "\n",
    "**2. Задание целевой функции.**\n",
    "\n",
    "Создаём модель МО, передаём ей данные и оцениваем её на основе выбранной метрики, можем минимизировать/максимизировать значение метрики. На данном этапе будет обучена модель только на одной комбинации гиперпараметров.\n",
    "\n",
    "**3. Создание объекта исследования create study.** \n",
    "\n",
    "По умолчанию используется алгоритм поиска `TPE` (есть и другие варианты) и вызов метода `optimize()`, в который передаётся целевая функция, созданная на первом шаге. Выполняется заданное `n_trials` раз, подставляются различные комбинации гиперпараметров."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml7_img12.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Практика <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Наша практика будет основана на соревновании [Kaggle: Predicting a Biological Response](https://www.kaggle.com/c/bioresponse)\n",
    "\n",
    "Данные представлены в формате `CSV`.  Каждая строка представляет молекулу. \n",
    "\n",
    "* Первый столбец `Activity` содержит экспериментальные данные, описывающие фактический биологический ответ `[0, 1]`; \n",
    "\n",
    "* Остальные столбцы `D1-D1776` представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n",
    "\n",
    "**Предварительная обработка не требуется**, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать `F1-score`.\n",
    "\n",
    "Необходимо обучить две модели: `логистическую регрессию` и `случайный лес`. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (`GridSeachCV`, `RandomizedSearchCV`, `Hyperopt`, `Optuna`) хотя бы по разу, максимальное количество итераций не должно превышать `50`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Итоги <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
