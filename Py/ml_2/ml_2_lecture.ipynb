{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-2 Обучение с учителем. Регрессия\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Линейная регрессия. Аналитическое решение](#2)\n",
    "- [2.1 Аналитическое решение с помощью NUMPY](#2-1)\n",
    "- [2.1 Аналитическое решение с помощью SKLEARN](#2-2)\n",
    "- [3. Метрики регрессии. Недостатки аналитического решения](#3)\n",
    "- [3.1 Расчёт метрик на Python](#3-1)\n",
    "- [3.2 Недостатки аналитического решения ](#3-2)\n",
    "- [4. Линейная регрессия. Численные решения](#4)\n",
    "- [4.1 Численные решения на python](#4-1)\n",
    "- [4.2 Сравнение аналитического и числовово методов](#4-2)\n",
    "- [5. Дилемма смещения и разброса. Полигональные признаки. Регуляризация](#5)\n",
    "- [5.1 Смещение и разброс.](#5)\n",
    "- [5.2 Полиномиальные признаки](#5-2)\n",
    "- [5.3 Регуляция](#5-3)\n",
    "- [6. Линейная регрессия. Практика](#6)\n",
    "- [7. Итоги](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение <a class=\"anchor\" id=1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "<img src=ml2_img1.png width=900>\n",
    "\n",
    "В категории обучения с учителем модели можно условно разделить на следующие основные типы:\n",
    "\n",
    "* **Линейные модели:** линейная регрессия (для задачи регрессии) и логистическая регрессия (для задачи классификации) и производные от них.\n",
    "* **«Древесные» модели:** дерево решений и производные от него. \n",
    "* **Метрические алгоритмы:** метод ближайших соседей и производные от него.\n",
    "* **Байесовские методы:** метод наивного Байеса и производные от него.\n",
    "* **Ансамблевые методы:** композиции из методов (бэггинг, стекинг, бустинг).\n",
    "\n",
    "В этом модуле мы поговорим о **линейных моделях** (но на самом деле ими не ограничимся), которые позволяют решать задачу регрессии.\n",
    "\n",
    ">**Линейные модели** — это модели, отображающие зависимость целевого признака от факторов в виде линейной взаимосвязи.\n",
    "\n",
    "<img src=ml2_img2.png width=900>\n",
    "\n",
    ">На данном графике мы видим зависимость цены товара от его размера. Из диаграммы рассеяния видно, что в среднем точки расположены на одной прямой линии. То есть зависимость линейная.\n",
    "\n",
    "Подкласс линейных моделей в свою очередь содержит множество конкретных моделей. В библиотеке `sklearn`, которую мы будем использовать, все линейные алгоритмы содержатся в модуле [linear_model](https://scikit-learn.ru/1-1-linear-models/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Линейная регрессия. Аналитическое решение <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "`Регрессия` — это класс задач обучения с учителем, когда по определённому набору признаков объекта необходимо предсказать числовую целевую переменную.\n",
    "\n",
    "`Цель обучения` — построить модель, которая бы отражала зависимость между признаками и целевой числовой переменной.\n",
    "\n",
    "Когда зависимость принимается линейной, такая модель называется `линейной регрессией`.\n",
    "\n",
    "## ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ЛИНЕЙНОЙ РЕГРЕССИИ\n",
    "\n",
    "**Линейная регрессия** (`Linear Regression`) — одна из простейших моделей для решения задачи регрессии. Главная гипотеза состоит в том, что рассматриваемая зависимость является линейной.\n",
    "\n",
    "Общий вид модели в случае, когда целевая переменная зависит от `m` факторов, будет иметь следующий вид:\n",
    "\n",
    "<img src=ml2_img3.png>\n",
    "\n",
    "Давайте разбираться, что в этом выражении значит каждая из переменных. Начнём с простого — с двумерного случая.\n",
    "\n",
    "### 2D-СЛУЧАЙ\n",
    "\n",
    "Для начала поговорим о самом простом случае, когда у нас есть один фактор и зависящий от него целевой признак. Геометрически такая зависимость представляет собой координатную плоскость, где мы отмечаем точки по оси `x` и соответствующие им точки на оси `y`.\n",
    "\n",
    ">Рассмотрим задачу из нефтяной отрасли. Есть набор данных, где представлены данные о средней пористости скважин (в процентах) и добыче газа на этих скважинах в сутки (в миллионах кубических футов). \n",
    "\n",
    "Нам бы хотелось построить модель, которая опишет зависимость и позволит по известной пористости скважин предсказывать неизвестную выработку газа.\n",
    "\n",
    "Зависимость целевого признака от фактора представлена на диаграмме рассеяния (см. ниже). Пористость скважины отложена по оси абсцисс — `Porosity (%)`, а добыча газа — по оси ординат, `Gas production (Mcf/day)`.\n",
    "\n",
    "<img src=ml2_img4.png>\n",
    "\n",
    "Из диаграммы отчётливо видно, что с ростом пористости скважины растёт добыча газа. Причём растёт она преимущественно линейно: основная масса точек находится на одной прямой.\n",
    "\n",
    ">Идея! Давайте проведём через точки прямую линию так, чтобы она максимально хорошо описывала зависимость.\n",
    "\n",
    "Для этого сначала вспомним уравнение прямой из школьного курса математики:\n",
    "\n",
    "`y = kx + b`\n",
    "\n",
    "где:\n",
    "\n",
    "* `x` — это некоторый фактор, от которого зависит целевая переменная `y`. В нашем случае, `x` — это пористость скважины, а `y` — добыча газа.\n",
    "* `k` — коэффициент наклона прямой (**тангенс угла наклона**). Если `k > 0`, это означает, что угол наклона прямой острый и прямая возрастает. Если `k < 0`, угол наклона тупой и прямая убывает.\n",
    "* `b` — коэффициент смещения прямой по оси `y`. Он будет соответствовать значению `y` при `x = 0`. То есть это точка пересечения прямой и оси `Y`.\n",
    "\n",
    "<img src=ml2_img5.png>\n",
    "\n",
    "<img src=ml2_img6.png>\n",
    "\n",
    "Это уравнение и есть двумерная модель линейной регрессии. Зная коэффициенты `k` и `b`, мы можем подставить в него любую пористость скважины `x` и получить предсказание добычи газа `y`.\n",
    "\n",
    "Однако в машинном обучении приняты немного другие обозначения. Фактическое значение целевой переменной обозначается как `y`, а вот предсказанное моделью — `y^`. Также для удобства коэффициенты `k`и `b` приведём к единому обозначению: `w0 = k` и `w1 = b`. Тогда уравнение модели линейной регрессии запишется в виде:\n",
    "\n",
    "<img src=ml2_img7.png>\n",
    "\n",
    ">**Примечание. Коэффициенты `w0` и `w1` называются параметрами линейной регрессии**.\n",
    "\n",
    "Остаётся только один вопрос: откуда, собственно, взять параметры `w0` и `w1`? Обсудим этот вопрос чуть позже.\n",
    "\n",
    "А пока представим, что параметры мы нашли. В таком случае можно построить прямую, которая опишет нашу зависимость. Пусть коэффициенты составляют (мы их нашли сами по методу наименьших квадратов, о котором поговорим ниже):\n",
    "\n",
    "`w0 = -2.94`\n",
    "\n",
    "`w1 = 287.7`\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "`y^ = 287.7x - 2.94`\n",
    "\n",
    "Если подставлять значения конкретные значения пористости `x` в модель, можно построить прямую, которая описывает исходную зависимость. Это и будет графическая интерпретация нашей модели:\n",
    "\n",
    "<img src=ml2_img8.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D-СЛУЧАЙ\n",
    "\n",
    "Теперь представим, что у нас не один фактор, а два. Например, помимо пористости скважины, мы дополнительно знаем ещё и о её хрупкости в процентах. То есть у нас теперь есть два фактора: `x1` — пористость и `x2` — хрупкость.\n",
    "\n",
    "Можно отобразить такую зависимость добычи газа от этих факторов в трёхмерном пространстве в виде диаграммы рассеяния:\n",
    "\n",
    "<img src=ml2_img9.png>\n",
    "\n",
    "В таком случае в выражение для модели добавится ещё одна переменная`x2` и соответствующий ей коэффициент `w2`:\n",
    "\n",
    "Опять же, представим, что параметры модели мы нашли и они равны:\n",
    "\n",
    "`w0 = -2003`\n",
    "\n",
    "`w1 = 302.3`\n",
    "\n",
    "`w1 = 31.38`\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "`y^ = 302.2x1 + 31.38x2 - 2003`\n",
    "\n",
    "Это была алгебра — теперь перейдём к геометрии. Геометрически данное уравнение описывает плоскость в трёхмерном пространстве с осями `x1` и `x2`, `w0` — смещение плоскости по вертикальной оси, а коэффициенты `w1` и `w2` — коэффициенты наклона этой плоскости к осям `x1` и `x2`. \n",
    "\n",
    "То это это будет плоскость, которая подстроена под точки в трёхмерном пространстве:\n",
    "\n",
    "<img src=ml2_img10.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОБЩИЙ СЛУЧАЙ\n",
    "\n",
    "А что если факторов не два, а больше: 3, 15, 100? Тут-то мы и приходим к общему виду модели линейной регрессии, который вводили в самом начале. Пусть у нас есть `m` факторов `{x1, x2, ..., xm}`, от которых зависит целевая переменная `y`.\n",
    "\n",
    "<img src=ml2_img11.png>\n",
    "\n",
    "В геометрическом смысле данное уравнение описывает плоскость в `(m - 1)`-мерном пространстве (`m` факторов + `1` целевой признак отложены по осям координат). Такую плоскость называют **гиперплоскостью**.\n",
    "\n",
    "Абстрактное `(m - 1)`-мерное пространство, конечно же, невозможно отобразить графически и сложно даже представить, как оно выглядит. Но нам это и не нужно. Все операции в таком пространстве аналогичны операциям в двумерном или трёхмерном пространстве.\n",
    "\n",
    ">Для понимания принципа работы мы будем рассматривать только прямую в двумерном пространстве, а результат уже обобщать на случай с большей размерностью.\n",
    "\n",
    "Стоит отметить, что в `DS` мы, как правило, работаем с большим количеством факторов (больше двух), которые описывают данные, поэтому отобразить модель в геометрическом пространстве не получится, но важно понимать, что представляет собой сама модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОИСК ПАРАМЕТРОВ ЛИНЕЙНОЙ РЕГРЕССИИ: МЕТОД НАИМЕНЬШИХ КВАДРАТОВ\n",
    "\n",
    ">Теперь мы знаем, как выглядит модель линейной регрессии в общем случае: это простое линейное выражение, подставляя в которое значения факторов, можно найти целевую переменную. Это линейное выражение соответствует прямой, плоскости или гиперплоскости в зависимости от количества признаков.\n",
    "\n",
    "Остаётся вопрос: откуда взять коэффициенты, которые стоят при `x`?\n",
    "\n",
    "Прямую же можно провести как угодно. Вот например несколько прямых, построенных с различными случайными коэффициентами:\n",
    "\n",
    "<img src=ml2_img12.png>\n",
    "\n",
    "Какие параметры будут наилучшими?\n",
    "\n",
    "Для ответа на этот вопрос давайте вспомним схему обучения моделей машинного обучения по принципу минимизации эмпирического риска, которую мы рассматривали в предыдущем модуле:\n",
    "\n",
    "<img src=ml2_img13.png width=900>\n",
    "\n",
    "Согласно данной схеме обучения, поиск параметров производится путём минимизации некоторой **функции ошибки**. Математически мы пытаемся с помощью методов оптимизации найти такие параметры, чтобы ошибка была наименьшей из возможных.\n",
    "\n",
    "Осталось только понять: **где взять эту функцию ошибки**? Ответ кроется в картинке ниже. Давайте представим, как могла бы выглядеть прямая в двумерном пространстве, проведённая, например, через пять точек:\n",
    "\n",
    "<img src=ml2_img14.png>\n",
    "\n",
    ">Что вообще есть **ошибка**? В самом простом понимании это расхождение между истиной и предсказанием.\n",
    "\n",
    "Чтобы не учитывать знак расхождения, можно взять модуль разницы между истинным значением и предсказанным (тем, что лежит на прямой). Рассчитать ошибки  `e_i` (на рисунке они отмечены красными отрезками) для всех пяти точек можно следующим образом:\n",
    "\n",
    "<img src=ml2_img15.png>\n",
    "\n",
    ">Тут-то математики и столкнулись с проблемой. Оказывается, если пытаться решить эту оптимизационную задачу классическими способами (через условия экстремума функции), то поиск решения будет противоречить основным законам математического анализа. Почему? Обсудим это в модулях по математике, когда будем решать оптимизационные задачи.\n",
    "\n",
    "<img src=ml2_img16.png>\n",
    "\n",
    "Математике известно решение данной задачи оптимизации. Метод поиска параметров линейной регрессии называется методом наименьших квадратов (сокращённо — `МНК`) и был изобретён **Гауссом** ещё в **1795 году**. В английской литературе часто можно встретить аббревиатуру `OLS` (`Ordinary Least Squares`).\n",
    "\n",
    ">Решать саму задачу поиска минимума функции мы сейчас не будем, так как пока что не владеем достаточными для её решения знаниями о частной производной и условиях экстремума функции многих переменных, но приведём финальный ответ, полученный для общего случая.\n",
    "\n",
    "Итак, пусть у нас есть матрица `X`, в которой по строкам собрано `n` наблюдений, а по столбцам отложено `m` факторов — по сути, это обычный, привычный нам `DataFrame`. К каждому примеру из таблицы `X` есть ответ `y`.\n",
    "\n",
    "Зависимость между факторами и целевым признаком принята линейной, то есть рассматривается обучение модели линейной регрессии:\n",
    "\n",
    "<img src=ml2_img17.png>\n",
    "\n",
    "Мы хотим найти наилучшую оценку для `w0`, `w1`, `w2`, ...m `w_m`.\n",
    "\n",
    ">Примечание. Для того чтобы конечная запись формулы была короче и можно было включить в вектор `w-` коэффициент смещения прямой `w0`, в матрицу `X` первым добавляют столбец, полностью состоящий из единиц. Это связано со спецификой матричного умножения, о котором мы поговорим далее в курсе.\n",
    "\n",
    "Согласно методу наименьших квадратов, аналитическое выражение для поиска вектора коэффициентов уравнения линейной регрессии имеет вид:\n",
    "\n",
    "<img src=ml2_img18.png>\n",
    "\n",
    "Саму процедуру обращения матриц мы будем рассматривать в модуле по линейной алгебре. Сейчас же для проведения этой операции мы будем использовать библиотеку numpy, которая позволяет очень быстро и просто обращать матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# АНАЛИТИЧЕСКОЕ РЕШЕНИЕ С ПОМОЩЬЮ NUMPY <a class=\"anchor\" id=2-1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Перейдём к практической части. Давайте научимся строить аналитическое решение линейной регрессии по `МНК` в `Python`.\n",
    "\n",
    "Вот какие этапы нам предстоит пройти, чтобы построить свою модель:\n",
    "\n",
    "1. Загрузить данные и проанализировать датасет на предмет пропусков.\n",
    "2. Подготовить данные для подачи в модель: избавиться от пропусков, если они есть, и перекодировать категориальные признаки, если они представлены текстом.\n",
    "3. Построить модель. Будем строить несколько моделей линейной регрессии: первую — на одном признаке, вторую — на всех доступные признаках.\n",
    "4. Оценить качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') #установка стиля matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с датасетом из библиотеки `sklearn` о домах в Бостоне. Этот набор данных содержит информацию, собранную службой переписи населения США и касающуюся жилья в районе Бостона, штат Массачусетс.\n",
    "\n",
    "Данный датасет содержится в модуле `datasets` библиотеки `sklearn`. Давайте загрузим датасет с помощью функции `load_boston()` и выведем его описание, обратившись по ключу `'DESCR'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном описании говорится, что у нас есть `506` участков с жилыми домами, которые описываются `13`-ю признаками. На каждом из участков находится несколько домов. Измерены общие показатели по каждому из участков, в том числе медианная стоимость.\n",
    "\n",
    "Задача — научить модель предсказывать медианную стоимость дома на участке.\n",
    "\n",
    "`CRIM` — уровень преступности на душу населения по городам.;\n",
    "`ZN` — доля земли под жилую застройку, разделённая на участки площадью более 25 000 кв. футов;\n",
    "`INDUS` — доля акров, которые принадлежат предприятиям, не связанным с розничной торговлей, на город;\n",
    "`CHAS` — фиктивная переменная реки Чарльз (1 — если участок прилегает к реке; 0 — в противном случае);\n",
    "`NOX` — концентрация оксидов азота (в десятимиллионных долях);\n",
    "`RM` — среднее количество комнат в доме;\n",
    "`AGE` —доля зданий, построенных до 1940 г. и занимаемых владельцами;\n",
    "`DIS` — взвешенные расстояния до пяти бостонских центров занятости;\n",
    "`RAD` — индекс доступности радиальных автомобильных дорог;\n",
    "`TAX` — полная ставка налога на имущество за каждые 10 000 долларов стоимости;\n",
    "`PTRATIO` — соотношение учеников и учителей по городам;\n",
    "`B` — 1000 (`Bk` — 0.63) , где `Bk` — доля граждан афроамериканского происхождения по городам;\n",
    "`LSTAT` — процент населения с низким статусом;\n",
    "`MEDV` — медианное значение стоимости домов, занимаемых владельцами, в тысячах долларов США (целевой признак).\n",
    "\n",
    "Составим `DataFrame` из наших данных. Для этого обратимся по ключу '`data`' к загруженным данным и получим numpy-массив, в котором содержится информация обо всех признаках, а по ключу '`feature_names`' содержатся названия признаков. Обратившись по ключу '`target`', можно получить numpy-вектор со значениями целевой переменной — медианной стоимости занимаемых домов (`MEDV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примечание. Модель линейной регрессии требует, чтобы в подаваемых ей на вход данных не было пропущенных значений. Поэтому если в ваших данных окажутся пропуски, обязательно заранее позаботьтесь о них (способы мы изучали в модуле по очистке данных).\n",
    "\n",
    "Итак, в наших данных нет пропусков, а значит их можно подавать в модель, чтобы обучить её предсказывать целевой признак (признак MEDV).\n",
    "\n",
    ">Также модель не умеет работать с категориальными признаками, представленными в виде типа `object`. Прежде чем подавать в модель линейной регрессии категориальные признаки, необходимо произвести кодировку категорий с помощью уже знакомых вам методов кодирования.\n",
    "\n",
    "Давайте начнём с простого. Построим линейную регрессию на одном признаке. Выберем признак, который имеет наиболее высокую линейную взаимосвязь. Для этого рассчитаем корреляцию признаков с целевой переменной и выберем наиболее влиятельный.\n",
    "\n",
    "Для лучшего восприятия давайте построим столбчатую диаграмму для модульного значения корреляций:\n",
    "\n",
    ">Примечание. Мы могли визуализировать матрицу корреляций, однако сейчас нас интересует только связь факторов с целевым признаком, поэтому нагляднее будет воспользоваться столбчатой диаграммой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Вычисляем модуль корреляции\n",
    "corr_with_target = boston_data.corr()['MEDV'].abs().sort_values()\n",
    "#Удаляем корреляцию целевой переменной с самой собой\n",
    "corr_with_target = corr_with_target.drop('MEDV')\n",
    "#Строим столбчатую диаграмму корреляций\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) #фигура+координатная плоскость\n",
    "ax.bar(corr_with_target.index, corr_with_target.values) #столбчатая диаграмма\n",
    "ax.set_title('Correlations with target') #название графика\n",
    "ax.set_xlabel('Feature') #название оси x\n",
    "ax.set_ylabel('Сorrelation coefficient'); #название оси y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, самый коррелированный по модулю с медианной ценой (MEDV) признак — процент населения с низким статусом (LSTAT). Давайте построим линейную регрессию, используя этот признак.\n",
    "\n",
    ">Примечание. Построить линейную регрессию = обучить линейную регрессию = найти её параметры.\n",
    "\n",
    "Вспоминаем нашу формулу аналитического решения по методу наименьших квадратов:\n",
    "\n",
    "<img src=ml2_img19.png>\n",
    "\n",
    "Что есть `X` и `y`? Это матрица из примеров (матрица наблюдений) и вектор правильных ответов к ним соответственно. У нас матрица `X` — это таблица, состоящая из одного столбца (`LSTAT`), а `y` — столбец с медианными ценами (`MEDV`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LSTAT\n",
       "0   4.98\n",
       "1   9.14\n",
       "2   4.03\n",
       "3   2.94\n",
       "4   5.33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов\n",
    "X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примечание. Двойные квадратные скобки `boston_data[['LSTAT']]` позволяют выбрать признак из `DataFrame`, сохранив его в виде таблицы. Это важно, так как в формуле `МНК`  — это матрица.\n",
    "\n",
    "У нас есть все компоненты формулы, чтобы найти параметры модели. Давайте напишем функцию `linear_regression()`, в которой реализуем вычисления коэффициентов. Аргументами функции будут матрица наблюдений `X` и вектор ответов `y`, а возвращать она будет вектор параметров `w`.\n",
    "\n",
    "Матричные вычисления легче всего реализовать через библиотеку `numpy`.\n",
    "\n",
    "Для начала вспомним, что для вычисления свободного члена `w0` необходимо добавить в таблицу столбец, полностью состоящий из единиц. Такой столбец можно создать с помощью знакомой нам функции [ones()](https://numpy.org/doc/stable/reference/generated/numpy.ones.html) из библиотеки `numpy`, а присоединить его к таблице `X` поможет функция [column_stack()](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html).\n",
    "\n",
    "Матричное умножение в numpy реализуется с помощью оператора `@`. Транспонирование осуществляется через `.T`, а обратная матрица вычисляется с помощью функции [inv()](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html) из модуля `linalg` (модуля для линейной алгебры)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    #Создаём вектор из единиц\n",
    "    ones = np.ones(X.shape[0])\n",
    "    #Добавляем вектор к таблице первым столбцом\n",
    "    X = np.column_stack([ones, X])\n",
    "    #Вычисляем обратную матрицу Q\n",
    "    Q = np.linalg.inv(X.T @ X)\n",
    "    #Вычисляем вектор коэффициентов\n",
    "    w = Q @ X.T @ y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только вызвать нашу функцию и передать в неё нашу таблицу примеров `X` и столбец правильных ответов `y`. Вычислим вектор параметров и выведем его на экран:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector w: [34.55384088 -0.95004935]\n",
      "w0: 34.55\n",
      "w1: -0.95\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем параметры линейной регрессии\n",
    "w = linear_regression(X, y)\n",
    "#Выводим вычисленные значения параметров в виде вектора\n",
    "print('Vector w: {}'.format(w))\n",
    "#Выводим параметры с точностью до двух знаков после запятой\n",
    "print('w0: {:.2f}'.format(w[0]))\n",
    "print('w1: {:.2f}'.format(w[1]))\n",
    "# Vector w: [34.55384088 -0.95004935]\n",
    "# w0: 34.55\n",
    "# w1: -0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили значения коэффициентов уравнения прямой. С точностью до сотых они равны:\n",
    "\n",
    "`w0 = 34.55`\n",
    "\n",
    "`w1 = -0.95`\n",
    "\n",
    "А значит сама модель будет иметь вид:\n",
    "\n",
    "`y = 34.55 - 0.95x1`\n",
    "\n",
    "Самое приятное в модели линейной регрессии — то, что её коэффициенты можно проинтерпретировать. \n",
    "\n",
    "Коэффициент `w0 = 34.55` имитирует влияние сторонних факторов, которые не учтены в модели. Это значение медианной цены домов на участке, если бы значение процента населения с низким статусом было равно `0`. \n",
    "\n",
    "Коэффициент `w1 = -0.95` означает, на сколько в среднем изменится медианная цена (в тысячах долларов) при увеличении низкостатусного населения на 1 единицу. То есть если количество низкостатусного населения увеличится на `1 %`, то медианная цена зданий на участке упадёт на `0.95` тысяч долларов. Можно сказать, что каждый новый процент низкостатусного населения уменьшает медианную цену на `0.95` тысяч долларов.\n",
    "\n",
    "Теперь, если в данных появится новый участок Бостона с известной долей низкостатусного населения, мы сможем предсказать значение медианной стоимости домов простой подстановкой значений в модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 29.63\n"
     ]
    }
   ],
   "source": [
    "#Задаём процент низкостатусного населения\n",
    "x_example = 5.18 \n",
    "#Делаем предсказание\n",
    "y_predict = w[0] + w[1] * x_example\n",
    "print('Predicted value: {:.2f}'.format(float(y_predict)))\n",
    "#Predicted value: 29.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы работаем с одним фактором, то можем построить визуализацию нашей модели.\n",
    "\n",
    "Давайте напишем функцию `plot_regression_2d()`, у которой будет три обязательных аргумента (матрица наблюдений `X`, столбец правильных ответов `y` и столбец с предсказаниями модели `y_pred`) и два аргумента по умолчанию (`xlabel` — подпись оси абсцисс и `ylabel` — подпись оси ординат)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_2d(X, y_true, y_predict, xlabel='LSTAT', ylabel='MEDV'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) #фигура + координатная плоскость\n",
    "    ax.scatter(X, y_true, alpha=0.7, label='Sample data') #диаграмма рассеяния\n",
    "    ax.plot(X, y_predict, color='black', label='Regression model') #линейный график\n",
    "    ax.set_xlabel(xlabel) #название оси абсцисс\n",
    "    ax.set_ylabel(ylabel) #название оси ординат\n",
    "    ax.legend(facecolor='white', fontsize=11) #легенда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание для всех объектов из таблицы `X`, подставив её в модель линейной регрессии с найденными параметрами, и построим график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 27\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_predict \u001b[39m=\u001b[39m w[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m w[\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m X\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Строим визуализацию\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plot_regression_2d(X, y, y_predict)\n",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 27\u001b[0m in \u001b[0;36mplot_regression_2d\u001b[1;34m(X, y_true, y_predict, xlabel, ylabel)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m4\u001b[39m)) \u001b[39m#фигура + координатная плоскость\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax\u001b[39m.\u001b[39mscatter(X, y_true, alpha\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSample data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#диаграмма рассеяния\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax\u001b[39m.\u001b[39;49mplot(X, y_predict, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblack\u001b[39;49m\u001b[39m'\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRegression model\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#линейный график\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ax\u001b[39m.\u001b[39mset_xlabel(xlabel) \u001b[39m#название оси абсцисс\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ax\u001b[39m.\u001b[39mset_ylabel(ylabel) \u001b[39m#название оси ординат\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[39m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    488\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSupport for multi-dimensional indexing\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[39m=\u001b[39m x[:, \u001b[39mNone\u001b[39;49;00m]\u001b[39m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[39m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[39m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3629\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Делаем предсказание для всех объектов из таблицы\n",
    "y_predict = w[0] + w[1] * X\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, прямая является убывающей (коэффициент `w1 < 0`), и, если её продолжить влево, она пересечётся с осью ординат в точке `w0 = 34.55`. \n",
    "\n",
    ">Итак, мы воспользовались формулой для МНК алгоритма и нашли параметры модели линейной регрессии «вручную», реализовав формулу в виде функции. Отметим, что наша функция универсальна: в неё можно подавать не только матрицу  с одним признаком (LSTAT), но и таблицу, содержащую все признаки, описывающие участки.\n",
    ">\n",
    ">Конечно же, никто не строит линейную регрессию «руками», используя формулу МНК. Все дата-сайентисты пользуются библиотеками, такими как sklearn. Давайте посмотрим на реализацию ↓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# АНАЛИТИЧЕСКОЕ РЕШЕНИЕ С ПОМОЩЬЮ SKLEARN <a class=\"anchor\" id=2-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Алгоритм построения модели реализован в библиотеке машинного обучения `sklearn` и находится в модуле `linear_model`. Давайте импортируем этот модуль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модуле находится класс [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), который реализует аналитическое решение линейной регрессии. Для обучения модели необходимо просто вызвать метод `fit()`, передав в него матрицу наблюдений `X` и вектор правильных ответов `y`.\n",
    "\n",
    "Данный метод реализует формулу **метода наименьших квадратов** и рассчитает параметры модели самостоятельно. Чтобы получить свободный член `w0` нужно обратиться по атрибуту `intercept_`, а вектор параметров `w1, w2, ..., w_m` будет храниться в атрибуте `coef_` (так как у нас один фактор в матрице `X`, то и коэффициент будет только один):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: 34.55384087938311\n",
      "w1: [-0.95004935]\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_lstat = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_lstat.fit(X, y)\n",
    " \n",
    "print('w0: {}'.format(lr_lstat.intercept_)) #свободный член w0\n",
    "print('w1: {}'.format(lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm\n",
    " \n",
    "# w0: 34.55384087938311\n",
    "# w1: [-0.95004935]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примечание. Обратите внимание, что мы получили ровно те же самые значения для параметров модели, что является вполне ожидаемым, ведь метод `fit()` у объекта `LinearRegression` реализует ту же самую формулу `МНК`, которую мы прописали в функции `linear_regression()`. Интерпретация коэффициентов остаётся той же.\n",
    "\n",
    "Модель обучена. А как сделать предсказание? Вручную записывать выражение для модели и подставлять коэффициенты? Конечно же, нет. Для этого есть метод `predict()`. В него необходимо передать матрицу наблюдений, для которых нужно сделать предсказание.\n",
    "\n",
    "Давайте сделаем предсказание для всех наших наблюдений из таблицы `X` и визуализируем результат с помощью нашей функции `plot_regression_2d()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 34\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_predict \u001b[39m=\u001b[39m lr_lstat\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Строим визуализацию\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plot_regression_2d(X, y, y_predict)\n",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 34\u001b[0m in \u001b[0;36mplot_regression_2d\u001b[1;34m(X, y_true, y_predict, xlabel, ylabel)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m4\u001b[39m)) \u001b[39m#фигура + координатная плоскость\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax\u001b[39m.\u001b[39mscatter(X, y_true, alpha\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSample data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#диаграмма рассеяния\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax\u001b[39m.\u001b[39;49mplot(X, y_predict, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblack\u001b[39;49m\u001b[39m'\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRegression model\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#линейный график\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ax\u001b[39m.\u001b[39mset_xlabel(xlabel) \u001b[39m#название оси абсцисс\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ax\u001b[39m.\u001b[39mset_ylabel(ylabel) \u001b[39m#название оси ординат\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[39m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    488\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSupport for multi-dimensional indexing\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[39m=\u001b[39m x[:, \u001b[39mNone\u001b[39;49;00m]\u001b[39m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[39m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[39m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3629\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "y_predict = lr_lstat.predict(X)\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем тот же самый график, что мы видели ранее, когда реализовывали линейную регрессию вручную.\n",
    "\n",
    "А что, если мы хотим построить линейную регрессию, используя всю предоставленную информацию, то есть все `13` признаков? Не проблема! Нужно только расширить матрицу наблюдений `X`, добавив в неё остальные признаки и снова обучить модель `LinearRegression`.\n",
    "\n",
    "Давайте выберем из таблицы `boston` все столбцы, исключая столбец с целевой переменной (`MEDV`). Полученную матрицу `X` и вектор правильных ответов y отправляем в метод `fit()`, чтобы произвести подгонку и найти параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.108011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.046420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.020559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>2.686734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-17.766611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>3.809865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-1.475567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>0.306049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-0.012335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-0.952747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.009312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-0.524758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>36.459488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM     -0.108011\n",
       "1          ZN      0.046420\n",
       "2       INDUS      0.020559\n",
       "3        CHAS      2.686734\n",
       "4         NOX    -17.766611\n",
       "5          RM      3.809865\n",
       "6         AGE      0.000692\n",
       "7         DIS     -1.475567\n",
       "8         RAD      0.306049\n",
       "9         TAX     -0.012335\n",
       "10    PTRATIO     -0.952747\n",
       "11          B      0.009312\n",
       "12      LSTAT     -0.524758\n",
       "13  INTERCEPT     36.459488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': lr_full .coef_})\n",
    "#Составляем строку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': lr_full .intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили таблицу с признаками из нашего набора данных и коэффициентами, которые им соответствуют.\n",
    "\n",
    "Каждый из коэффициентов в модели показывает, на сколько в среднем (согласно модели) изменится медианная цена (в тысячах долларов) при увеличении параметра на единицу. Например, если уровень преступности увеличится на один пункт, то медианная цена зданий на участке упадёт на 0.1 тыс. долларов. А вот увеличение среднего количества комнат на участке (RM) на одну единицу повысит медианную цену на 3.8 тыс. долларов.\n",
    "\n",
    ">Свободный член (`INTERCEPT`) всё так же имитирует влияние внешних факторов и носит смысл «поправки» модели относительно медианной стоимости.\n",
    "\n",
    "Итак, мы с вами построили две модели линейной регрессии: `lr_lstat` на одном признаке (`LSTAT`) и `lr_full` — на всех признаках в данных. Хотелось бы сравнить эти модели по их качеству. Может, нам достаточно только знаний о проценте низкостатусного населения, чтобы предсказать медианную цену?\n",
    "\n",
    "Самая простая идея — визуализировать ошибки. Давайте построим коробчатые диаграммы ошибок моделей. Ошибки будем считать по формуле:\n",
    "\n",
    "`error_i = y_i - y^`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем ошибки\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) #фигура + координатная плоскость\n",
    "#Ошибки модели на одном факторе LSTAT\n",
    "y_errors_lstat = y - lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Ошибки модели на всех факторах\n",
    "y_errors_full = y - lr_full.predict(boston_data[features])\n",
    "#Для удобства визуализации составим DataFrame из ошибок\n",
    "errors_df = pd.DataFrame(\n",
    "    {'LSTAT_predict': y_errors_lstat, \n",
    "     'Full_factors_predict': y_errors_full\n",
    "    }\n",
    ")\n",
    "#Строим boxplot для ошибок\n",
    "sns.boxplot(data=errors_df, orient='h', ax=ax)\n",
    "ax.set_xlabel('Model errors') #название оси абсцисс\n",
    "ax.set_ylabel('Model'); #название оси ординат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из построенных диаграмм ошибок видно, что разброс ошибок для модели, построенной на всех признаках, ниже (ящик уже и усы короче), и медиана ошибки также более приближена к `0`. То есть можно сказать, что **визуально качество второй модели выглядит лучше**.\n",
    "\n",
    "На обеих диаграммах присутствуют точки, сильно выбивающиеся за пределы усов. Это наблюдения, для которых модель допустила очень большую ошибку, по сравнению с основной группой.\n",
    "\n",
    "Можно предположить, что это объекты, для которых гипотеза о линейной зависимости несправедлива, и линейной модели не хватает для предсказания целевой переменной для таких объектов. О том, как справиться с этой проблемой, мы поговорим чуть позже.\n",
    "\n",
    "Визуализация — это, конечно, хорошо, но, согласитесь, не очень удобно: визуализация не даёт конкретики — только общие представления об ошибках.\n",
    "\n",
    "Может быть, есть способ описать качество модели каким-то конкретным числом? Да. Этот показатель называется **`метрикой`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.35114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>6.041</td>\n",
       "      <td>49.9</td>\n",
       "      <td>4.7211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.9</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.35114  0.0   7.38   0.0  0.493  6.041  49.9  4.7211  5.0  287.0     19.6   \n",
       "\n",
       "       B  LSTAT  \n",
       "0  396.9    7.7  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Новые данные\n",
    "new_data = pd.DataFrame({'CRIM':[0.35114],\n",
    "                         'ZN':[0.00000],\n",
    "                         'INDUS':[7.38000],\n",
    "                         'CHAS':[0.00000],\n",
    "                         'NOX':[0.49300],\n",
    "                         'RM':[6.04100],\n",
    "                         'AGE':[49.90000],\n",
    "                         'DIS':[4.72110],\n",
    "                         'RAD':[5.00000],\n",
    "                         'TAX':[287.00000],\n",
    "                         'PTRATIO':[19.60000],\n",
    "                         'B':[396.90000],\n",
    "                         'LSTAT':[7.70000]})\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.86952447])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предсказания по новым данным\n",
    "lr_full.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <td>50122.192990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <td>0.805715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administration</th>\n",
       "      <td>-0.026816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marketing Spend</th>\n",
       "      <td>0.027228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "w0               50122.192990\n",
       "R&D Spend            0.805715\n",
       "Administration      -0.026816\n",
       "Marketing Spend      0.027228"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('50_Startups.zip')\n",
    "\n",
    "def linear_regression(X, y):\n",
    "    #Создаём вектор из единиц\n",
    "    ones = np.ones(X.shape[0])\n",
    "    #Добавляем вектор к таблице первым столбцом\n",
    "    X = np.column_stack([ones, X])\n",
    "    #Вычисляем обратную матрицу Q\n",
    "    Q = np.linalg.inv(X.T @ X)\n",
    "    #Вычисляем вектор коэффициентов\n",
    "    w = Q @ X.T @ y\n",
    "    return w\n",
    "\n",
    "w = linear_regression(data.drop(['State', 'Profit'], axis=1), data['Profit'])\n",
    "coef = pd.DataFrame(w, index=list(data.drop(['State', 'Profit'], axis=1).columns.insert(0, 'w0')))\n",
    "coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Метрики регрессии. Недостатки аналитического решения <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    ">**`Метрика`** — это численное выражение качества моделирования.\n",
    "\n",
    "Для оценки качества решения задачи регрессии существует множество метрик. Давайте рассмотрим самые основные и часто используемые.\n",
    "\n",
    "## МЕТРИКИ РЕГРЕССИИ\n",
    "\n",
    "Будем рассматривать метрики для задачи регрессии на следующем примере. Возьмём первые пять наблюдений из нашей таблицы и предсказанные для них моделью `lr_full` ответы:\n",
    "\n",
    "`y = (24.0, 21.6, 34.7, 33.4, 36.2)`\n",
    "\n",
    "`y^ = (29.82, 25.87, 30.73, 31.76, 29.49)`\n",
    "\n",
    "На этих значениях мы будем рассматривать следующие метрики:\n",
    "\n",
    "## 1. Средняя абсолютная ошибка — `MAE` (Mean Absolute Error)\n",
    "\n",
    "Это самый простой и уже знакомый вам показатель. Чтобы посчитать данную метрику, нужно найти все остатки (разницы между предсказанным значением и реальным), взять от каждого из них модуль, сложить их и поделить на количество. Иными словами, нам нужно найти среднее арифметическое модуля отклонения предсказанного значения от реального.\n",
    "\n",
    "<img src=ml2_img20.png>\n",
    "\n",
    "То есть для нашего примера из пяти наблюдений в среднем модель ошибается на `4.482` тысячи долларов.\n",
    "\n",
    "Много ли это? Хороший вопрос, на который без эксперта-оценщика недвижимости будет сложно дать ответ. Однако можно попробовать посчитать ошибку в процентах, ведь в процентах всё воспринимается легче, и для этого нам пригодится следующая метрика — MAPE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Средняя абсолютная ошибка в процентах — `MAPE` (Mean Absolute Percent Error)\n",
    "\n",
    "Для её вычисления мы делим модуль разницы между предсказанием алгоритма и истинным значением на истинное значение. Затем складываем все результаты (для каждого объекта), делим на количество и умножаем на 100 %.\n",
    "\n",
    "\n",
    "<img src=ml2_img21.png>\n",
    "\n",
    "Таким образом, на первых пяти наблюдениях модель в среднем ошибается на `15.781 %`. Это довольно неплохой результат.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Средняя квадратическая ошибка — `MSE`\n",
    "\n",
    "Данный показатель мы используем в линейной регрессии в качестве функции потерь, но ничто не мешает нам также использовать его и в качестве метрики.\n",
    "\n",
    "Логика вычисления данной ошибки очень похожа на предыдущую. Разница лишь в том, что вместо модуля разности между предсказанным и реальным значениями мы берём квадрат этого модуля:\n",
    "\n",
    "<img src=ml2_img22.png>\n",
    "\n",
    "Таким образом, для нашего примера квадрат отклонения составляет `22.116` тысяч долларов в квадрате.\n",
    "\n",
    "Согласитесь, не очень понятно, о чём идет речь. Однако данная метрика является популярной, так как позволяет `«штрафовать»` модель за очень большие ошибки.\n",
    "\n",
    ">Что значит `«штрафовать»`? \n",
    ">\n",
    ">Например, расхождение в `200` единиц в метрике `MSE` воспринимается как `200^2`, а в метрике `MAE` это расхождение воспринимается как `200`. Поэтому, если у нас есть две модели, но одна из них допускает большие ошибки, эти ошибки становятся ещё больше при расчёте метрики `MSE`, и нам легче сравнить модели между собой.\n",
    ">\n",
    ">Но в то же время это и проклятие `MSE`. Если в данных присутствуют выбросы, метрика может быть необъективной. Если модель будет утверждать, что цена здания — `30 тысяч долларов`, а в наборе данных ему соответствует цена в `3 миллиона долларов`, то при возведении такой ошибки в квадрат получится `9 миллионов`, что может сбить с толку исследователя. Необходимо скептически относиться к данной метрике, если вы не проводили исследование данных на предмет наличия выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Корень из средней квадратической ошибки — RMSE (Root Mean Squared Error)\n",
    "\n",
    "Для получения `RMSE` надо просто извлечь квадратный корень из `MSE`:\n",
    "\n",
    "<img src=ml2_img24.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Коэффициент детерминации (R^2)\n",
    "\n",
    "Все рассматриваемые ранее метрики имели масштаб от `0` до `+∞`. Чем это плохо?\n",
    "\n",
    "А что если нам скажут, что `MSE` для модели составляет `32`? Должны ли мы улучшить модель, или она достаточно хороша? А что если `MSE = 0.4`?\n",
    "\n",
    "На самом деле, трудно понять, хороша модель или нет, не сравнив её показатели с теми же показателями других моделей.\n",
    "\n",
    "Коэффициент детерминации, или `R^2`, является ещё одним показателем, который мы можем использовать для оценки модели. Он тесно связан с `MSE`, но его преимущество в том, что `R^2` всегда находится в промежутке между `-∞` и `1`.\n",
    "\n",
    "<img src=ml2_img25.png>\n",
    "\n",
    "Есть ещё одна интерпретация данной метрики. Статистически показатель `R^2` описывает, какую долю информации о зависимости (дисперсии) смогла уловить модель.\n",
    "\n",
    "Удовлетворительным `R^2` считается показатель выше `0.5`: чем ближе к `1`, тем лучше. Отрицательные значения `R^2` говорят о том, что построенная модель настолько плоха, что лучше было бы присвоить **всем ответам среднее значение**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим всё вышесказанное в виде таблицы:\n",
    "\n",
    "<img src=ml2_img26.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## РАСЧЁТ МЕТРИК НА PYTHON <a class=\"anchor\" id=3-1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Настало время проверить качество построенных нами ранее моделей линейной регрессии: `lr_lstat` и `lr_full`.\n",
    "\n",
    "Весь набор функций для вычисления метрик в `sklearn` находится в модуле [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Давайте его импортируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, которые нам понадобятся:\n",
    "\n",
    "* `mean_absolute_error()` — расчёт `MAE`;\n",
    "* `mean_square_error()` — расчёт `MSE`;\n",
    "* `mean_absolute_percentage_error()` — расчёт `MAPE`;\n",
    "* `r2_score()` — расчёт коэффициента детерминации `R^2`.\n",
    "\n",
    "В каждую из функций достаточно передать правильные ответы и предсказания, и функция вернёт рассчитанную метрику.\n",
    "\n",
    ">Примечание. Для расчёта метрики `RMSE` нет специальной функции, однако мы знаем, что для её расчёта достаточно извлечь квадратный корень из MSE.\n",
    ">\n",
    ">Из-за особенностей реализации функция `mean_absolute_percentage_error()` возвращает результат не в процентах, а в долях. Чтобы отобразить результат в процентах, необходимо умножить его на `100`.\n",
    "\n",
    "Давайте вычислим метрики и выведем их на экран, округлив до третьего знака после запятой. Начнём с модели `lr_lstat`: сделаем предсказание на основании признака `LSTAT` и передадим истинные и предсказанные медианные цены в функции для расчёта метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 4.505 k$\n",
      "RMSE score: 6.203 k$\n",
      "MAPE score: 21.352 %\n",
      "R2 score: 0.544\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по признаку LSTAT\n",
    "y_predict_lstat = lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} k$'.format(metrics.mean_absolute_error(y, y_predict_lstat)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} k$'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_lstat))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_lstat) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_lstat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделываем ту же самую операцию для второй модели линейной регрессии, `lr_full`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.271 k$\n",
      "RMSE score: 4.679 k$\n",
      "MAPE score: 16.417 %\n",
      "R2 score: 0.741\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по всем признакам\n",
    "y_predict_full = lr_full.predict(boston_data[features])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} k$'.format(metrics.mean_absolute_error(y, y_predict_full)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} k$'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_full))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные результаты:\n",
    "\n",
    "* `MAE`: в среднем первая модель ошибается на  `4.505` тыс. долларов, а вторая — на `3.271` тыс. долларов.\n",
    "* `RMSE`: среднеквадратичное отклонение первой модели от истинных ответов составляет `6.203` тыс. долларов, а второй — `4.679`.\n",
    "* `MAPE`: первая модель ошибается на `21.352 %`, а вторая — на `16.417 %`.\n",
    "* `R^2`: доля объясняемой информации (дисперсии), которую улавливает первая модель, — `0.544`, а вторая — `0.741`.\n",
    "Очевидно, что по всем метрикам вторая модель, построенная на основе всех признаков в данных, превосходит первую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕДОСТАТКИ АНАЛИТИЧЕСКОГО РЕШЕНИЯ <a class=\"anchor\" id=3-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Ранее мы с вами рассмотрели, что такое модель линейной регрессии, и научились рассчитывать её параметры с помощью аналитического подхода — метода наименьших квадратов.\n",
    "\n",
    "<img src=ml2_img27.png>\n",
    "\n",
    "Метод наименьших квадратов позволяет очень просто получить коэффициенты, подставив таблицу в формулу. Вот, собственно, и всё «обучение». \n",
    "\n",
    ">Существует теорема [Гаусса-Маркова](https://ru.wikipedia.org/wiki/Теорема_Гаусса_—_Маркова), которая говорит о том, что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров. Мы ещё вернемся к этой теореме, когда будем говорить об МНК в модулях по линейной алгебре.\n",
    "\n",
    "Казалось бы, относительно простая математика: надо всего лишь перемножить матрицы между собой и получить ответ. Особенно простой эта задача должна быть для компьютера. Но нам так кажется, поскольку мы ранее не сталкивались с матричным умножением и будем говорить о нём только в модулях по линейной алгебре.\n",
    "\n",
    ">Оказывается, у такого простого подхода есть один большой минус — это работа с **большим количеством признаков**.\n",
    "\n",
    "Давайте внимательно посмотрим на операцию обращения матриц (возведение в степень -1):\n",
    "\n",
    "<img src=ml2_img28.png>\n",
    "\n",
    "Обращение матриц больших размеров может стать очень трудоёмким процессом при работе с большими объёмами данных.\n",
    "\n",
    ">Второй недостаток МНК — это невозможность инкрементального обучения, или обучения в режиме реального времени.\n",
    "\n",
    "**Что это такое?**\n",
    "\n",
    "Представьте, что мы построили модель, но собираемся её уточнять в процессе эксплуатации. К нам приходят всё новые данные, и мы должны изменять параметры модели, подстраиваясь под новые зависимости.\n",
    "\n",
    "Если мы используем метод `fit()` для модели `LinearRegression` и передадим в него новые данные, то коэффициенты модели будут рассчитаны по новым данным, а прошлые наблюдения будут забыты. То есть придётся добавлять данные в таблицу и переобучать модель на всех доступных данных ещё раз.\n",
    "\n",
    ">Первая и вторая проблемы решаются с помощью замены аналитического МНК на численные методы, такие как градиентный спуск.\n",
    ">\n",
    ">Третий недостаток МНК больше теоретический и заключается в том, что матрица `Q` в результате вычислений может **не существовать**. Это связано с математическими особенностями вычисления обратной матрицы, которые мы рассмотрим далее в курсе. \n",
    ">\n",
    ">Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). Из-за этого коэффициенты линейной регрессии становятся слишком большими и модель становится неустойчивой. \n",
    ">\n",
    ">**Проблема решается с помощью `регуляризации`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Линейная регрессия. Числовые решения <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "В самом простом двумерном случае мы пытаемся найти такие коэффициенты  уравнения прямой `w0` и `w1`, чтобы средний квадрат ошибки (`MSE`) был минимален.\n",
    "\n",
    "<img src=ml2_img29.png>\n",
    "\n",
    "Гауссу удалось найти общее решение для этой оптимизационной задачи и вывести формулу метода наименьших квадратов для поиска коэффициентов.\n",
    "\n",
    "Но можно пойти другим путём, не аналитическим (вывод формулы «в лоб»), а численным (итерационное приближение функции к минимуму).\n",
    "\n",
    "Самым популярным численным методом оптимизации, используемым в машинном обучении, является алгоритм градиентного спуска.\n",
    "\n",
    ">Градиентный спуск (`Gradient descent`) — самый используемый [алгоритм](https://neurohive.io/ru/osnovy-data-science/gradient-descent/) минимизации функции потерь. Он применяется почти в каждой модели машинного обучения и является наиболее простым в реализации из всех методов численной оптимизации.\n",
    "\n",
    "С градиентным спуском мы будем детально знакомиться в модулях по оптимизации и даже реализуем его своими руками. Сейчас же нам важно усвоить принцип работы, чтобы понимать, какими параметрами алгоритма мы можем управлять при его использовании в коде.\n",
    "\n",
    "Начнём обзор алгоритма немного издалека.\n",
    "\n",
    "Представим, что мы находимся на некоторой холмистой местности и нам надо добраться до самой низкой точки, но делаем мы это вслепую, то есть не знаем сам ландшафт. Назовём эту точку целью.\n",
    "\n",
    "<img src=ml2_img30.png>\n",
    "\n",
    "Давайте опишем, как мы будем искать эту точку. Для начала необходимо задать начальную точку, из которой мы, собственно, стартуем. Далее мы двигаемся в сторону крутизны склона. Если склон круче справа, надо сделать шаг вправо, если склон круче слева, надо сделать шаг влево. Повторяем шаги до тех пор, пока не достигнем самой низкой точки.\n",
    "\n",
    "У вас мог возникнуть вопрос: как определить, что мы достигли цели — самой низкой точки? В этой точке крутизна склона с обеих сторон равна 0 или близка к нему (ровная поверхность). Можно использовать эту информацию как точку остановки нашего алгоритма.\n",
    "\n",
    "Описанный нами алгоритм можно перевести на язык математики. Он то и будет называться алгоритмом **градиентного спуска**.\n",
    "\n",
    "Наша функция потерь, которая зависит от параметров модели, — это аналогия ландшафта местности. Пространство, в котором находится ландшафт, — это пространство параметров нашей модели. То есть это система координат, в которой по осям отложены все возможные значения параметров.\n",
    "\n",
    "В двумерном случае, когда есть только один параметр, от которого зависит функция потерь, можно построить график функции потерь. Например, для `MSE`, зависящей от одного параметра, график будет иметь вид параболы:\n",
    "\n",
    "<img src=ml2_img31.png>\n",
    "\n",
    "Если параметров не один, а два, то функция потерь будет графически представлена в виде поверхности в трёхмерном пространстве. Ниже приведён пример такой поверхности и её вид сверху в виде концентрических кругов:\n",
    "\n",
    "<img src=ml2_img32.png>\n",
    "\n",
    ">В общем случае, когда у нас больше параметров модели, мы будем работать в многомерном пространстве. Но в этом нет ничего страшного. Суть поиска минимума от этого не меняется, меняется только сложность функции — структуры ландшафта.\n",
    "\n",
    "Для линейной регрессии необходимо найти в этом пространстве такие координаты `w0`, `w1`, ... ,`w_m` в которых находится минимум функции потерь.\n",
    "\n",
    "Как же нам понять, в какую сторону двигаться? Что будет отвечать за направление крутизны склона? На этот вопрос нам ответит математический анализ. В теории анализа функций, зависящих от нескольких переменных, существует понятие градиента.\n",
    "\n",
    "Математически градиент — это вектор, который состоит из частных производных по параметрам функции.\n",
    "\n",
    "Он записывается следующим образом:\n",
    "\n",
    "<img src=ml2_img33.png>\n",
    "\n",
    "Пусть пока что математическая формализация градиента нам непонятна, но нам важно отметить его ключевую особенность.\n",
    "\n",
    ">Градиент — это вектор, который показывает направление наискорейшего роста функции, а его длина — это само значение скорости функции в точке.\n",
    "\n",
    "Если вновь обратиться к примеру с холмами, градиент показывает, с какой скоростью и в каком направлении нужно двигаться из текущей точки, чтобы достичь более высшей точки.\n",
    "\n",
    ">А теперь время фокусов. Если поставить перед градиентом знак минус `-L(w)`, то мы получим вектор `антиградиента`, который показывает в сторону наискорейшего убывания функции потерь!.\n",
    "\n",
    "В случае одного параметра:\n",
    "\n",
    "<img src=ml2_img34.png>\n",
    "\n",
    "В случае двух параметров:\n",
    "\n",
    "<img src=ml2_img35.png>\n",
    "\n",
    "А это и есть то, что нам нужно. С помощью этого знания мы сможем вычислять следующую координату в пространстве — следующую точку, которую нам нужно посетить, чтобы дойти до цели — минимума функции.\n",
    "\n",
    "Формально это записывается следующим образом (формулу запоминать не нужно):\n",
    "\n",
    "<img src=ml2_img36.png>\n",
    "\n",
    "Отдельное внимание стоит уделить коэффициенту `n` (читается как `«эта»`). Это поправочный коэффициент, который носит название темп обучения (`learning rate`).\n",
    "\n",
    "`Темп обучения` — это основной параметр алгоритма. Он определяет то, насколько сильно мы будем двигать точку. В аналогии с нашим примером с движением по холмам можно сказать, что это коэффициент, обратный сопротивлению ландшафта, по которому мы движемся.\n",
    "\n",
    "Управляя данным параметром (уменьшая и увеличивая его), мы управляем скоростью движения к точке минимума. Чем больше темп обучения, тем длиннее наши шаги и тем быстрее мы движемся, и наоборот. О том, зачем этот параметр нужен и как выбирать значение , мы поговорим чуть позже.\n",
    "\n",
    ">**Примечание**. Темп обучения является примером внешнего параметра алгоритма, которым может управлять пользователь. Такие параметры ещё называют **гиперпараметрами**.\n",
    "\n",
    "Есть ещё одно важное свойство градиента: теоретически в точке минимума длина вектора равна 0, то есть движения не происходит. Это свойство мы можем использовать в качестве критерия остановки нашего алгоритма.\n",
    "\n",
    "<img src=ml2_img37.png>\n",
    "\n",
    "Теперь у нас есть все компоненты, чтобы составить алгоритм для обучения модели линейной регрессии методом градиентного спуска. Для простоты возьмём случай, когда мы строим регрессию на основе только одного признака.\n",
    "\n",
    "Для начала вспомним, как выглядит вид модели линейной регрессии, когда у нас есть только один фактор:\n",
    "\n",
    "`y = w0 + w1 * x`\n",
    "\n",
    "У нас есть набор значений фактора `x = (x1, x2, ..., x_m)` и столбец с правильными ответами `y = (y1, y2, ..., y_m)`. Мы пытаемся найти такие коэффициенты прямой, чтобы ошибка предсказания была минимальной. \n",
    "\n",
    "Алгоритм градиентного спуска для такой модели будет выглядеть следующим образом: \n",
    "\n",
    "* 1. Проинициализировать значения параметров `w0`, `w1`. \n",
    "\n",
    "На аналогии наших холмов это будет означать выбор начальной точки в пространстве, из которой мы будем двигаться.\n",
    "\n",
    "Правильная инициализация параметров — это отдельная история. Например, можно инициализировать все параметры нулями или случайными значениями.\n",
    "\n",
    "* 2. Повторять до тех пор, пока длина градиента не приблизится к `0`.\n",
    "\n",
    "На практике полного равенства градиента нулю достичь невозможно из-за численных вычислений, поэтому в качестве остановки задают минимальную границу, ниже которой длина градиента считается достаточной, чтобы остановиться (например, `0.1`, `0.01` или `0.001`). Если длина будет меньше заданной, то алгоритм можно останавливать.\n",
    "\n",
    "Существуют и другие критерии остановки: например, остановиться, если текущее значение функции потерь < 1.5. Но они используются гораздо реже.\n",
    "\n",
    "* 2.1. Вычислить градиент функции потерь .\n",
    "\n",
    "Это будет означать нахождение направления и вектора скорости роста нашего ландшафта. \n",
    "\n",
    "Грубо говоря, нужно взять вектор-столбец с примерами  и подставить его в формулу для вычисления градиента функции потерь. Формулы вычисления градиента для наиболее часто используемых функций потерь уже вычислены и заложены в библиотечные реализации.\n",
    "\n",
    "Далее приведены формулы вычисления градиента для MSE для двух параметров.\n",
    "\n",
    "<img src=ml2_img38.png>\n",
    "\n",
    "* 2.2. Обновить параметры модели, сдвинув их в сторону антиградиента.\n",
    "\n",
    "Из текущей точки необходимо перейти в новую точку, в сторону убывания высоты ландшафта.\n",
    "\n",
    "Для обновления координат точки используем формулу:\n",
    "\n",
    "Далее приведены формулы вычисления градиента для MSE для двух параметров.\n",
    "\n",
    "<img src=ml2_img39.png>\n",
    "\n",
    "### Давайте подведём промежуточный итог.\n",
    "\n",
    "`Градиентный спуск` — простой и мощный алгоритм оптимизации, который позволяет итеративно находить минимум функции потерь и тем самым находить оптимальные параметры модели.\n",
    "\n",
    "Причём функция потерь не обязательно должна быть MSE. Главное требование к функции потерь — это её гладкость во всех точках.\n",
    "\n",
    ">**Примечание**. С математической точки зрения гладкими называются функции, которые имеют производную во всех точках.\n",
    "\n",
    "Для нашего пока что обывательского понимания это значит, что функция должна иметь плавный переход из точки в точку. Примеры:\n",
    "\n",
    "<img src=ml2_img40.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Благодаря своей простоте алгоритм обладает минимальной вычислительной сложностью и работает быстрее, чем метод наименьших квадратов, даже на огромных наборах данных с тысячами признаков.\n",
    "\n",
    "Однако у градиентного спуска есть одна большая проблема — это **сходимость** алгоритма к точке истинного минимума. Алгоритм может попросту не сойтись к истинному минимуму.\n",
    "\n",
    "**Сходимость** зависит от многих факторов, главные из которых:\n",
    "\n",
    "* сложности зависимости и сложности функции потерь;\n",
    "* выбранный темп обучения;\n",
    "* выбранная начальная точка (инициализация параметров);\n",
    "* масштабирование признаков.\n",
    "\n",
    "Из-за сложной зависимости и сложности самой функции потерь она может иметь несколько видов минимумов: локальные и глобальные.\n",
    "\n",
    ">**Локальный минимум** — это минимум на какой-то локальной области. \n",
    "\n",
    ">**Глобальный минимум** — это минимум на всей области определения функции (на всём ландшафте).\n",
    "\n",
    "Например, ваши минимальные расходы в онлайн-банке за весь период пользования приложением — это глобальный минимум. А минимальные расходы в приложении за последние шесть месяцев — это локальный минимум. Эти значения могут существенно отличаться.\n",
    "\n",
    ">Когда мы говорим о функции потерь, нас интересует именно глобальный минимум, то есть тот минимум, которого вообще возможно достичь при управлении параметрами.\n",
    "\n",
    "Функция потерь с локальным и глобальным минимумом в случае одного параметра:\n",
    "\n",
    "<img src=ml2_img41.png>\n",
    "\n",
    "Функция потерь с локальным и глобальным минимумом в случае двух параметров:\n",
    "\n",
    "<img src=ml2_img42.png>\n",
    "\n",
    "Проблема градиентного спуска заключается в том, что алгоритм может `«застрять»` в локальном минимуме и не выйти из него.\n",
    "\n",
    "Застряв в локальном минимуме, мы не найдем настоящие оптимальные значения параметров.\n",
    "\n",
    "Чтобы частично решить эту проблему используется не классический градиентный спуск, а его модификации. Существует множество модификаций градиентного спуска, и мы будем знакомиться с большей их частью далее в курсе.\n",
    "\n",
    "В этом модуле мы будем использовать **стохастический градиентный спуск** (`Stochastic Gradient Descent, SGD`). \n",
    "\n",
    "В классическом алгоритме мы используем всю выборку и прогоняем её несколько раз через алгоритм, вычисляя градиент функции ошибки, плавно приближаясь к минимуму.\n",
    "\n",
    "Стохастическая модификация предполагает, что один шаг градиентного спуска производится на основе градиента, рассчитанного не по всей выборке, а только по случайно выбранной части.\n",
    "\n",
    "То есть мы случайно выбираем несколько строк из таблицы и подставляем их в алгоритм, делаем шаг в сторону минимума и повторяем это множество раз, пока алгоритм не сойдётся к приемлемому значению или пока не закончатся итерации (в реализации **всегда задаётся максимум итераций** на случай, если алгоритм не сойдётся и будет **«блуждать по холмам» вечно**).\n",
    "\n",
    "Благодаря этому вектор градиента всё время колеблется, и мы прыгаем из точки в точку, а не идём вдоль ровной линии, как это было в классическом градиентом спуске.\n",
    "\n",
    "На рисунке ниже приведены графики «блуждания» точки в пространстве функции потерь (вид сверху).\n",
    "\n",
    "<img src=ml2_img43.png>\n",
    "\n",
    "**В чём выгода?**\n",
    "\n",
    "Благодаря таким случайным колебаниям у нас появляется больше возможностей «выкарабкаться» из локальных минимумов и дойти до глобального минимума.\n",
    "\n",
    ">Однако из-за таких скачков есть шанс пропустить и глобальный минимум функции потерь, если скачки будут слишком большими.\n",
    "\n",
    "Чтобы управлять шагами, как раз и существует параметр **темпа обучения**. Он позволяет управлять размером шага градиентного спуска.\n",
    "\n",
    ">Даже для обычной выпуклой функции, такой как парабола, градиентный спуск может сходиться медленно, если выбран слишком маленький темп обучения, или не сходиться вообще, если темп слишком большой. Поэтому темп обучения — это один из самых важных внешних параметров, на который мы можем повлиять.\n",
    "\n",
    "<img src=ml2_img44.png>\n",
    "\n",
    "Наиболее распространённые значения `n < 1`:  `0.01`, `0.001` и т. д.\n",
    "\n",
    "Но есть идея получше! Будем брать большой шаг в начале обучения и уменьшать его постепенно, приближаясь к минимуму, чтобы не «выпрыгнуть» из точки минимума.\n",
    "\n",
    "В реализации стохастического градиентного спуска в `sklearn`, с которым мы будем работать, именно такая идея и используется по умолчанию. Параметр  регулируется в процессе обучения — он уменьшается с ростом числа итераций по формуле:\n",
    "\n",
    "<img src=ml2_img45.png>\n",
    "\n",
    "Ещё один важный момент, на который стоит обратить внимание при работе с градиентным спуском — это обязательное масштабирование факторов (приведение факторов к единому масштабу или к единым статистическим характеристикам), если их несколько.\n",
    "\n",
    "Например, в нашем наборе данных о домах в Бостоне есть признак NOX (концентрация оксидов азота): он изменяется в диапазоне от 0 до 1. Также есть признак LSTAT (процент низкостатусного населения), который изменяется в диапазоне от 0 до 100 %. \n",
    "\n",
    "Для градиентного спуска (особенно стохастического) важно, чтобы все факторы были приведены к единому масштабу с помощью нормализации/стандартизации (мы изучали их в модуле EDA-3. «Проектирование признаков»). Иначе в пространстве параметров функция ошибки становится очень растянутой по одной оси, но очень сжатой по другой, и найти её минимум будет очень сложно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 ЧИСЛЕННОЕ РЕШЕНИЕ НА PYTHON <a class=\"anchor\" id=4-1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Как и раньше, будем работать с датасетом о домах в Бостоне из библиотеки sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим с помощью градиентного спуска линейную регрессию на одном факторе — `LSTAT` (процент низкостатусного населения) — и сравним результат с полученным ранее результатом `МНК`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать реализацию стохастического градиентного спуска для линейной регрессии из библиотеки `sklearn` — [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html). Она находится в том же модуле `linear_model`.\n",
    "\n",
    "У класса `SGDRegressor` есть множество параметров. Например, параметр `random_state` отвечает за число, на основе которого происходит генерация  случайных чисел. Напомним, в `SGD` случайность присутствует в инициализации параметров и выборе части из набора данных. Установив значение параметра `random_state` равным определённому числу, мы можем гарантировать одинаковые результаты работы метода при разных запусках. Пусть это будет число `42`.\n",
    "\n",
    "Для обучения используется метод `fit()`: он запускает работу градиентного спуска для поиска параметров, в него необходимо передать данные и правильные ответы.\n",
    "\n",
    ">**Примечание**. К сожалению, в `sklearn` нельзя посмотреть то, как происходит поиск оптимальных параметров с помощью `SGD`. Поэтому нет возможности продемонстрировать историю изменения функции потерь. В модулях по оптимизации мы самостоятельно реализуем алгоритм и посмотрим на поэтапную минимизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_lstat = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "sgd_lr_lstat.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение завершено, параметры найдены. Давайте выведем их на экран. Для этого используются уже знакомые вам атрибуты `coef_` и `intercept_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0: [34.33010969]\n",
      "w1: [-0.96193242]\n"
     ]
    }
   ],
   "source": [
    "print('w0: {}'.format(sgd_lr_lstat.intercept_)) #свободный член w0\n",
    "print('w1: {}'.format(sgd_lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примечание. Обратите внимание, что значения параметров немного отличаются от полученных ранее с помощью МНК значений. Для МНК коэффициенты были равны:\n",
    ">\n",
    ">* `w0`: [34.55384087938311]\n",
    ">* `w1`: [-0.95004935]\n",
    ">\n",
    "В этом нет ничего удивительного, ведь `МНК` — это аналитический метод, он выдаёт точное решение, а `SGD` — численный, и вычисления останавливаются, когда достигается приемлемая точность.\n",
    "\n",
    "Давайте с помощью метода predict() сделаем предсказание цены для всех объектов из нашей выборки и построим визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 69\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y_predict \u001b[39m=\u001b[39m sgd_lr_lstat\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#Строим визуализацию\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plot_regression_2d(X, y, y_predict)\n",
      "\u001b[1;32mc:\\Личные документы\\Python\\Py\\ml_2\\ml_2_lecture.ipynb Ячейка 69\u001b[0m in \u001b[0;36mplot_regression_2d\u001b[1;34m(X, y_true, y_predict, xlabel, ylabel)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m4\u001b[39m)) \u001b[39m#фигура + координатная плоскость\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ax\u001b[39m.\u001b[39mscatter(X, y_true, alpha\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSample data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m#диаграмма рассеяния\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ax\u001b[39m.\u001b[39;49mplot(X, y_predict, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mblack\u001b[39;49m\u001b[39m'\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mRegression model\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#линейный график\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ax\u001b[39m.\u001b[39mset_xlabel(xlabel) \u001b[39m#название оси абсцисс\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/%D0%9B%D0%B8%D1%87%D0%BD%D1%8B%D0%B5%20%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/Python/Py/ml_2/ml_2_lecture.ipynb#Y131sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m ax\u001b[39m.\u001b[39mset_ylabel(ylabel) \u001b[39m#название оси ординат\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[39m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(xy) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m    488\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSupport for multi-dimensional indexing\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[39m=\u001b[39m x[:, \u001b[39mNone\u001b[39;49;00m]\u001b[39m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[39m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[39m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3629\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[39m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#функция для визуализации регрессии\n",
    "def plot_regression_2d(X, y_true, y_predict, xlabel='LSTAT', ylabel='MEDV'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 4)) #фигура + координатная плоскость\n",
    "    ax.scatter(X, y_true, alpha=0.7, label='Sample data') #диаграмма рассеяния\n",
    "    ax.plot(X, y_predict, color='black', label='Regression model') #линейный график\n",
    "    ax.set_xlabel(xlabel) #название оси абсцисс\n",
    "    ax.set_ylabel(ylabel) #название оси ординат\n",
    "    ax.legend(facecolor='white', fontsize=11) #легенда\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "y_predict = sgd_lr_lstat.predict(X)\n",
    "#Строим визуализацию\n",
    "plot_regression_2d(X, y, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассчитать метрики регрессии для полученной модели. Давайте для примера посчитаем `R^2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.542\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый `R^2` для линейной регрессии, обученной с помощью градиентного спуска, составил `0.542`. Напомним, для той же модели, обученной с помощью `МНК`, метрика была равна `0.544`. То есть доля информации, которую объяснила модель, обученная с помощью градиентного спуска, ниже примерно на `0.002`. Очевидно, в реальных задачах такая разница не имеет значения. \n",
    "\n",
    "Теперь попробуем обучить многомерную линейную регрессию с помощью `SGD`. Как и раньше составим полную матрицу наблюдений `X` из всех факторов, которые нам даны. Обучим модель и выведем значения коэффициентов в виде `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>2.156857e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>1.248446e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>7.277644e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>8.306154e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-8.413828e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>-3.148182e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>8.685820e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-2.256141e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>-4.683208e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>1.892286e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>1.040701e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>-1.057912e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>1.899998e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>-7.922809e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM  2.156857e+11\n",
       "1          ZN  1.248446e+10\n",
       "2       INDUS  7.277644e+09\n",
       "3        CHAS  8.306154e+09\n",
       "4         NOX -8.413828e+09\n",
       "5          RM -3.148182e+10\n",
       "6         AGE  8.685820e+10\n",
       "7         DIS -2.256141e+11\n",
       "8         RAD -4.683208e+10\n",
       "9         TAX  1.892286e+09\n",
       "10    PTRATIO  1.040701e+11\n",
       "11          B -1.057912e+11\n",
       "12      LSTAT  1.899998e+11\n",
       "13  INTERCEPT -7.922809e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    " \n",
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_full = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "sgd_lr_full.fit(X, y)\n",
    " \n",
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': sgd_lr_full.coef_})\n",
    "#Составляем строчку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': sgd_lr_full.intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все коэффициенты имеют запредельные значения (`9-11 степени числа 10`). Это типичная картина расходящегося градиентного спуска: алгоритм не достиг точки минимума по каким-то причинам. Такие высокие значения коэффициентов означают, что модель является неустойчивой.\n",
    "\n",
    "Давайте сделаем предсказание и выведем  для обученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -10590303862129977211224064.000\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "y_predict = sgd_lr_full.predict(X)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`R^2` отрицательный. Да ещё какой! Напомним, отрицательный `R^2` говорит о том, что модель абсолютно не описывает зависимости в данных.\n",
    "\n",
    "В чём же причина? Неужели `SGD` не справился с поиском `14` параметров (свободный член `+13` коэффициентов при факторах)?\n",
    "\n",
    ">Ответ очень простой — **отсутствие масштабирования**. Как мы уже говорили ранее, при использовании градиентного спуска и его модификаций очень важно масштабировать данные с помощью нормализации или стандартизации. Иначе алгоритм теряется в таком растянутом пространстве из-за неравномерных градиентов.\n",
    "\n",
    "Давайте стандартизируем наши данные. Воспользуемся классом `StandardScaler` из модуля `preprocessing` библиотеки `sklearn`, который реализует стандартизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    " \n",
    "#Инициализируем стандартизатор StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Производим стандартизацию\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "#Составляем DataFrame из результата\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Попытка №2**. Обучим модель и составим таблицу из её параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIM</td>\n",
       "      <td>-0.870552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZN</td>\n",
       "      <td>0.947112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDUS</td>\n",
       "      <td>-0.116802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAS</td>\n",
       "      <td>0.730289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOX</td>\n",
       "      <td>-1.894276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RM</td>\n",
       "      <td>2.757578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGE</td>\n",
       "      <td>-0.027846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DIS</td>\n",
       "      <td>-3.049237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RAD</td>\n",
       "      <td>1.957066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAX</td>\n",
       "      <td>-1.305271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>-2.012984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.843065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LSTAT</td>\n",
       "      <td>-3.697319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTERCEPT</td>\n",
       "      <td>22.541417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients\n",
       "0        CRIM     -0.870552\n",
       "1          ZN      0.947112\n",
       "2       INDUS     -0.116802\n",
       "3        CHAS      0.730289\n",
       "4         NOX     -1.894276\n",
       "5          RM      2.757578\n",
       "6         AGE     -0.027846\n",
       "7         DIS     -3.049237\n",
       "8         RAD      1.957066\n",
       "9         TAX     -1.305271\n",
       "10    PTRATIO     -2.012984\n",
       "11          B      0.843065\n",
       "12      LSTAT     -3.697319\n",
       "13  INTERCEPT     22.541417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_full = linear_model.SGDRegressor(random_state=42)\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_full.fit(X_scaled, y)\n",
    " \n",
    "#Составляем таблицу из признаков и их коэффициентов\n",
    "w_df = pd.DataFrame({'Features': features, 'Coefficients': sgd_lr_full.coef_})\n",
    "#Составляем строчку таблицы со свободным членом\n",
    "intercept_df =pd.DataFrame({'Features': ['INTERCEPT'], 'Coefficients': sgd_lr_full.intercept_})\n",
    "coef_df = pd.concat([w_df, intercept_df], ignore_index=True)\n",
    "display(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот теперь результат более схож с реальностью. Сделаем предсказание и посчитаем результирующий `R^2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.740\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_full.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь метрика имеет приемлемое значение, а значит градиентный спуск смог сойтись.\n",
    "\n",
    ">**Важно**! Если вы обучили модель на стандартизованных данных, то и для предсказания необходимо передавать их в стандартизованном виде.\n",
    "\n",
    "Например, если попытаться сделать предсказание с помощью построенной модели, передав в качестве матрицы наблюдений нестандартизованную таблицу, то ошибки мы не получим, однако значение метрики будет неадекватным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -1856.503\n"
     ]
    }
   ],
   "source": [
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_full.predict(X)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml2_img46.png>\n",
    "\n",
    "[документация](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "\n",
    "Давайте посмотрим, что будет, если выставить константный режим управления темпом обучения и задать ему более высокое значение, например 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -335415038359.635\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad = linear_model.SGDRegressor(\n",
    "    learning_rate='constant', #режим темпа обучения — константа\n",
    "    eta0=0.1, #начальное и постоянное значение темпа обучения\n",
    "    random_state=42\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`R^2 < 0`, то есть `SGD` разошёлся из-за слишком высокого темпа обучения. \n",
    "\n",
    "Вот ещё один плохой пример. Что будет, если поставить слишком маленькое значение параметра `eta0`? Например, `0.000001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -1.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:1503: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad2 = linear_model.SGDRegressor(\n",
    "    learning_rate='constant', #режим темпа обучения — константа\n",
    "    eta0=1e-6, #начальное и постоянное значение темпа обучения\n",
    "    random_state=42\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad2.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad2.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова `R^2`, но также мы видим предупреждение (`warning`), которое говорит о том, что алгоритму не хватило количества итераций (`max_iter`), чтобы добраться до минимума. То есть `SGD` не дошёл до точки минимума из-за слишком низкого темпа обучения.\n",
    "\n",
    ">Так как модель линейной регрессии является довольно простой и исследованной, то значения параметров, которые обладают наибольшей эффективностью, уже установлены по умолчанию (аргументы по умолчанию), но бывают ситуации, когда поэкспериментировать с параметрами может быть полезно, чтобы попытаться повысить качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.735\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с SGD\n",
    "sgd_lr_bad2 = linear_model.SGDRegressor(\n",
    "    learning_rate='constant', #режим темпа обучения — константа\n",
    "    eta0=0.01, #начальное и постоянное значение темпа обучения\n",
    "    random_state=42,\n",
    "    tol=0.1 #критерий остановки\n",
    ")\n",
    "#Обучаем модель — ищем параметры по методу SGD\n",
    "#Подаём стандартизованные данные\n",
    "sgd_lr_bad2.fit(X_scaled, y)\n",
    "#Предсказываем медианную цену для всех участков из набора данных\n",
    "#Передаём стандартизованные данные\n",
    "y_predict = sgd_lr_bad2.predict(X_scaled)\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СРАВНЕНИЕ АНАЛИТИЧЕСКОГО И ЧИСЛЕННОГО РЕШЕНИЙ <a class=\"anchor\" id=4-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "У вас наверняка возник вопрос: что лучше использовать — `LinearRegression` (аналитическое решение через метод наименьших квадратов) или `SGDRegressor` (численное решение через стохастический градиентный спуск)?\n",
    "\n",
    "Приведём сравнение двух реализаций в виде таблицы:\n",
    "\n",
    "<img src=ml2_img47.png>\n",
    "\n",
    "[Функции потерь](https://scikit-learn.ru/1-5-stochastic-gradient-descent/#mathematical-formulation)\n",
    "[Инкреминальное обучение](https://coderzcolumn.com/tutorials/machine-learning/scikit-learn-incremental-learning-for-large-datasets)\n",
    "\n",
    "По приведённой таблице можно выделить примерные области применения каждого из методов:\n",
    "\n",
    "* Если стоит задача **одноразового обучения на всех данных**, которые есть, **и признаков немного** (меньше 1 000), наш выбор — `LinearRegression`, так как МНК обеспечивает простое решение и гарантированную сходимость.\n",
    "\n",
    "* Если стоит задача **непрерывного обучения модели** в процессе её эксплуатации **или количество признаков очень велико**, наш выбор — `SGDRegressor` с возможностью корректировки параметров на новых данных.\n",
    "\n",
    ">Однако существенной разницы между двумя подходами нет, так как используется одна и та же модель. Наиболее распространённым является классический метод наименьших квадратов (`LinearRegression`), им в прикладных задачах пользуется большинство дата-сайентистов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Дилемма смещения и разброса. Полигональные признаки. Регуляризация <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "## СМЕЩЕНИЕ И РАЗБРОС\n",
    "\n",
    "До этого момента мы обучали модели на всех имеющихся данных. С одной стороны, это имеет смысл, ведь мы хотим минимизировать ошибки модели, используя как можно больше данных для обучения.\n",
    "\n",
    "С другой стороны, из-за такого подхода становится труднее оценивать, насколько хорошо работает модель. Причина этого в том, что, если мы продолжим рассчитывать метрики, используя тренировочные данные, мы можем обнаружить, что при применении модели на незнакомых ей данных она работает довольно плохо.\n",
    "\n",
    ">Таким образом, модель может детально подстроиться под зависимость в обучающей выборке, **но не уловить общей сути**.\n",
    "\n",
    "Такая проблема называется переобучением (`overfitting`). По сути, такая модель работает намного лучше с обучающими данными, чем с новыми. Она была чрезмерно натренирована на обнаружение уникальных характеристик обучающего набора данных, которые не являются общими закономерностями.\n",
    "\n",
    ">Недообучение (`underfitting`) — проблема, обратная переобучению. Модель из-за своей слабости не уловила никаких закономерностей в данных. В этом случае ошибка будет высокой как для тренировочных данных, так и для данных, не показанных во время обучения.\n",
    "\n",
    "<img src=ml2_img48.png>\n",
    "\n",
    "* На первом рисунке изображена простая модель линейной регрессии, не способная уловить сложную зависимость в данных.\n",
    "* На втором рисунке изображена оптимальная модель, которая хорошо описывает зависимость и при этом не имеет переобучения (**полином 4-ой степени**).\n",
    "* На последнем рисунке изображен **полином 27-й степени**, который подстроился под каждую точку в тренировочном наборе, но не смог уловить общие закономерности.\n",
    "\n",
    "С теоретической точки зрения недообучение и переобучение характеризуются понятиями смещения и разброса модели.\n",
    "\n",
    ">**Смещение** (`bias`) — это **математическое ожидание** разности между истинным ответом и ответом, выданным моделью. То есть это ожидаемая ошибка модели.\n",
    "\n",
    "<img src=ml2_img49.png>\n",
    "\n",
    "**Чем больше смещение, тем слабее модель**. Если модель слабая, она не в состоянии выучить закономерность. Таким образом, налицо недообучение модели.\n",
    "\n",
    ">**Разброс** (`variance`) — это вариативность ошибки, то, насколько ошибка будет отличаться, если обучать модель на разных наборах данных. Математически это **дисперсия** (разброс) ответов модели.\n",
    "\n",
    "<img src=ml2_img50.png>\n",
    "\n",
    "Чем больше разброс, тем больше ошибка будет колебаться на разных наборах данных. **Наличие высокого разброса и есть свидетельство переобучения**: модель подстроилась под конкретный набор данных и даёт высокий разброс ответов на разных данных.\n",
    "\n",
    "Теоретически на составляющие смещения и разброса модели можно разложить любую функцию потерь. Например, разложение квадратичной ошибки (её математическое ожидание) будет выглядеть следующим образом:\n",
    "\n",
    "<img src=ml2_img52.png>\n",
    "<img src=ml2_img51.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О чём нам говорит эта теоретическая формула?\n",
    "\n",
    "Ошибка модели складывается из смещения модели (в квадрате) и её разброса, а также случайной ошибки. \n",
    "\n",
    ">Если с последним слагаемым `сигма_квадрат` мы ничего не сможем сделать, то вот на первые два (`bias` и `variance`) мы можем как-то повлиять. В идеале мы должны свести их к 0. Однако уменьшение одного слагаемого повлечёт увеличение другого. На практике часто приходится балансировать между смещёнными и нестабильными оценками.\n",
    "\n",
    "[Дилемма смещения-дисперсии](https://ru.wikipedia.org/wiki/Дилемма_смещения–дисперсии) является центральной проблемой в обучении с учителем. В идеале мы хотим построить модель, которая точно описывает зависимости в тренировочных данных и хорошо работает на неизвестных данных. К сожалению, обычно это невозможно сделать одновременно.\n",
    "\n",
    "Усложняя модель, мы пытаемся уменьшить смещение (`bias`), однако появляется риск получить переобучение, то есть мы повышаем разброс (`variance`). \n",
    "\n",
    "С другой стороны, снизить разброс (`variance`) позволяют более простые модели, не склонные к переобучению, но есть риск, что простая модель не уловит зависимостей и окажется недообученной, то есть мы повышаем смещение (`bias`).\n",
    "\n",
    ">Если провести аналогию, что модель — это игрок в дартс, то самый лучший игрок будет иметь небольшое смещение и разброс: его дротики ложатся кучно «в яблочко». Если у игрока большое смещение, то дротики сгруппированы около другой точки, а если большой разброс — дротики разлетаются по всей мишени.\n",
    "\n",
    "<img src=ml2_img53.png>\n",
    "\n",
    "**Интересный факт**. По теореме Гаусса-Маркова, оценки линейной регрессии, полученные методом наименьших квадратов, обладают наименьшим разбросом. То есть если существует другая линейная модель, обученная способом, отличным от МНК (например, градиентным спуском), то теорема гарантирует, что эта модель будет обладать большим либо равным разбросом (`variance`), чем МНК-модель. **То есть у линейной регрессии, обученной с помощью МНК, меньше всего риск переобучения.** \n",
    "\n",
    "Однако это не значит, что его не существует вовсе.\n",
    "\n",
    "Теперь, когда мы знаем о теоретических основах проблемы переобучения и недообучения, что мы можем сделать, чтобы лучше судить о способности модели к обобщению на практике? Как диагностировать высокие `bias` и `variance`?\n",
    "\n",
    "Типичным решением является разделение данных на две части: **обучающий** и **тестовый наборы**. На тренировочном наборе данных мы будем обучать модель, подбирая параметры. Тестовый набор данных, который модель не видела при обучении, мы будем использовать для оценки истинного качества моделирования. Схематично можно представить это следующим образом:\n",
    "\n",
    "<img src=ml2_img54.png>\n",
    "\n",
    "Давайте посмотрим, как это работает на практике. Работать будем с уже знакомыми нам данными — данными о домах в Бостоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AubakirovMA\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "\n",
    "boston = load_boston()\n",
    "#создаём DataFrame из загруженных numpy-матриц\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    " \n",
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn` для разделения выборки на тренировочную и тестовую есть функция `train_test_split()` из модуля `model_selection`. Данная функция принимает следующие аргументы:\n",
    "\n",
    "* `X` и `y` — таблица с примерами и ответами к ним.\n",
    "* `random_state` — число, на основе которого генерируются случайные числа. Тренировочная и тестовая выборка генерируются случайно. Чтобы эксперимент был воспроизводимым, необходимо установить этот параметр в конкретное значение.\n",
    "* `test_size` — доля тестовой выборки. Параметр определяет, в каких пропорциях будет разделена выборка. Стандартные значения: `70/30`, `80/20`.\n",
    "\n",
    "Функция возвращает четыре объекта в следующем порядке: тренировочные примеры, тестовые примеры, тренировочные ответы и тестовые ответы. \n",
    "\n",
    "Итак, давайте разделим нашу выборку на тренировочную и тестовую в соотношении `70/30`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (354, 13) (354,)\n",
      "Test: (152, 13) (152,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Разделяем выборку на тренировочную и тестовую в соотношении 70/30\n",
    "#Устанавливаем random_state для воспроизводимости результатов \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "#Выводим результирующие размеры таблиц\n",
    "print('Train:', X_train.shape, y_train.shape)\n",
    "print('Test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После разделения в тренировочной выборке оказались `354` наблюдения, а в тестовой — `152`.\n",
    "\n",
    "Затем обучим линейную регрессию (с помощью `МНК`) на тренировочных данных и рассчитаем  для тренировочных и тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.743\n",
      "Test R^2: 0.722\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_model = linear_model.LinearRegression()\n",
    "#Обучаем модель по МНК\n",
    "lr_model.fit(X_train, y_train)\n",
    " \n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict = lr_model.predict(X_train)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict = lr_model.predict(X_test)\n",
    " \n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, `R^2 = 0.743` на тренировочной выборке и `R^2 = 0.722` на тестовой выборке. То есть показатели **довольно близки друг к другу** (низкий разброс ответов модели для разных выборок).\n",
    "\n",
    "Это одно из свидетельств отсутствия переобучения. Это не удивительно, ведь линейная регрессия, построенная на 13 факторах, является довольно простой моделью: всего лишь 14 параметров, что очень мало по меркам машинного обучения. Риск переобучения возрастает с количеством факторов, которые участвуют в обучении модели.\n",
    "\n",
    "Но что насчёт смещения? Самый простой способ оценить смещение и недообученность модели — посмотреть на значение метрики и интуитивно оценить её.\n",
    "\n",
    "Может, наша модель слишком слабая? `R^2 = 0.722` — не слишком уж высокий показатель (напомним, **максимум — 1**). Возможно, стоит попробовать обучить более сложную модель. Например, можно построить модель полиномиальной регрессии.\n",
    "\n",
    ">Примечание. Существуют более совершенные визуальные способы оценить наличие смещения и разброса, такие как кривая обучения и кросс-валидация. О них мы ещё поговорим далее в курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ПОЛИНОМИАЛЬНЫЕ ПРИЗНАКИ <a class=\"anchor\" id=5-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "**Полиномиальная регрессия** (`Polynomial Regression`) — это более сложная модель, чем линейная регрессия. Вместо уравнения прямой используется уравнение **полинома** (многочлена). Степень полинома может быть сколь угодно большой: **чем больше степень, тем сложнее модель**.\n",
    "\n",
    "В простом двумерном случае, когда мы рассматриваем зависимость целевого признака от одного фактора, полиномом второй степени будет уравнение параболы:\n",
    "\n",
    "`y = w0 + w1*x + w2*x^2`\n",
    "\n",
    "Геометрически полином в двумерном пространстве — это некоторая кривая, которая пытается описать зависимость в данных. Выглядит это следующим образом:\n",
    "\n",
    "<img src=ml2_img55.png>\n",
    "\n",
    "Когда факторов больше одного, например два, то, помимо возведения фактора в квадрат, появляются ещё и комбинации из `x1` и `x2`:\n",
    "\n",
    "<img src=ml2_img56.png>\n",
    "\n",
    "Такая модель будет описывать сложную поверхность в трёхмерном пространстве, которая проставлена на рисунке:\n",
    "\n",
    "<img src=ml2_img57.png>\n",
    "\n",
    "Заметьте, как быстро растёт количество коэффициентов, а с ним и сложность модели. А ведь это только два фактора —  и . Мы не будем приводить уравнение для общего случая, как делали это с линейной регрессией, так как оно будет содержать слишком много слагаемых.\n",
    "\n",
    "Например, рассматривая построенный ранее график зависимости медианной цены домов от процента низкостатусного населения, вы могли заметить, что между данными показателями существует не линейная, а скорее полиномиальная связь.\n",
    "\n",
    "<img src=ml2_img58.png>\n",
    "\n",
    "На рисунке изображены модели **линейной** и **полиномиальной** (вторая степень) регрессий.\n",
    "\n",
    "Заметим, что степени `x` можно тоже считать своего рода искусственными признаками в данных. Они называются **полиномиальными признаками**.\n",
    "\n",
    "Поэтому полиномиальная регрессия — это та же линейная регрессия, просто с новыми признаками. Полиномиальные признаки — один из самых распространённых методов FeatureEngineering.\n",
    "\n",
    "Пример:\n",
    "\n",
    "<img src=ml2_img59.png>\n",
    "\n",
    ">Благодаря степенным слагаемым модель становится сложнее и начинает улавливать более сложные зависимости и выдавать меньшее смещение. Но, как вы понимаете, резко повышается риск переобучения модели — увеличивается разброс предсказаний на разных данных из-за количества факторов.\n",
    "\n",
    "Давайте проследим за этим.\n",
    "\n",
    "Построить полиномиальную регрессию в `sklearn` очень просто. Для начала необходимо создать полиномиальные признаки с помощью объекта класса `PolynomialFeatures` из модуля `preprocessing`. Это преобразователь, который позволит сгенерировать полиномиальные признаки любой степени и добавить их в таблицу. У него есть два важных параметра:\n",
    "\n",
    "`degree` — степень полинома. По умолчанию используется степень 2.\n",
    "`include_bias` — включать ли в результирующую таблицу столбец из единиц (`x в степени 0`). По умолчанию стоит `True`, но лучше выставить его в значение `False`, так как столбец из единиц и так добавляется в методе наименьших квадратов.\n",
    "\n",
    ">**Примечание**. Как правило, дата-сайентисты останавливаются на полиноме второй (максимум третьей) степени. Чем выше степень полинома, тем больше слагаемых, а значит, тем больше признаков и тем сложнее становится модель.\n",
    "\n",
    "Для того чтобы подогнать генератор и рассчитать количество комбинаций степеней, мы используем метод `fit()`, а чтобы сгенерировать новую таблицу признаков, в которую будут включены полиномиальные признаки, используется метод `transform()`, в который нужно передать выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "#Создаём генератор полиномиальных признаков\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train)\n",
    "#Генерируем полиномиальные признаки для тренировочной выборки\n",
    "X_train_poly = poly.transform(X_train)\n",
    "#Генерируем полиномиальные признаки для тестовой выборки\n",
    "X_test_poly = poly.transform(X_test)\n",
    "#Выводим результирующие размерности таблиц\n",
    "print(X_train_poly.shape)\n",
    "print(X_test_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы сгенерировали новые тренировочные и тестовые наборы данных. В каждой таблице в дополнение к 13 изначальным признакам добавилась 91 полиномиальная комбинация степени 2.\n",
    "\n",
    "В результате мы получили два `numpy`-массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_poly))\n",
    "print(type(X_test_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.929\n",
      "Test R^2: 0.268\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса LinearRegression\n",
    "lr_model_poly = linear_model.LinearRegression()\n",
    "#Обучаем модель по МНК\n",
    "lr_model_poly.fit(X_train_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lr_model_poly.predict(X_train_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lr_model_poly.predict(X_test_poly)\n",
    " \n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Потрясающе**! На тренировочной выборке коэффициент детерминации `R^2 = 0.929`, то есть наша модель описывает почти `93 %` зависимости в данных.\n",
    "\n",
    "Смотрим на показатели тестовой выборки и сразу **«спускаемся с небес на землю»**: `R^2 = 0.268` . Метрика значительно ниже, чем на тренировочном наборе. **Это и есть переобучение модели**. Из-за своей сложности (количества факторов) модель полностью адаптировалась под тренировочные данные, но взамен получила высокий разброс в показателях на данных, которые она не видела ранее. \n",
    "\n",
    ">**Примечание**. Модель линейной регрессии может быть неустойчивой, даже если показатели на тренировочной и тестовой выборках довольно близки, однако все коэффициенты уравнения имеют огромные значения.\n",
    "\n",
    "Такая модель никому не нужна, так как она не отражает действительности.\n",
    "\n",
    "Однако не стоит расстраиваться — есть один замечательный метод, который сможет спасти нашу модель от переобучения, и это **регуляризация**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РЕГУЛЯРИЗАЦИЯ <a class=\"anchor\" id=5-3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "`Регуляризация` — способ **уменьшения переобучения** моделей машинного обучения.\n",
    "\n",
    "Идея регуляризации состоит в том, что мы намеренно пытаемся увеличить смещение модели, чтобы уменьшить разброс. Закон баланса в действии!\n",
    "\n",
    "Но как можно увеличить смещение модели? Мы можем «наказывать» модель за обучение сложным взаимосвязям. \n",
    "\n",
    "Математически это будет очень простая операция — добавление к функции потерь некоторого штрафа.\n",
    "\n",
    ">`Штраф` — это дополнительное неотрицательное слагаемое в выражении для функции потерь, которое специально повышает ошибку. За счёт этого слагаемого метод оптимизации (`OLS` или `SGD`) будет находить не истинный минимум функции потерь, а псевдоминимум.\n",
    "\n",
    "Есть несколько способов добавления штрафа к функции потерь:\n",
    "\n",
    "<img src=ml2_img60.png>\n",
    "\n",
    "Коэффициенты `a` (`альфа`) — это коэффициенты регуляризации. Они отвечают за то, насколько сильное смещение мы будем вносить в модель: **чем оно больше, тем сильнее будет штраф за переобучение**.\n",
    "\n",
    "А что по геометрии? Рассмотрим, как будет выглядеть минимум функции потерь в трёхмерном пространстве (вид сверху). Первый метод, , заставляет искать минимум функции потерь на пересечении его с ромбом, а второй, , — с окружностью. Визуализация представлена ниже:\n",
    "\n",
    "<img src=ml2_img61.png>\n",
    "\n",
    "<img src=ml2_img62.png>\n",
    "\n",
    ">**Примечание**. В реализации `sklearn` для решения задачи оптимизации используется итеративный алгоритм координатного спуска (аналог градиентного спуска, но не использующий производную).\n",
    "\n",
    "Отличительной особенностью `L1`-регуляризации является то, что коэффициенты, которые соответствуют «ненужным», по мнению модели, факторам, обнуляются, то есть факторы просто не будут участвовать в предсказании. Это очень важно для сложных моделей, в обучении которых используются множество факторов (как в нашей модели выше — 91 фактор). Тем самым мы уменьшим сложность модели, сократим её разброс и, как следствие, уменьшим переобучение.\n",
    "\n",
    "В заключение теоретической части хочется отметить, что на практике никогда не ясно, какой из методов регуляризации сработает лучше всего. Выход — пробовать оба метода и сравнивать результаты.\n",
    "\n",
    "А теперь пора приниматься за практику!\n",
    "\n",
    "Практика показывает, что обучение линейной регрессии с большим количеством признаков рекомендуется производить на стандартизованных (нормализованных) данных.\n",
    "\n",
    ">**Примечание**. Часто возникает вопрос: как правильно проводить стандартизацию/нормализацию при наличии тренировочной и тестовой выборки?\n",
    "\n",
    "Вы обучаете (`fit()`) преобразование на тренировочной выборке и используете его с одними и теми же параметрами на тренировочной и тестовой выборке (`transform()`). Если производить подгонку на каждой из выборок в отдельности, вы внесёте смещение в модель.\n",
    "\n",
    "Стандартизацию (нормализацию) полезнее проводить перед генерацией полиномиальных признаков, иначе можно потерять масштаб полиномов.\n",
    "\n",
    "Давайте предобработаем наши данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 104)\n",
      "(152, 104)\n"
     ]
    }
   ],
   "source": [
    "#Инициализируем стандартизатор StandardScaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "#Подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "scaler.fit(X_train)\n",
    "#Производим стандартизацию тренировочной выборки\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "#Производим стандартизацию тестовой выборки\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "#Создаём генератор полиномиальных признаков\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit(X_train_scaled)\n",
    "#Генерируем полиномиальные признаки для тренировочной выборки\n",
    "X_train_scaled_poly = poly.transform(X_train_scaled)\n",
    "#Генерируем полиномиальные признаки для тестовой выборки\n",
    "X_test_scaled_poly = poly.transform(X_test_scaled)\n",
    "#Выводим результирующие размерности таблиц\n",
    " \n",
    "print(X_train_scaled_poly.shape)\n",
    "print(X_test_scaled_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В `sklearn` методы регуляризации реализованы в классах `Lasso` (`L1`-регуляризация) и `Ridge` (`L2`-регуляризация). Оба метода осуществляют поиск параметров с добавлением регуляризации. Процесс обучения и предсказания не отличается от обычной линейной регрессии.\n",
    "\n",
    "Давайте построим модель линейной регрессии с `L1`-регуляризацией на сгенерированных нами ранее полиномиальных признаках.\n",
    "\n",
    "Главный параметр инициализации `Lasso` — это `alpha`, коэффициент регуляризации. По умолчанию `alpha=1`. Практика показывает, что это довольно сильная регуляризация для `L1`-метода. Давайте установим значение этого параметра на `0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.879\n",
      "Test R^2: 0.882\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.1)\n",
    "#Обучаем модель\n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, как изменились значения метрик. Да, на тренировочной выборке `R^2 = 0.879`. Метрика упала (до стандартизации + регуляризации значение было `R^2 = 0.929`). Однако метрика ощутимо выросла на тестовой выборке: `R^2 = 0.882` (ранее она была равна `R^2 = 0.268`). Мы смогли преодолеть переобучение.\n",
    "\n",
    "Давайте выведем значения коэффициентов модели, округлив их до третьего знака после запятой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.     0.    -0.038  0.    -0.523  2.766 -0.355 -0.605  0.    -0.595\n",
      " -0.763  0.    -3.259 -0.    -0.     0.     3.132 -0.141  0.     0.\n",
      "  0.    -0.     0.     0.    -0.015 -0.     0.063 -0.    -0.     0.\n",
      "  0.159 -0.    -0.    -0.     0.     0.07  -0.    -0.     0.017  0.\n",
      "  0.    -0.     0.     0.     0.     0.    -0.    -0.     0.     0.46\n",
      " -0.808 -0.643  0.    -0.    -0.     0.    -0.     0.    -0.43  -0.348\n",
      " -0.511 -0.     0.    -0.14  -0.    -0.277  0.    -0.     0.223 -0.\n",
      " -0.    -0.836 -0.054 -0.421  0.019 -0.784  0.    -0.     0.706  0.\n",
      " -0.    -0.335 -0.198  0.    -0.     0.     0.205 -0.     0.531 -0.\n",
      "  0.     0.048 -0.    -0.292  0.677  0.81  -0.    -1.151 -0.    -0.\n",
      " -0.    -0.288 -0.356  0.429]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(lasso_lr_poly.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание: **большая часть коэффициентов обнулилась**. Это значит, что признаки, которые соответствуют этим коэффициентам, не используются в прогнозе модели `Lasso`-регрессии.\n",
    "\n",
    "Теперь давайте на тех же данных обучим модель линейной регрессии с `L2`-регуляризацией. Для `L2`-регуляризации параметр `alpha` по умолчанию равен `1`. Давайте попробуем использовать значение параметра `alpha=10`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.907\n",
      "Test R^2: 0.848\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L2-регуляризацией\n",
    "ridge_lr_poly = linear_model.Ridge(alpha=10)\n",
    "#Обучаем модель\n",
    "ridge_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = ridge_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = ridge_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения метрики `R^2` на тренировочной и тестовой выборках для `L2`-регуляризации **получились немного выше**. В первую очередь мы всегда ориентируемся на тестовую выборку — это данные, которые модель ещё не видела.\n",
    "\n",
    "Давайте выведем значения коэффициентов модели, округлив их до третьего знака после запятой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.128 -0.049  0.084  0.117 -0.932  2.848 -1.008 -1.464  0.909 -0.908\n",
      " -0.653  0.971 -2.605  0.085 -0.032  0.466  2.721 -0.507  0.986  0.309\n",
      " -0.391 -0.714  0.376 -0.379  0.072  0.287  0.143 -0.138 -0.014  0.315\n",
      "  0.05  -0.409 -0.316  0.075  0.702  0.08  -0.281 -0.37   0.511  0.175\n",
      "  0.72   0.282  0.477  0.888 -0.012  0.074 -0.052  0.166 -0.263  0.414\n",
      " -1.129 -0.852  0.273  0.227 -0.106  0.368 -0.137 -0.241 -0.697 -0.177\n",
      " -0.326 -0.524  0.882 -0.637  0.344 -0.439 -0.006  0.386  0.233 -0.535\n",
      "  0.111 -0.802 -0.662 -0.56   0.22  -1.001  0.123  0.144  0.889 -0.114\n",
      " -0.086 -1.022 -0.71   1.08  -0.446 -0.178 -0.07  -0.496  0.874 -0.926\n",
      "  0.717  0.601 -0.49  -0.723  0.308  1.086 -0.448 -1.256  0.057  0.354\n",
      " -0.059 -0.433 -0.791  0.177]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(ridge_lr_poly.coef_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что `L2`-регуляризация не обнуляет коэффициенты — она использует для предсказания все признаки.\n",
    "\n",
    "Параметр `alpha` имеет очень важное значение: от его выбора зависит, как сильно мы будем штрафовать модель за переобучение. Важно найти значение, которое приносит наилучший эффект.\n",
    "\n",
    "Попробуйте вручную изменять параметр `alpha` для построенных ранее моделей. Согласитесь, это не очень удобно.\n",
    "\n",
    "Давайте организуем процесс перебора параметров модели: создадим цикл, в котором будем перебирать `20` различных значений `alpha` в диапазоне от `0.001` до `1`. Такой список проще всего создать с помощью функции `linspace()` из библиотеки `numpy`.\n",
    "\n",
    "В цикле будем обучать модель линейной регрессии и `L1`-регуляризацией (`Lasso`), вычислять значения метрики `R^2` на тренировочной и тестовой выборках и заносить результаты в списки `train_scores` и `test_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём список из 20 возможных значений от 0.001 до 1\n",
    "alpha_list = np.linspace(0.001, 1, 20)\n",
    "#Создаём пустые списки, в которые будем добавлять результаты \n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for alpha in alpha_list:\n",
    "    #Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "    lasso_lr_poly = linear_model.Lasso(alpha=alpha, max_iter=10000)\n",
    "    #Обучаем модель\n",
    "    lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "    #Делаем предсказание для тренировочной выборки\n",
    "    y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "    #Делаем предсказание для тестовой выборки\n",
    "    y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "    #Рассчитываем коэффициенты детерминации для двух выборок и добавляем их в списки\n",
    "    train_scores.append(metrics.r2_score(y_train, y_train_predict_poly))\n",
    "    test_scores.append(metrics.r2_score(y_test, y_test_predict_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения данного кода в списках `train_scores` и `test_scores` появятся `20` различных значений  на тренировочной и тестовой выборках.\n",
    "\n",
    "Давайте построим линейные графики, которые покажут, как меняется метрика `R^2` на тренировочной и тестовой выборках в зависимости от `alpha`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем изменение R^2 в зависимости от alpha\n",
    "fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость\n",
    "ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки\n",
    "ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки\n",
    "ax.set_xlabel('Alpha') #название оси абсцисс\n",
    "ax.set_ylabel('R^2') #название оси ординат\n",
    "ax.grid() #добави сетку\n",
    "ax.set_xticks(alpha_list) #метки по оси абсцисс\n",
    "ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс\n",
    "ax.legend(); #отображение легенды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью графика мы можем подобрать оптимальное значение параметра `alpha`. Нам нужна такая точка на оси абсцисс, при которой на тестовой выборке наблюдается максимальная метрика и при этом разница между метриками на тренировочной и тестовой выборках минимальна.\n",
    "\n",
    "Видно, что `R^2` на тестовой выборке достигает наибольшего значения в точке `0.0536`. Причём в этой точке наблюдается примерное равенство метрик на каждом наборе данных. Далее метрика на тестовой выборке начинает падать.\n",
    "\n",
    "Обратите внимание, что на тренировочной выборке  непрерывно падает с ростом `alpha`. Оно и понятно, ведь чем больше `alpha`, тем сильнее регуляризация и тем меньше модель подстраивается под обучающую выборку.\n",
    "\n",
    "Давайте подставим значение `alpha=0.0536` в модель `Lasso` и получим результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.894\n",
      "Test R^2: 0.890\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(alpha=0.0536)\n",
    "#Обучаем модель \n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "print(\"Train R^2: {:.3f}\".format(metrics.r2_score(y_train, y_train_predict_poly)))\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, метрика `R^2` выросла благодаря тому, что мы смогли подобрать оптимальное значение параметра `alpha`.\n",
    "\n",
    "<img src=ml2_img63.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Линейная регрессия. Практика <a class=\"anchor\" id=6></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "## Чтение данных, читка отбор, вся хуйня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('insurance.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, набор данных содержит следующие столбцы:\n",
    "\n",
    "* `age` — возраст основного бенефициара;\n",
    "* `sex` — пол страхового подрядчика;\n",
    "* `bmi` — индекс массы тела (кг/м), в идеале — от 18.5 до 24.9;\n",
    "* `children` — количество детей, охваченных медицинской страховкой;\n",
    "* `smoker` — является ли человек курящим;\n",
    "* `region` — жилой район США (северо-восток, юго-восток, северо-запад, юго-запад);\n",
    "* `charges` (целевой признак) — индивидуальные медицинские расходы, оплачиваемые медицинской страховкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# еcть ли пропуски\n",
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex          object\n",
       "bmi         float64\n",
       "children      int64\n",
       "smoker       object\n",
       "region       object\n",
       "charges     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# типы данных\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем приступать к этапу подготовки данных для модели, вы можете произвести небольшое исследование зависимостей в данных, например построить следующие графики и диаграммы:\n",
    "\n",
    "* гистограммы/коробчатые диаграммы числовых признаков;\n",
    "* столбчатые диаграммы медианных медицинских расходов в зависимости от категориальных признаков;\n",
    "* диаграммы рассеяния зависимости целевого признака от других числовых в разрезе категориальных (обратите особенное внимание на зависимость медицинских расходов от признака курения).\n",
    "\n",
    "Мы знаем, что модель линейной регрессии не умеет работать с категориальными признаками, поэтому категории **необходимо перекодировать**.\n",
    "\n",
    "Кодировку будем совершать по следующему принципу:\n",
    "\n",
    "* `smoker` — переведём в бинарные значения (`0` — некурящий, `1` — курящий);\n",
    "* `sex` — аналогично (`0` — female, `1` — male);\n",
    "* `region` — используем OneHot-кодирование (воспользуемся функцией `get_dummies`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker      charges  region_northeast  \\\n",
       "0   19    0  27.900         0       1  16884.92400                 0   \n",
       "1   18    1  33.770         1       0   1725.55230                 0   \n",
       "2   28    1  33.000         3       0   4449.46200                 0   \n",
       "3   33    1  22.705         0       0  21984.47061                 0   \n",
       "4   32    1  28.880         0       0   3866.85520                 0   \n",
       "\n",
       "   region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 1  \n",
       "1                 0                 1                 0  \n",
       "2                 0                 1                 0  \n",
       "3                 1                 0                 0  \n",
       "4                 1                 0                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['smoker'] = data['smoker'].apply(lambda x: 0 if x=='no' else 1)\n",
    "data['sex'] = data['sex'].apply(lambda x: 0 if x=='female' else 1)\n",
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили перекодированную таблицу, в которой все признаки являются числовыми.\n",
    "\n",
    "Выделим факторы и целевой признак в отдельные таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop('charges', axis=1).columns\n",
    "X, y = data[features], data['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1070, 9)\n",
      "Test shape: (268, 9)\n",
      "y_train: (1070,)\n",
      "y_test: (268,)\n"
     ]
    }
   ],
   "source": [
    "#Разделяем выборку на тренировочную и тестовую в соотношении 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))\n",
    "print('y_train: {}'.format(y_train.shape))\n",
    "print('y_test: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.742\n",
      "Train MAE: 4208.235\n",
      "Train MAPE: 42.203\n",
      "\n",
      "\n",
      "Test R^2: 0.784\n",
      "Test MAE: 4181.194\n",
      "Train MAPE: 46.888\n",
      "w0: -12390.804294570275\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(y_train, y_train_predict, y_test, y_test_predict):\n",
    "    print('Train R^2: {:.3f}'.format(metrics.r2_score(y_train, y_train_predict)))\n",
    "    print('Train MAE: {:.3f}'.format(metrics.mean_absolute_error(y_train, y_train_predict)))\n",
    "    print('Train MAPE: {:.3f}'.format(metrics.mean_absolute_percentage_error(y_train, y_train_predict)*100))\n",
    "    print('\\n')\n",
    "    print('Test R^2: {:.3f}'.format(metrics.r2_score(y_test, y_test_predict)))\n",
    "    print('Test MAE: {:.3f}'.format(metrics.mean_absolute_error(y_test, y_test_predict)))\n",
    "    print('Train MAPE: {:.3f}'.format(metrics.mean_absolute_percentage_error(y_test, y_test_predict)*100))\n",
    "\n",
    "#Инициализируем объект класса линейная регрессия\n",
    "lr = linear_model.LinearRegression()\n",
    "#Обучаем модель - ищем параметры\n",
    "lr.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "#Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "#Выводим результирующие метрики\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print('w0: {}'.format(lr.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Визуализируем ошибки\n",
    "fig, ax = plt.subplots(figsize=(12, 6)) #фигура+координатная плоскость\n",
    "\n",
    "y_train_errors = y_train - y_train_pred\n",
    "\n",
    "y_test_errors = y_test - y_test_pred\n",
    "predict_df = pd.DataFrame(\n",
    "    {'Train errors':y_train_errors,\n",
    "     'Test errors':y_test_errors\n",
    "    }\n",
    ")\n",
    "\n",
    "sns.boxplot(data=predict_df, ax=ax)\n",
    "ax.set_xlabel('Model errors') #название оси абсцисс\n",
    "ax.set_ylabel('Model'); #название оси ординат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1070, 54)\n",
      "Test shape: (268, 54)\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект для min-max нормализации\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "#Вычисляем параметры для нормализации - min и max для каждого столбца\n",
    "scaler.fit(X_train)\n",
    "#Производим преобразование для каждой из выборок\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Создаем объект для генерации полиномиальных признаков степени 2\n",
    "poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)\n",
    "#Вычисляем параметры генерации - результирующее количество признак\n",
    "poly.fit(X_train_scaled)\n",
    "#Производим преобразование для каждой из выборок\n",
    "X_train_scaled_poly = poly.transform(X_train_scaled)\n",
    "X_test_scaled_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "print('Train shape: {}'.format(X_train_scaled_poly.shape))\n",
    "print('Test shape: {}'.format(X_test_scaled_poly.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.842\n",
      "Train MAE: 2882.546\n",
      "Train MAPE: 29.183\n",
      "\n",
      "\n",
      "Test R^2: 0.867\n",
      "Test MAE: 2720.547\n",
      "Train MAPE: 29.982\n",
      "w0: -12390.804294570275\n"
     ]
    }
   ],
   "source": [
    "lr_1 = linear_model.LinearRegression()\n",
    "#Обучаем модель - ищем параметры\n",
    "lr_1.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = lr_1.predict(X_train_scaled_poly)\n",
    "y_test_pred = lr_1.predict(X_test_scaled_poly)\n",
    "#Выводим результирующие метрики\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)\n",
    "print('w0: {}'.format(lr.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2: 0.867\n",
      "Test MAE: 2719.334\n",
      "Test MAPE: 30.070\n"
     ]
    }
   ],
   "source": [
    "#Создаём объект класса линейной регрессии с L1-регуляризацией\n",
    "lasso_lr_poly = linear_model.Lasso(max_iter=2000)\n",
    "#Обучаем модель\n",
    "lasso_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для тренировочной выборки\n",
    "y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)\n",
    "#Делаем предсказание для тестовой выборки\n",
    "y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)\n",
    "#Рассчитываем коэффициент детерминации для двух выборок\n",
    "\n",
    "print(\"Test R^2: {:.3f}\".format(metrics.r2_score(y_test, y_test_predict_poly)))\n",
    "print(\"Test MAE: {:.3f}\".format(metrics.mean_absolute_error(y_test, y_test_predict_poly)))\n",
    "print(\"Test MAPE: {:.3f}\".format(metrics.mean_absolute_percentage_error(y_test, y_test_predict_poly)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.839\n",
      "Train MAE: 2948.804\n",
      "Train MAPE: 29.546\n",
      "\n",
      "\n",
      "Test R^2: 0.863\n",
      "Test MAE: 2860.555\n",
      "Train MAPE: 31.380\n"
     ]
    }
   ],
   "source": [
    "#Инициализируем объект класса линейная регрессия с L2-регуляризацией \n",
    "ridge_lr_poly = linear_model.Ridge()\n",
    "#Обучаем модель предсказывать логарифм целевого признака\n",
    "ridge_lr_poly.fit(X_train_scaled_poly, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "#Если обучили на логарифме, то от результата необходимо взять обратную функцию - экспоненту\n",
    "y_train_pred = ridge_lr_poly.predict(X_train_scaled_poly)\n",
    "y_test_pred = ridge_lr_poly.predict(X_test_scaled_poly)\n",
    "#Выводим результирующие метрики\n",
    "print_metrics(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Итоги <a class=\"anchor\" id=7></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "## ДОПОЛНИТЕЛЬНО:\n",
    "\n",
    "* [Десять датасетов для практики работы с линейной регрессией](https://www.telusinternational.com/articles/10-open-datasets-for-linear-regression)\n",
    "* [Базовые принципы машинного обучения на примере линейной регрессии](https://habr.com/ru/company/ods/blog/322076/)\n",
    "* [Регрессионные модели в Python](https://nagornyy.me/it/regressionnye-modeli-v-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3380a37b4678e1f5e651331348d62bc6038aef0d5f414da260f404a34792558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
