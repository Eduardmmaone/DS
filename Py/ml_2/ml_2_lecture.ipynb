{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-2 Обучение с учителем. Регрессия\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Линейная регрессия. Аналитическое решение](#2)\n",
    "- [3. Метрики регрессии. Недостатки аналитического решения](#3)\n",
    "- [4. Линейная регрессия. Численные решения](#4)\n",
    "- [5. Дилемма смещения и разброса. Полигональные признаки. Регуляризация](#5)\n",
    "- [6. Линейная регрессия. Практика](#6)\n",
    "- [7. Итоги](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение <a class=\"anchor\" id=1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "<img src=ml2_img1.png width=900>\n",
    "\n",
    "В категории обучения с учителем модели можно условно разделить на следующие основные типы:\n",
    "\n",
    "* **Линейные модели:** линейная регрессия (для задачи регрессии) и логистическая регрессия (для задачи классификации) и производные от них.\n",
    "* **«Древесные» модели:** дерево решений и производные от него. \n",
    "* **Метрические алгоритмы:** метод ближайших соседей и производные от него.\n",
    "* **Байесовские методы:** метод наивного Байеса и производные от него.\n",
    "* **Ансамблевые методы:** композиции из методов (бэггинг, стекинг, бустинг).\n",
    "\n",
    "В этом модуле мы поговорим о **линейных моделях** (но на самом деле ими не ограничимся), которые позволяют решать задачу регрессии.\n",
    "\n",
    ">**Линейные модели** — это модели, отображающие зависимость целевого признака от факторов в виде линейной взаимосвязи.\n",
    "\n",
    "<img src=ml2_img2.png width=900>\n",
    "\n",
    ">На данном графике мы видим зависимость цены товара от его размера. Из диаграммы рассеяния видно, что в среднем точки расположены на одной прямой линии. То есть зависимость линейная.\n",
    "\n",
    "Подкласс линейных моделей в свою очередь содержит множество конкретных моделей. В библиотеке `sklearn`, которую мы будем использовать, все линейные алгоритмы содержатся в модуле [linear_model](https://scikit-learn.ru/1-1-linear-models/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Линейная регрессия. Аналитическое решение <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "`Регрессия` — это класс задач обучения с учителем, когда по определённому набору признаков объекта необходимо предсказать числовую целевую переменную.\n",
    "\n",
    "`Цель обучения` — построить модель, которая бы отражала зависимость между признаками и целевой числовой переменной.\n",
    "\n",
    "Когда зависимость принимается линейной, такая модель называется `линейной регрессией`.\n",
    "\n",
    "## ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ЛИНЕЙНОЙ РЕГРЕССИИ\n",
    "\n",
    "**Линейная регрессия** (`Linear Regression`) — одна из простейших моделей для решения задачи регрессии. Главная гипотеза состоит в том, что рассматриваемая зависимость является линейной.\n",
    "\n",
    "Общий вид модели в случае, когда целевая переменная зависит от `m` факторов, будет иметь следующий вид:\n",
    "\n",
    "<img src=ml2_img3.png>\n",
    "\n",
    "Давайте разбираться, что в этом выражении значит каждая из переменных. Начнём с простого — с двумерного случая.\n",
    "\n",
    "### 2D-СЛУЧАЙ\n",
    "\n",
    "Для начала поговорим о самом простом случае, когда у нас есть один фактор и зависящий от него целевой признак. Геометрически такая зависимость представляет собой координатную плоскость, где мы отмечаем точки по оси `x` и соответствующие им точки на оси `y`.\n",
    "\n",
    ">Рассмотрим задачу из нефтяной отрасли. Есть набор данных, где представлены данные о средней пористости скважин (в процентах) и добыче газа на этих скважинах в сутки (в миллионах кубических футов). \n",
    "\n",
    "Нам бы хотелось построить модель, которая опишет зависимость и позволит по известной пористости скважин предсказывать неизвестную выработку газа.\n",
    "\n",
    "Зависимость целевого признака от фактора представлена на диаграмме рассеяния (см. ниже). Пористость скважины отложена по оси абсцисс — `Porosity (%)`, а добыча газа — по оси ординат, `Gas production (Mcf/day)`.\n",
    "\n",
    "<img src=ml2_img4.png>\n",
    "\n",
    "Из диаграммы отчётливо видно, что с ростом пористости скважины растёт добыча газа. Причём растёт она преимущественно линейно: основная масса точек находится на одной прямой.\n",
    "\n",
    ">Идея! Давайте проведём через точки прямую линию так, чтобы она максимально хорошо описывала зависимость.\n",
    "\n",
    "Для этого сначала вспомним уравнение прямой из школьного курса математики:\n",
    "\n",
    "`y = kx + b`\n",
    "\n",
    "где:\n",
    "\n",
    "* `x` — это некоторый фактор, от которого зависит целевая переменная `y`. В нашем случае, `x` — это пористость скважины, а `y` — добыча газа.\n",
    "* `k` — коэффициент наклона прямой (**тангенс угла наклона**). Если `k > 0`, это означает, что угол наклона прямой острый и прямая возрастает. Если `k < 0`, угол наклона тупой и прямая убывает.\n",
    "* `b` — коэффициент смещения прямой по оси `y`. Он будет соответствовать значению `y` при `x = 0`. То есть это точка пересечения прямой и оси `Y`.\n",
    "\n",
    "<img src=ml2_img5.png>\n",
    "\n",
    "<img src=ml2_img6.png>\n",
    "\n",
    "Это уравнение и есть двумерная модель линейной регрессии. Зная коэффициенты `k` и `b`, мы можем подставить в него любую пористость скважины `x` и получить предсказание добычи газа `y`.\n",
    "\n",
    "Однако в машинном обучении приняты немного другие обозначения. Фактическое значение целевой переменной обозначается как `y`, а вот предсказанное моделью — `y^`. Также для удобства коэффициенты `k`и `b` приведём к единому обозначению: `w0 = k` и `w1 = b`. Тогда уравнение модели линейной регрессии запишется в виде:\n",
    "\n",
    "<img src=ml2_img7.png>\n",
    "\n",
    ">**Примечание. Коэффициенты `w0` и `w1` называются параметрами линейной регрессии**.\n",
    "\n",
    "Остаётся только один вопрос: откуда, собственно, взять параметры `w0` и `w1`? Обсудим этот вопрос чуть позже.\n",
    "\n",
    "А пока представим, что параметры мы нашли. В таком случае можно построить прямую, которая опишет нашу зависимость. Пусть коэффициенты составляют (мы их нашли сами по методу наименьших квадратов, о котором поговорим ниже):\n",
    "\n",
    "`w0 = -2.94`\n",
    "\n",
    "`w1 = 287.7`\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "`y^ = 287.7x - 2.94`\n",
    "\n",
    "Если подставлять значения конкретные значения пористости `x` в модель, можно построить прямую, которая описывает исходную зависимость. Это и будет графическая интерпретация нашей модели:\n",
    "\n",
    "<img src=ml2_img8.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D-СЛУЧАЙ\n",
    "\n",
    "Теперь представим, что у нас не один фактор, а два. Например, помимо пористости скважины, мы дополнительно знаем ещё и о её хрупкости в процентах. То есть у нас теперь есть два фактора: `x1` — пористость и `x2` — хрупкость.\n",
    "\n",
    "Можно отобразить такую зависимость добычи газа от этих факторов в трёхмерном пространстве в виде диаграммы рассеяния:\n",
    "\n",
    "<img src=ml2_img9.png>\n",
    "\n",
    "В таком случае в выражение для модели добавится ещё одна переменная`x2` и соответствующий ей коэффициент `w2`:\n",
    "\n",
    "Опять же, представим, что параметры модели мы нашли и они равны:\n",
    "\n",
    "`w0 = -2003`\n",
    "\n",
    "`w1 = 302.3`\n",
    "\n",
    "`w1 = 31.38`\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "`y^ = 302.2x1 + 31.38x2 - 2003`\n",
    "\n",
    "Это была алгебра — теперь перейдём к геометрии. Геометрически данное уравнение описывает плоскость в трёхмерном пространстве с осями `x1` и `x2`, `w0` — смещение плоскости по вертикальной оси, а коэффициенты `w1` и `w2` — коэффициенты наклона этой плоскости к осям `x1` и `x2`. \n",
    "\n",
    "То это это будет плоскость, которая подстроена под точки в трёхмерном пространстве:\n",
    "\n",
    "<img src=ml2_img10.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ОБЩИЙ СЛУЧАЙ\n",
    "\n",
    "А что если факторов не два, а больше: 3, 15, 100? Тут-то мы и приходим к общему виду модели линейной регрессии, который вводили в самом начале. Пусть у нас есть `m` факторов `{x1, x2, ..., xm}`, от которых зависит целевая переменная `y`.\n",
    "\n",
    "<img src=ml2_img11.png>\n",
    "\n",
    "В геометрическом смысле данное уравнение описывает плоскость в `(m - 1)`-мерном пространстве (`m` факторов + `1` целевой признак отложены по осям координат). Такую плоскость называют **гиперплоскостью**.\n",
    "\n",
    "Абстрактное `(m - 1)`-мерное пространство, конечно же, невозможно отобразить графически и сложно даже представить, как оно выглядит. Но нам это и не нужно. Все операции в таком пространстве аналогичны операциям в двумерном или трёхмерном пространстве.\n",
    "\n",
    ">Для понимания принципа работы мы будем рассматривать только прямую в двумерном пространстве, а результат уже обобщать на случай с большей размерностью.\n",
    "\n",
    "Стоит отметить, что в `DS` мы, как правило, работаем с большим количеством факторов (больше двух), которые описывают данные, поэтому отобразить модель в геометрическом пространстве не получится, но важно понимать, что представляет собой сама модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПОИСК ПАРАМЕТРОВ ЛИНЕЙНОЙ РЕГРЕССИИ: МЕТОД НАИМЕНЬШИХ КВАДРАТОВ\n",
    "\n",
    ">Теперь мы знаем, как выглядит модель линейной регрессии в общем случае: это простое линейное выражение, подставляя в которое значения факторов, можно найти целевую переменную. Это линейное выражение соответствует прямой, плоскости или гиперплоскости в зависимости от количества признаков.\n",
    "\n",
    "Остаётся вопрос: откуда взять коэффициенты, которые стоят при `x`?\n",
    "\n",
    "Прямую же можно провести как угодно. Вот например несколько прямых, построенных с различными случайными коэффициентами:\n",
    "\n",
    "<img src=ml2_img12.png>\n",
    "\n",
    "Какие параметры будут наилучшими?\n",
    "\n",
    "Для ответа на этот вопрос давайте вспомним схему обучения моделей машинного обучения по принципу минимизации эмпирического риска, которую мы рассматривали в предыдущем модуле:\n",
    "\n",
    "<img src=ml2_img13.png width=900>\n",
    "\n",
    "Согласно данной схеме обучения, поиск параметров производится путём минимизации некоторой **функции ошибки**. Математически мы пытаемся с помощью методов оптимизации найти такие параметры, чтобы ошибка была наименьшей из возможных.\n",
    "\n",
    "Осталось только понять: **где взять эту функцию ошибки**? Ответ кроется в картинке ниже. Давайте представим, как могла бы выглядеть прямая в двумерном пространстве, проведённая, например, через пять точек:\n",
    "\n",
    "<img src=ml2_img14.png>\n",
    "\n",
    ">Что вообще есть **ошибка**? В самом простом понимании это расхождение между истиной и предсказанием.\n",
    "\n",
    "Чтобы не учитывать знак расхождения, можно взять модуль разницы между истинным значением и предсказанным (тем, что лежит на прямой). Рассчитать ошибки  `e_i` (на рисунке они отмечены красными отрезками) для всех пяти точек можно следующим образом:\n",
    "\n",
    "<img src=ml2_img15.png>\n",
    "\n",
    ">Тут-то математики и столкнулись с проблемой. Оказывается, если пытаться решить эту оптимизационную задачу классическими способами (через условия экстремума функции), то поиск решения будет противоречить основным законам математического анализа. Почему? Обсудим это в модулях по математике, когда будем решать оптимизационные задачи.\n",
    "\n",
    "<img src=ml2_img16.png>\n",
    "\n",
    "Математике известно решение данной задачи оптимизации. Метод поиска параметров линейной регрессии называется методом наименьших квадратов (сокращённо — `МНК`) и был изобретён **Гауссом** ещё в **1795 году**. В английской литературе часто можно встретить аббревиатуру `OLS` (`Ordinary Least Squares`).\n",
    "\n",
    ">Решать саму задачу поиска минимума функции мы сейчас не будем, так как пока что не владеем достаточными для её решения знаниями о частной производной и условиях экстремума функции многих переменных, но приведём финальный ответ, полученный для общего случая.\n",
    "\n",
    "Итак, пусть у нас есть матрица `X`, в которой по строкам собрано `n` наблюдений, а по столбцам отложено `m` факторов — по сути, это обычный, привычный нам `DataFrame`. К каждому примеру из таблицы `X` есть ответ `y`.\n",
    "\n",
    "Зависимость между факторами и целевым признаком принята линейной, то есть рассматривается обучение модели линейной регрессии:\n",
    "\n",
    "<img src=ml2_img17.png>\n",
    "\n",
    "Мы хотим найти наилучшую оценку для `w0`, `w1`, `w2`, ...m `w_m`.\n",
    "\n",
    ">Примечание. Для того чтобы конечная запись формулы была короче и можно было включить в вектор `w-` коэффициент смещения прямой `w0`, в матрицу `X` первым добавляют столбец, полностью состоящий из единиц. Это связано со спецификой матричного умножения, о котором мы поговорим далее в курсе.\n",
    "\n",
    "Согласно методу наименьших квадратов, аналитическое выражение для поиска вектора коэффициентов уравнения линейной регрессии имеет вид:\n",
    "\n",
    "<img src=ml2_img18.png>\n",
    "\n",
    "Саму процедуру обращения матриц мы будем рассматривать в модуле по линейной алгебре. Сейчас же для проведения этой операции мы будем использовать библиотеку numpy, которая позволяет очень быстро и просто обращать матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Метрики регрессии. Недостатки аналитического решения <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Линейная регрессия. Числовые решения <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Дилемма смещения и разброса. Полигональные признаки. Регуляризация <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Линейная регрессия. Практика <a class=\"anchor\" id=6></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Итоги <a class=\"anchor\" id=7></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3380a37b4678e1f5e651331348d62bc6038aef0d5f414da260f404a34792558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
