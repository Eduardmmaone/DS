{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-5 Валидация данный и оценка моделей\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Валидация данных. Методы валидации](#2)\n",
    "- [2.1 hold-out (отложенная выборка)](#2-1)\n",
    "- [2.2 k-fold (кросс валидация)](#2-2)\n",
    "- [2.3 leave-one-out (отложенный пример)](#2-3)\n",
    "- [3. Дисбаланс выборки](#3)\n",
    "- [4. Недообучение и переобучение. Утечка данных](#4)\n",
    "- [5. Кривая обучения](#5)\n",
    "- [6. Практика](#6)\n",
    "- [7. Итоги](#7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. # Валидация данных. Методы валидации <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "**Главная цель машинного обучения** — усвоить общие закономерности в данных, а не просто запомнить обучающий, или тренировочный, набор данных (training data).\n",
    "\n",
    "Поэтому так важно иметь отложенный набор данных (с известными правильными ответами), который модель не видела во время обучения. На нём мы будем оценивать качество обученной модели.\n",
    "\n",
    ">В предыдущих модулях по машинному обучению тот набор данных, на котором мы проверяли качество построенной модели, мы называли тестовым набором данных (`testing data`). Мы заранее выделяли этот набор данных для того, чтобы рассчитать финальную метрику модели и сделать вывод о том, устраивает ли нас качество моделирования. Такой подход называется `двухкомпонентным`.\n",
    "\n",
    "<img src=ml5_img1.png width=400>\n",
    "\n",
    ">**Примечание**. Ранее мы использовали тестовый набор не только для проверки итогового качества, но и для подбора внешних параметров. Вспомните: мы выбирали оптимальные пороги вероятности и коэффициенты регуляризации, при которых наблюдался максимум целевой метрики (мы использовали `F1`-меру). \n",
    ">\n",
    ">Однако такой подход не совсем корректен, ведь мы подстраивали модель под тестовую выборку, то есть по сути занимались небольшим самообманом. Тестовая выборка должна быть «независимым судьёй», который должен объективно и непредвзято «выносить приговор» нашей модели.\n",
    "\n",
    "Из-за этого в больших Data Science-проектах используется не два, а три набора данных: в дополнение к тренировочному и тестовому набору данных выделяется **валидационный набор** (`validation data`). Этот набор используется для промежуточного контроля качества модели и настройки внешних параметров, которые задаёт исследователь при построении модели. Такой подход называется трёхкомпонентным.\n",
    "\n",
    "<img src=ml5_img2.jpg width=400>\n",
    "\n",
    "## Итак, существует три основных вида выборок, которые используются в машинном обучении:\n",
    "\n",
    "1. **Обучающая (тренировочная)** — набор данных, который используется в процессе обучения модели (подбора внутренних параметров, например коэффициентов линейной регрессии или предикатов в деревьях решений).\n",
    "\n",
    "2. **Валидационная (проверочная)** — набор данных, на котором мы оцениваем промежуточные результаты обучения.\n",
    "\n",
    "Основная цель создания такого набора данных — отслеживание переобучения.\n",
    "\n",
    "На валидационной выборке мы производим подбор гиперпараметров — внешних параметров модели, например коэффициентов регуляризации, максимальной глубины дерева, количества деревьев в случайном лесу и т. д.\n",
    "\n",
    "3. **Тестовая (контрольная)** — набор данных, который имитирует работу модели в реальных условиях после подбора всех параметров.\n",
    "\n",
    "С помощью этого набора осуществляется окончательная проверка качества.\n",
    "\n",
    "Главное условие для тестовой выборки — она должна быть независимой от обучающей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## ОСОБЕННОСТИ ТЕРМИНОЛОГИИ\n",
    ">\n",
    ">В промышленности, научных кругах и различной литературе термины **валидационная** и **тестовая выборка** зачастую употребляются как синонимы. Строго говоря, они не являются таковыми.\n",
    ">\n",
    ">**Тестирование** — это попытка что-то выяснить, а **валидация** — доказать, что что-то является истиной (в нашем случае — доказать, что качество модели на валидационной выборке совпадает с качеством при обучении).\n",
    ">\n",
    ">Вне зависимости от того, как будут называться контрольные выборки, важная концепция, которую необходимо сохранить, состоит в том, что окончательный набор (называемый тестом или валидацией) не используется в процессе обучения модели, а используется исключительно для оценки её качества.\n",
    "\n",
    "Процесс проверки предсказательной способности модели машинного обучения называется `валидацией`.\n",
    "\n",
    "Существует несколько методов такого контроля. Мы последовательно рассмотрим каждый из них.\n",
    "\n",
    "Но прежде чем мы перейдём к обсуждению методов валидации, давайте познакомимся с данными, на которых будем практиковаться\n",
    "\n",
    "В этом модуле мы будем решать задачу классификации: классифицировать воду на пригодную  и не пригодную для питья на основе её химического состава.\n",
    "\n",
    "Скачать набор данных можно [здесь](https://lms.skillfactory.ru/assets/courseware/v1/9cd645af21ef409ff23bf03a783b4b71/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/water_potability.zip). С подробным описанием датасета и столбцов таблицы ознакомьтесь [в источнике](https://www.kaggle.com/datasets/adityakadiwal/water-potability).\n",
    "\n",
    "Переходим к работе с данными. Импортируем модули, которые нам понадобятся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data = pd.read_csv('water_potability.zip')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что большинство столбцов таблицы являются числовыми. Целевой признак — `Potability` (пригодность для питья): `1` — вода пригодна, `0` — вода не пригодна.\n",
    "\n",
    "В данных есть пропуски. Выведем информацию о них в процентном соотношении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас отсутствует около `15 %` информации о кислотности воды (`ph`), около` 24 %` — о содержании сульфатов (`Sulfate`) и около `5 %` — о тригалометанах (`Trihalomethanes`). Мы знаем, что пропуски — непосильная ноша для большинства моделей машинного обучения. Их необходимо обработать.\n",
    "\n",
    "Заполним пропуски медианным значением в признаке зависимости класса воды (`Potability`). Для этого сгруппируем данные по признаку `Potability`, посчитаем медиану в каждой группе, а затем отправим результат в метод `fillna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))\n",
    "\n",
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проблема пропусков устранена. Давайте по традиции разделим набор данных на матрицу наблюдений `X` и вектор правильных ответов `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLD-OUT <a class=\"anchor\" id=2-1></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Метод `hold-out` (отложенная выборка) нам уже знаком. Это самый простой и очень популярный метод.\n",
    "\n",
    "Его идея состоит в том, что для проверки модели мы просто случайным образом разбиваем весь набор данных на обучающую, валидационную и тестовую выборки (последняя — по желанию).\n",
    "\n",
    "Обычно разбиение производится в соотношении `70/30` или `80/20` при двухкомпонентном подходе, и в соотношении `70/15/15` или `80/10/10` — при трёхкомпонентном.\n",
    "\n",
    "Схема разбиения представлена ниже:\n",
    "\n",
    "<img src=ml5_img3.png>\n",
    "\n",
    "## Плюсы:\n",
    "\n",
    "* Очень простой и понятный.\n",
    "\n",
    "* Чаще всего применяется на больших датасетов, так как требует значительно меньше вычислительных мощностей, чем другие методы.\n",
    "\n",
    "## Минусы:\n",
    "\n",
    "* Важно помнить, что разбиение производится случайным образом и оценка в этом методе зависит от того, какие наблюдения попали в набор для валидации. Это плохо, так как возможна ситуация, когда распределение целевого признака в тренировочной, валидационной (и тестовой) выборках может значительно различаться и оценка качества может быть необъективной.\n",
    "\n",
    "## РЕАЛИЗАЦИЯ МЕТОДА В `SKLEARN`\n",
    "\n",
    "Все методы разбиения выборки и валидации, которые мы будем изучать, находятся в модуле `model_selection`, мы импортировали его заранее.\n",
    "\n",
    "Метод hold-out реализован в уже знакомой вам функции [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Она предназначена для разбиения исходного набора данных случайным образом на две части в заданных соотношениях.\n",
    "\n",
    ">Основные параметры `train_test_split()`:\n",
    ">\n",
    ">* `*arrays` — порядковый аргумент с переменным количеством. Набор массивов (это могут быть списки, numpy-массивы, DataFrame), которые подлежат разбиению.\n",
    ">* `test_size` — размер тестовой (валидационной) выборки. Может быть указан в долях. Определяется автоматически, если параметр `test_size` передан как `1-train_size`.\n",
    ">* `train_size` — размер тренировочной выборки. Может быть указан в долях. Определяется автоматически, если параметр `test_size` передан как `1-test_size`.\n",
    ">* `random_state` — число, на основе которого производится генерация случайных чисел.\n",
    ">* `shuffle` — параметр, указывающий, стоит ли перемешивать выборку перед разбиением (по умолчанию `True`).\n",
    ">* `stratify` — стратифицированное разбиение (о нём мы поговорим в юните по дисбалансу выборки).\n",
    "\n",
    "Если мы используем двухкомпонентный подход (разбиваем выборку на тренировочную и валидационную, она же тестовая), то всё очень просто: нам лишь нужно вызвать функцию `train_test_split()` и передать в неё матрицу наблюдений `X` и вектор-столбец с правильными ответами `y`.\n",
    "\n",
    "Для примера разделим выборку в соотношении `80/20` (`test_size=0.2`), в качестве значения параметра `random_state` по традиции возьмём число `42`.\n",
    "\n",
    "Функция вернёт четыре массива:\n",
    "\n",
    "* таблицу `X` с обучающими примерами,\n",
    "* таблицу `X` с примерами для валидации,\n",
    "* столбец `y` с ответами на обучающие примеры,\n",
    "* столбец `y` с ответами на валидационные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, `2 620` образцов воды являются обучающими — в них модель будет искать закономерности и подбирать внутренние параметры, а `656` являются валидационными — на них мы будем производить контроль качества.\n",
    "\n",
    "Далее нам останется только обучить модель на тренировочной выборке (`X_train`, `y_train`) и рассчитать метрики на валидационной выборке (`X_valid`, `y_valid`).\n",
    "\n",
    "В качестве модели будем использовать дерево решений с максимальной глубиной `7`, `энтропией` в качестве критерия информативности, минимальное число объектов в листе дерева — `5`.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем `трёхкомпонентный` подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в `sklearn` нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию `train_test_split()` дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении `80/20`, затем разобьём валидационный набор на валидационный и тестовый в соотношении `50/50`. В итоге наша выборка будет разбита в соотношении `80/10/10`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD <a class=\"anchor\" id=2-2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    ">Метод `k-fold` более известен как `кросс-валидация` (`cross validation`), или перекрёстный контроль.\n",
    "\n",
    "Пожалуй, это самый **популярный метод валидации** для оценки качества моделирования, и он используется практически во всех проектах. Эта идея также применяется во многих моделях и методах машинного обучения, например в стекинге.\n",
    "\n",
    "Напомним алгоритм кросс-валидации:\n",
    "\n",
    "1. Разбить исходную выборку на `k` частей — **фолдов (fold)**.\n",
    "\n",
    "2. Повторять `k` раз:\n",
    "* Обучить модель на `k-1` частях. Назовём их тренировочными фолдами (`training fold`). \n",
    "* Произвести оценку качества (вычислить метрику) на оставшейся части. Назовем её валидационным фолдом (`validation fold`).\n",
    "\n",
    "3. Усреднить значения метрики на валидационных фолдах.\n",
    "\n",
    "\n",
    "Схематично алгоритм кросс-валидации можно представить следующим образом (на рисунке представлена схема работы кросс-валидации с предварительно выделенной для тестирования выборкой):\n",
    "\n",
    "<img src=ml5_img4.png>\n",
    "\n",
    "Благодаря такому подходу мы избавляемся от необходимости создавать отложенную валидационную выборку — мы генерируем её искусственно на каждом из этапов кросс-валидации из исходного набора данных. Каждая из `k` частей исходного обучающего набора данных используется в качестве валидационной выборки.\n",
    "\n",
    "Для больших наборов данных в качестве значения `k` часто берут `10`, то есть выборка разбивается на десять фолдов. В случае маленьких выборок `k` берут равным `3 или 5`.\n",
    "\n",
    ">Чем больше `k`, тем больше моделей будут обучаться, тем объективнее будет оценка качества, однако тем больше времени займёт процесс валидации.\n",
    "\n",
    "## Плюсы:\n",
    "\n",
    "* Подход позволяет получить более устойчивую к выбросам оценку качества модели, так как модель обучается на нескольких независимых наборах данных.\n",
    "\n",
    "* Значения метрик получаются более объективными, ведь мы обучаем одну модель `k` раз — у нас получается `k` независимых друг от друга значений метрики.\n",
    "\n",
    ">**Примечание**. Мы оцениваем метрику не по одному значению на валидационной выборке, как это было в `hold-out`, а по `k` значений. Если `k` достаточно велико, можно даже построить гистограмму и оценить, в каких пределах находится истинное качество. Однако на практике этим занимаются крайне редко, так как такие вычисления очень времязатратны.\n",
    "\n",
    "## Минусы:\n",
    "\n",
    "* Подход предусматривает, что мы обучаем одну и ту же модель `k` раз, что, очевидно, плохо сказывается на производительности. Если модель обучается довольно медленно (например, сложная нейронная сеть), то валидация может занять очень много времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РЕАЛИЗАЦИЯ МЕТОДА В SKLEARN\n",
    "\n",
    "В библиотеке `sklearn` метод `k-fold` реализован в классе `KFold`.\n",
    "\n",
    ">Основные параметры инициализатора `KFold`:\n",
    ">\n",
    ">* `n_split` —  число фолдов (число  из метода `k-fold`). По умолчанию — `5`.\n",
    ">* `shuffle` — параметр, указывающий, стоит ли перемешивать исходный набор данных перед разбиением. По умолчанию — `False`.\n",
    ">* `random_state` — число, на основе которого производится генерация случайных чисел, если набор данных будет перемешиваться.\n",
    "\n",
    "У объекта класса `KFold` есть метод `split()`. В данный метод необходимо передать матрицу наблюдений `X` и вектор-столбец ответов `y` — метод вернёт генератор, который позволит получать индексы тренировочной и валидационной выборок, сгенерированных по методу `k-fold`.\n",
    "\n",
    "Будем использовать двухкомпонентный контроль, то есть подавать в кросс-валидацию весь доступный набор данных без предварительного выделения тестовой выборки.\n",
    "\n",
    "Создадим объект `KFold` для кросс-валидации с пятью фолдами, остальные параметры оставим по умолчанию. Затем организуем цикл `for` для получения элементов из генератора, созданного с помощью метода `split()`. На каждой итерации в переменных `train_index` и `valid_index` будут находиться индексы текущей тренировочной и валидационной выборок соответственно.\n",
    "\n",
    ">**В цикле будем:**\n",
    ">\n",
    ">* выделять строки таблицы, относящиеся к текущим тренировочной и валидационной выборкам, в отдельные таблицы;\n",
    ">* обучать дерево решений;\n",
    ">* делать предсказания для текущих тренировочной и валидационной выборок;\n",
    ">* рассчитывать метрику accuracy на текущих выборках и заносить её значение в список.\n",
    "\n",
    "Код будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_metrics: [0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "val_metrics:  [0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "print('train_metrics:', train_metrics)\n",
    "print('val_metrics: ', val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В каждом из выведенных списков содержится по пять значений метрики `accuracy`, вычисленных на тренировочном и валидационном фолдах кросс-валидации. Для агрегированной оценки рассчитаем среднее значение метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, среднее значение метрики `accuracy` на кросс-валидации равно `0.81` для тренировочных фолдов и `0.74` — для валидационных фолдов. Помним о том, что основной показатель для нас — метрика на **валидационных фолдах** (если не предусмотрена тестовая выборка). \n",
    "\n",
    "Согласитесь, сложновато — не совсем в стиле `sklearn`. Тут и циклы, и генераторы... Неужели каждый раз придётся писать подобный код для проведения кросс-валидации?\n",
    "\n",
    "Конечно же, нет. На самом весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — [cross_validate()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) из модуля `model_selection`. Она организует процедуру кросс-валидации и расчёт метрик.\n",
    "\n",
    ">Основные параметры функции `cross_validate()`:\n",
    ">\n",
    ">* `estimator` — модель, качество которой будет проверяться на кросс-валидации.\n",
    ">* `X` — матрица наблюдений.\n",
    ">* `y` — вектор-столбец правильных ответов.\n",
    ">* `cv` — кросс-валидатор из библиотеки `sklearn` (например, `KFold`) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация на пяти фолдах.\n",
    ">* `scoring` — название метрики в виде строки либо функция для её вычисления ('`accuracy`', '`precision`', '`recall`', '`f1`' и другие; полный список — в документации к функции).\n",
    ">* `return_train_score` — параметр, указывающий стоит ли возвращать значения метрики, полученных на тренировочных фолдах. По умолчанию — `False`, то есть метрики считаются только на валидационных фолдах.\n",
    "\n",
    "Функция возвращает словарь со следующими ключами:\n",
    "\n",
    "* `fit_time` — время обучения модели на каждой итерации кросс-валидации;\n",
    "* `score_time` — время вычисления метрик на каждой итерации кросс-валидации;\n",
    "* `test_score` — значения метрик на валидационных фолдах;\n",
    "* `train_score` — значения метрик на тренировочных фолдах.\n",
    "\n",
    "Итоговый код с использованием функции `cross_validate()` будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01994634, 0.02094579, 0.01895118, 0.01894712, 0.01894832]),\n",
       " 'score_time': array([0.00099754, 0.00102639, 0.00099945, 0.00099635, 0.00199533]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В массивах, хранящихся по ключам `train_score` и `test_score`, содержится по пять значений метрики accuracy, полученных на тренировочных и валидационных фолдах соответственно на каждой итерации кросс-валидации. Давайте рассчитаем среднее и сравним его с результатом, полученным ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAVE-ONE-OUT <a class=\"anchor\" id=2-3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    ">Метод `leave-one-out` (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (`k-fold`), когда размер `k` равняется размеру всей выборки `k = n`, где `n` — количество примеров (строк в таблице).\n",
    "\n",
    "Алгоритм метода:\n",
    "\n",
    "1. Повторять  `n` раз:\n",
    " * Выбрать один случайный пример для валидации.\n",
    " * Обучить модель на всех оставшихся `n-1` примерах.\n",
    " * Произвести оценку качества (вычислить метрику) на отложенном примере.\n",
    "\n",
    "2. Усреднить значение метрик на всех примерах.\n",
    "\n",
    "<img src=ml5_img5.png>\n",
    "\n",
    "## Плюсы:\n",
    "\n",
    "* Идеально подходит для небольших датасетов (**менее 100 примеров**).\n",
    "\n",
    "* Поскольку все доступные данные используются как для обучения, так и для валидации, значения метрик наиболее объективны и надёжны.\n",
    "\n",
    "## Минусы:\n",
    "\n",
    "* Подход предусматривает, что мы обучаем одну и ту же модель `n` раз. Очевидно, что чем больше примеров в обучающем наборе данных, тем больше моделей мы будем обучать. Поэтому метод не подходит для оценки качества модели на больших наборах данных, поскольку становится **очень ресурсозатратным**.\n",
    ">**Примечание**. Тем не менее, в некоторых методах обучения вычисление leave-one-out получается заметно ускорить, и его использование становится возможным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РЕАЛИЗАЦИЯ МЕТОДА В `SKLEARN`\n",
    "\n",
    "В библиотеке `sklearn` метод `leave-one-out` реализован в классе `LeaveOneOut`. Параметров инициализации у данного класса нет.\n",
    "\n",
    "Работа с кросс-валидатором полностью идентична работе с `KFold`, который мы рассматривали ранее (цикл для организации кросс-валидации вручную будет выглядеть аналогично).\n",
    "\n",
    "Объект класса `LeaveOneOut` также можно передать в функцию `cross_validate()` для получения метрик на каждом из примеров. В случае с метрикой `accuracy` список будет состоять из 0 и 1 (0 — модель не угадала класс на отложенном примере, 1 — модель угадала класс на отложенном примере).\n",
    "\n",
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации `leave-one-out` будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые `500` наблюдений из исходной таблицы.\n",
    "\n",
    ">**Примечание**. Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу `X` и столбец `y` целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут.\n",
    "\n",
    "Итоговый код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X.iloc[:500], #матрица наблюдений X\n",
    "    y=y.iloc[:500], #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Примечание**. Метод `leave-one-out` можно реализовать и без использования специального класса — достаточно просто указать параметр `n_split=n` в инициализаторе `KFold`, где `n` — количество строк в таблице.\n",
    "\n",
    "<img src=ml5_img6.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. # Дисбаланс выборки <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. # Недообучение и переобучение. Утечка данных <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. # Валидация данных. Методы валидации <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. # Практика <a class=\"anchor\" id=6></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. # Итоги <a class=\"anchor\" id=7></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3380a37b4678e1f5e651331348d62bc6038aef0d5f414da260f404a34792558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
