{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495530808754976"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.1\n",
    "\n",
    "(1.1 * 5.1 + 2.3 * 6.2 + 5.1 * 1.1) / ((1.2**2 + 2.3**2 + 5.1**2)**0.5 * (5.1**2 + 6.2**2 + 1.1**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7787, 17905)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.2\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('netflix_titles.zip')\n",
    "model = TfidfVectorizer(stop_words='english')\n",
    "df['description'] = df['description'].fillna('')\n",
    "feature_matrix = model.fit_transform(df['description'])\n",
    "\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)\n",
    "indices = pd.Series(df.index,index=df['title']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return df['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709                Balto 2: Wolf Quest\n",
       "7446                           Vroomiz\n",
       "1338    Chilling Adventures of Sabrina\n",
       "7388                          Vampires\n",
       "1770                          Dinotrux\n",
       "2767                     Hold the Dark\n",
       "5540                 Shanghai Fortress\n",
       "4041                             Mercy\n",
       "2582                       Half & Half\n",
       "1365        Christmas in the Heartland\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.3\n",
    "\n",
    "get_recommendations('Balto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
    "\n",
    "data = Dataset.load_from_file(\n",
    "    \"u.data.txt\",\n",
    "    reader=Reader(line_format=\"user item rating timestamp\", sep=\"\\t\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.1\n",
    "\n",
    "df.apply('nunique')\n",
    "\n",
    "# 1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.2\n",
    "\n",
    "df.apply('nunique')\n",
    "\n",
    "# 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.3\n",
    "\n",
    "df['rating'].value_counts()\n",
    "\n",
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# в collab загрузим файл `u.data.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
    "\n",
    "data = Dataset.load_from_file(\n",
    "    \"u.data.txt\",\n",
    "    reader=Reader(line_format=\"user item rating timestamp\", sep=\"\\t\"),\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)\n",
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.4\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)\n",
    "len(testset)\n",
    "\n",
    "# 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.5\n",
    "\n",
    "from surprise import SVD, KNNBasic, accuracy\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "predictions\n",
    "\n",
    "#1.\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction.uid == '500' and prediction.iid == '699':\n",
    "        print(prediction.r_ui)\n",
    "        print(round(prediction.est, 2))\n",
    "        break\n",
    "    \n",
    "# 3    \n",
    "    \n",
    "# 2.\n",
    "uid = str(500)\n",
    "iid = str(699)  \n",
    "pred = knn.predict(uid, iid, verbose=True)\n",
    "\n",
    "# 3.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.6\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True\n",
    "}\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.7\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
