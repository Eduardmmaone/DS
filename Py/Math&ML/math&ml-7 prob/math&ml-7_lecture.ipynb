{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH&ML-7 Теория вероятностей в контексте наивного байесовского классификатора.\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "\n",
    "- [1. Введение](#2)\n",
    "- [2. Классическая верочтность. Сложение и умножение](#2)\n",
    "- [3. Условная вероятность](#3)\n",
    "- [4. Полная вероятность](#4)\n",
    "- [5. Теорема Байеса](#5)\n",
    "- [6. Наивный бейсовский классификатор: практика](#6)\n",
    "- [7. Случайная величина и её характеристики](#7)\n",
    "- [8. Дискретные распределения](#8)\n",
    "- [9. Неприрывные распределения](#9)\n",
    "- [10. Итоги](#10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Введение <a class=\"anchor\" id=0></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    ">**Детерминированность** — это ситуация, в которой одно и то же действие всегда приводит к одному и тому же результату."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но что, если вы бросаете два кубика и делаете ставку на сумму? Какое число выбрать для ставки?\n",
    "\n",
    "Может показаться, что сумма очков на двух равновероятных кубиках также равновероятна, но это не так: 6 и 7 будут выпадать гораздо чаще, чем 2 или 12. Для наглядности можно отобразить все возможные комбинации в таблице:\n",
    "\n",
    "|  | **1** | **2** | **3** | **4** | **5** | **6** |\n",
    "| - | - | - | - | - | - | - |\n",
    "| **1** |(1,1)|(1,2)|(1,3)|(1,4)|(1,5)|(1,6)|\n",
    "| **2** |(2,1)|(2,2)|(2,3)|(2,4)|(2,5)|(2,6)|\n",
    "| **3** |(3,1)|(3,2)|(3,3)|(3,4)|(3,5)|(3,6)|\n",
    "| **4** |(4,1)|(4,2)|(4,3)|(4,4)|(4,5)|(4,6)|\n",
    "| **5** |(5,1)|(5,2)|(5,3)|(5,4)|(5,5)|(5,6)|\n",
    "| **6** |(6,1)|(6,2)|(6,3)|(6,4)|(6,5)|(6,6)|\n",
    "\n",
    "Как видите, для того, чтобы выпало 12 , нужны две шестёрки, а, например, для 7 есть много вариантов, поэтому шанс угадать больше. Но насколько больше? В целом, поскольку у нас выписаны все варианты, мы можем примерно понять, насколько чаще в сумме будет выпадать 7, а не 12.\n",
    "\n",
    "<img src=m7_img1.png width=300>\n",
    "\n",
    "Тогда всё становится ещё сложнее. Выписывать все варианты мы уже не сможем, так как их слишком много.\n",
    "\n",
    "<img src=m7_img2.png width=600>\n",
    "\n",
    ">Здесь нам уже понадобится **теория вероятностей** — наука, которая позволяет сделать предположения о более простых вероятностях (об очках на одном кубике) и на их основе математически вывести гораздо более сложные (об очках на нескольких кубиках). К примеру, теория вероятностей помогает ответить на вопрос: «На что ставить, чтобы увеличить шансы на выигрыш?»"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не случайно начали юнит с примера про кубики: именно попытки предсказать вероятности выигрыша в такие азартные игры, как игральные кости или орлянка несколько столетий назад дали стимул развитию этой области математики. Но, разумеется, теория вероятностей широко используется и по сей день и может быть полезна не только для того, чтобы оценить свои шансы в казино.\n",
    "\n",
    "Изучение вероятности важно, так как она имеет дело с количественными оценками ситуаций с неопределёнными результатами.\n",
    "\n",
    "* При **производстве** какого-то продукта всегда неясно, получится ли он с дефектом. Тестирование каждого продукта, который должен выйти в продажу, было бы невероятно дорогим и трудозатратным. Однако понимание вероятности дефекта позволяет заранее заложить её в издержки и проработать политику решения ситуаций с бракованными товарами.\n",
    "\n",
    "* Также всякий раз, когда человек вкладывает деньги в акции, он, осознавая это или нет, занимается оценками вероятностей. Каждая **инвестиция** имеет некоторую степень неопределённости: никто не может быть уверен, какова будет стоимость акций в будущем. Инвестируя деньги в акции, вы, по сути, предполагаете высокую вероятность того, что эти акции вырастут в цене. Продажа же акций означает, что вы оцениваете вероятность падения цены как довольно большую. Профессиональные финансовые аналитики, как правило, уделяют много внимания оценкам вероятности при просчёте своих рисков. Они используют исторические данные и огромный поток ежедневной информации, чтобы определить вероятность увеличения или уменьшения стоимости инвестиций.\n",
    "\n",
    "* Вероятностные модели также постоянно используются в **анализе данных**: в алгоритмах классификации и прогнозирования, а также при построении рекомендательных систем и в стохастических алгоритмах оптимизации.\n",
    "\n",
    "* Если мы хотим построить алгоритм, который будет рекомендовать фильмы пользователю сервиса, для каждого фильма необходимо рассчитать вероятности, выражающие соответствие фильма предпочтениям человека. После этого можно будет предложить пользователю те фильмы, у которых эти вероятности наибольшие.\n",
    "\n",
    "* Если вы сможете собрать данные о том, какие вопросы и как часто встречаются на собеседованиях на позицию специалистов по машинному обучению, то сможете предсказать вероятность столкнуться с задачей на тему данного модуля при трудоустройстве."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    ">Под **случайным экспериментом** понимается такой эксперимент, результат которого не детерминирован изначально.\n",
    "\n",
    "Предположим, если мы заходим на наш сайт в какой-то случайный момент времени и узнаём количество пользователей, находящихся на сайте в данный момент, мы совершаем случайный эксперимент, ведь заранее никак нельзя предугадать, сколько точно людей будет на сайте в то или иное время.\n",
    "\n",
    ">Приведём ещё несколько примеров случайных экспериментов:\n",
    ">\n",
    ">* подбрасывание игральной кости;\n",
    ">* вытаскивание карты из колоды;\n",
    ">* подсчёт числа людей, находящихся в помещении;\n",
    ">* выстрел по мишени;\n",
    ">* сдача студентом экзамена;\n",
    ">* запуск случайной песни из плейлиста.\n",
    "\n",
    "Все вышеперечисленные эксперименты объединяет то, что каждый раз мы не можем точно знать, что получится в итоге — результаты могут быть разными. Например, если мы открываем плейлист и просим плеер выбрать случайную песню, то в результате слышим одну из песен, которые мы уже выбрали ранее. Или, если мы берём колоду карт и вытягиваем одну из них, то в результате получаем карту какой-то определённой масти и достоинства.\n",
    "\n",
    ">Так появляется понятие **элементарного исхода** — любого возможного исхода случайного эксперимента. Например, если вернуться к примеру про количество пользователей на сайте, то все элементарные исходы — это все возможные количества посетителей на сайте.\n",
    ">\n",
    ">Разумеется, по результатам эксперимента обычно может получаться много различных результатов (элементарных исходов). Всё множество таких исходов носит называется пространством элементарных исходов и обычно обозначается буквой $\\Omega$ (омега).\n",
    "\n",
    "Ниже можно увидеть примеры случайных экспериментов и пространства элементарных исходов:\n",
    "\n",
    "| **СЛУЧАЙНЫЙ ЭКСПЕРИМЕНТ** | **ПРОСТРАНСТВО ЭЛЕМЕНТАРНЫХ ИСХОДОВ** |\n",
    "| - | - |\n",
    "| Сдача экзамена TOEFL | Любое число от 0 до 120 |\n",
    "| Бросок одного шестигранного кубика | 1, 2, 3, 4, 5, 6 |\n",
    "| Попытка устроиться на определённую должность | \t«Устроился» ли «не устроился» |\n",
    "| Подбрасывание монетки два раза | ОО, ОР, РО, РР, где Р — это решка, а О — орёл |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Классическая верочтность. Сложение и умножение <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Вероятностью случайного события $A$ называется отношение числа $n$ равновероятных элементарных исходов, составляющих событие $A$, к числу всех возможных элементарных исходов $N$:\n",
    "\n",
    "$P(A)=\\frac{n}{N}$\n",
    "\n",
    "Элементарные исходы, составляющие событие $A$, также очень часто называют исходами, **благоприятными или благоприятствующими для события** $A$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Вы работаете в компании, которая разрабатывает новое лекарство.\n",
    ">\n",
    ">В клинических испытаниях участвовали `2800` человек. Ухудшение состояния было зарегистрировано у `7` из них.\n",
    ">\n",
    ">Необходимо понять, какова вероятность, что новое лекарство вызовет ухудшение состояния пациента, так как, если она велика, то лекарство требует доработки.\n",
    ">\n",
    "\n",
    "Итак, в данном случае $2800$ — это общее количество исходов события, а $7$ — количество благоприятных исходов. Согласно определению вероятности, вероятность серьёзных побочных эффектов вычисляется следующим образом:\n",
    "\n",
    "$\\frac{7}{2800}=0.0025$\n",
    "\n",
    "Можно также сказать, что вероятность — это число, которое оценивает степень возможности наступления того или иного случайного события. Вероятности всегда находятся в диапазоне **от 0 до 1 включительно**:\n",
    "\n",
    "$0 \\leq P(A) \\leq 1$\n",
    "\n",
    "Чем больше полученное значение, тем более вероятно, что событие произойдёт. Вероятность $0$ означает, что событие **никогда не случится**. Такое событие называют **невозможным**:\n",
    "\n",
    "$P(A)=P(\\oslash)=\\frac{n}{N}=\\frac{0}{N}=0$\n",
    "\n",
    "Вероятность 1 означает, что событие произойдёт **в любом случае** — такое событие называют **достоверным**:\n",
    "\n",
    "$P(A)=P(\\Omega)=\\frac{n}{N}=\\frac{N}{N}=1$\n",
    "\n",
    "Все остальные значения от 0 до 1 представляют различные уровни вероятности.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    ">**Дополнение события** $A$ — это подмножество таких исходов во всём пространстве исходов, что они не благоприятствуют событию $A$. Дополнение события $A$ само по себе тоже является событием и обозначается как $\\overline{A}$.\n",
    "\n",
    "Важно понимать, что у события и дополнения к нему нет общих исходов, то есть они взаимоисключающие или, как это обычно называют в теории вероятностей, несовместные. Также событие и дополнение к нему содержат в сумме абсолютно все исходы из пространства исходов. Из этого следует, что сумма их вероятностей равняется одному:\n",
    "\n",
    "$P(A)+P\\left(\\overline{A}\\right)=1$\n",
    "\n",
    "Например, если мы знаем, что вероятность того, что пойдёт дождь, равна $0.7$, то вероятность того, что дождя не будет, равна $1-0.7=0.3$. События «пойдёт дождь» и «дождя не будет» являются **несовместными**, так как не может быть, чтобы одновременно шёл дождь и его не было. Также они покрывают всё пространство исходов, так как никаких других вариантов быть не может.\n",
    "\n",
    "Если у нас есть любое количество взаимоисключающих событий, которые описывают абсолютно все возможные элементарные исходы, то сумма их вероятностей равна 1:\n",
    "\n",
    "$P\\left(A_{1}\\right)+P\\left(A_{2}\\right)+P\\left(A_{3}\\right)+\\ldots+P\\left(A_{n}\\right)=1$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ПРАВИЛО СУММЫ\n",
    "\n",
    ">Вероятностное **правило суммы** используется в ситуациях, когда необходимо найти вероятность наступления **объединения событий**.\n",
    "\n",
    "К примеру, если есть события «Маша получила за тест 4» и «Маша получила за тест 5», их объединением будет событие «Маша получила за тест 4 или 5», и для вычисления его вероятности нам как раз понадобится правило суммы.\n",
    "\n",
    "Это правило используется для **несовместных событий**, то есть событий, которые не могут произойти одновременно.\n",
    "\n",
    "Если события $A$ и $B$ являются несовместными, то вероятность для объединения этих событий вычисляется по следующей формуле:\n",
    "\n",
    "$P(A \\cup B)=P(A)+P(B)$\n",
    "\n",
    "Разумеется, формулу для вероятности объединения событий можно легко вывести математически. За $S$ обозначим всё пространство исходов:\n",
    "\n",
    "$P(A \\cup B)=\\frac{\\left|A \\right|+\\left|B \\right|}{\\left|S \\right|}=\\frac{\\left|A \\right|}{\\left|S \\right|}+\\frac{\\left|B \\right|}{\\left|S \\right|}=P(A)+P(B)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В магазине одежды есть в наличии две зеленые юбки, три — красные и четыре — синие. Приходит покупательница и случайным образом выбирает юбку, причём каждая юбка может быть выбрана с одинаковой вероятностью. Точно известно, что она выберет только одну юбку.\n",
    ">\n",
    ">Какова вероятность того, что покупательница выберет зелёную или синюю юбку?\n",
    ">\n",
    ">Определим события $G$ и $B$ следующим образом:\n",
    ">\n",
    ">* $G$ = клиентка выбирает зелёную юбку;\n",
    ">* $B$ = клиентка выбирает синюю юбку.\n",
    ">Нельзя купить одновременно зелёную и синюю юбку, так что можно без проблем применить правило для вероятности суммы:\n",
    ">\n",
    ">$P(G \\cup B)=P(G)+P(B)=\\frac{2}{9}+\\frac{4}{9}=\\frac{2}{3}$\n",
    ">\n",
    ">Получаем, что с вероятностью $\\frac{2}{3}$ будет выбрана зелёная или синяя юбка."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ПРАВИЛО УМНОЖЕНИЯ\n",
    "\n",
    "Перейдём к правилу умножения или, его ещё называют, **правилу произведения**.\n",
    "\n",
    ">Правило произведения используется для нахождения вероятности пересечения событий:\n",
    ">\n",
    ">$P (A \\cap B) = P(A) \\times P(B)$\n",
    "\n",
    "Пусть нам известно, что среди людей, заходящих в магазин, `70 %` ничего не покупают. Остальные с равной вероятностью покупают `1`, `2` или `3` бутылки воды.\n",
    "\n",
    "Допустим, что в магазин заходят два человека. Если событие $A$ — это «покупка чётного числа бутылок первым человеком», а событие $B$ — «покупка вторым человеком более чем одной бутылки», давайте найдём вероятность события $A \\cap B$, то есть вероятность того, что один человек купил чётное количество бутылок, а второй купил более одной бутылочки.\n",
    "\n",
    "Рассмотрим элементарные исходы, благоприятные событию $A$, и его вероятность:\n",
    "\n",
    "$A = \\{0,2 \\}, \\ P(A) = 0.8$\n",
    "\n",
    "Сделаем то же самое для события $B$:\n",
    "\n",
    "$B = \\{2,3 \\}, \\ P(B) = 0.2$\n",
    "\n",
    "Тогда вероятность их пересечения ищем следующим образом:\n",
    "\n",
    "$P (A \\cap B) = 0.8 \\cdot 0.2 = 0.16$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ОБОБЩЁННОЕ ПРАВИЛО СУММЫ\n",
    "\n",
    "Применение рассмотренного нами правила суммы несколько ограничено, поскольку требует несовместных событий.\n",
    "\n",
    "?Что, если события всё же могут быть совместными, то есть происходить одновременно?\n",
    "\n",
    "Приведём обобщенное правило суммы, которое можно применять и в таких ситуациях:\n",
    "\n",
    "$P(A \\cup B)=P(A)+P(B)-P(A \\cap B)$\n",
    "\n",
    "Давайте рассмотрим, как выводится это правило.\n",
    "\n",
    "Дело в том, что при сложении вероятностей наступления событий $A$ и $B$ мы считаем центральную часть (пересечение) дважды. Поэтому нам необходимо вычесть вероятность пересечения данных событий, чтобы она была вычислена только один раз.\n",
    "\n",
    "$P(A \\cup B)=\\frac{\\left|A \\right|}{\\left|S \\right|}+\\frac{\\left|B \\right|}{\\left|S \\right|}-\\frac{\\left|A \\cap B \\right|}{\\left|S \\right|}=P(A)+P(B)-P(A \\cap B)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть 30 % клиентов нашей клининговой компании — женщины. Также мы знаем, что $\\frac{2}{3}$ женщин пользуются нашими услугами еженедельной уборки, а $\\frac{1}{3}$ — нет. Среди мужчин $\\frac{3}{7}$ пользуются услугами еженедельной уборки, а $\\frac{4}{7}$ ими не пользуются.\n",
    "\n",
    "Необходимо найти вероятность, что случайно выбранный клиент либо женского пола, либо пользуется нашими услугами еженедельной уборки, либо и то, и другое.\n",
    "\n",
    "Просто сложить вероятность, что клиент женского пола, и вероятность, что клиент пользуется рассматриваемыми услугами, нельзя, так как в таком случае мы дважды посчитаем женщин, которые используют еженедельную уборку.\n",
    "\n",
    "Можно представить наши данные в виде следующей таблицы:\n",
    "\n",
    "| |Пользуются услугами|Не пользуются услугами|\n",
    "|-|-|-|\n",
    "|Женщины|\t20 %|\t10 %|\n",
    "|Мужчины|\t30 %|\t40 %|\n",
    "\n",
    "Чтобы рассчитать все значения, мы воспользовались информацией из условия задачи.\n",
    "\n",
    "Если мы знаем, что всего женщин 30 %, и $\\frac{2}{3}$ из них пользуются нашими услугами еженедельной уборки, а $\\frac{1}{3}$ — нет, то легко рассчитать:\n",
    "\n",
    "* процент женщин, которые используют услугу: $30 \\%* \\frac{2}{3} = 20 \\%$;\n",
    "* процент женщин, которые не используют услугу: $30 \\%* \\frac{1}{3} = 10 \\%$.\n",
    "\n",
    "Аналогичные расчёты можно провести и для мужчин.\n",
    "\n",
    "Если пользоваться формулой, то для начала необходимо сложить вероятности того, что клиент женского пола:\n",
    "\n",
    "| |Пользуются услугами|Не пользуются услугами|\n",
    "|-|-|-|\n",
    "|Женщины|\t`20 %`|\t`10 %`|\n",
    "|Мужчины|\t30 %|\t40 %|\n",
    "\n",
    "Затем надо прибавить вероятность того, что клиент пользуется нашими услугами:\n",
    "\n",
    "| |Пользуются услугами|Не пользуются услугами|\n",
    "|-|-|-|\n",
    "|Женщины|\t`20 %`|\t10 %|\n",
    "|Мужчины|\t`30 %`|\t40 %|\n",
    "\n",
    "Тогда мы получим, что мы посчитали 30 % и 10 % по одному разу, а 20 % — два раза:\n",
    "\n",
    "| |Пользуются услугами|Не пользуются услугами|\n",
    "|-|-|-|\n",
    "|Женщины|\t**20 %**|\t`10 %`|\n",
    "|Мужчины|\t`30 %`|\t40 %|\n",
    "\n",
    "Поэтому вычитаем 20 % и получаем необходимый нам результат:\n",
    "\n",
    "$50 \\% + 30 \\% - 20 \\% = 60 \\%$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Условная вероятность <a class=\"anchor\" id=3></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    ">**Условная вероятность** — это вероятность события при некоторых уже известных условиях.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, нам может быть необходимо найти вероятность, что человек вернёт ипотеку, если у него уже есть кредит на автомобиль, или вероятность того, что клиент компании уйдёт к конкурентам, если нам известно, что он отклонял все рекламные предложения в течение предыдущего года.\n",
    "\n",
    ">Условная вероятность события $B$ при условии $A$ определяется как вероятность того, что событие $B$ произойдёт после того, как событие $A$ уже произошло, и обозначается следующим образом:\n",
    ">\n",
    ">$P(B|A)$\n",
    ">\n",
    "Чтобы найти формулу для поиска условной вероятности, запишем, что вероятность того, что произойдёт и событие $A$ и событие $B$ сразу (по сути, это пересечение событий $A$ и $B$) — это вероятность того, что произойдёт событие $A$, умноженная на вероятность того, что произойдёт событие $B$ (при условии, что $A$ уже произошло). Это соотношение получается напрямую из правила произведения, которое вы изучили в предыдущем юните:\n",
    "\n",
    "$P(A \\ и \\ B)=P(A) \\cdot P(B \\mid A)$\n",
    "\n",
    "Поделим обе части на $P(A)$\n",
    "\n",
    "$\\frac{P(A \\text { и } B)}{P(A)}=\\frac{P(A) \\cdot P(B \\mid A)}{P(A)}$\n",
    "\n",
    "В правой части сократим $P(A)$ в числителе и знаменателе и получим формулу для поиска условной вероятности:\n",
    "\n",
    "$\\frac{P(A \\text { and } B)}{P(A)}=P(B \\mid A)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Представим, что некий стажёр пытается устроиться на работу. С вероятностью $0.06$ он успеет вовремя прийти на собеседование и получит работу. С вероятностью $0.2$ он в принципе придёт на собеседование вовремя. Необходимо найти вероятность, что стажёр получит работу, если известно, что он уже пришёл на собеседование в нужное время.\n",
    "\n",
    "Обозначим за $N$ событие, что стажёр пришёл вовремя, а за $T$ — событие, что его взяли на работу. Тогда получаем следующую формулу:\n",
    "\n",
    "$P(T \\mid N)=\\frac{P(N \\text { и } T)}{P(N)}=\\frac{0.06}{0.20}=0.30$\n",
    "\n",
    "Получаем, что стажёр получит работу при условии, что он вовремя пришел на встречу, **с вероятностью $0.3$**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Среди людей, заходящих в магазин, `70 %` ничего не покупают. Остальные с равной вероятностью покупают `1`, `2` или `3` бутылки воды. Найдите вероятность купить 2 бутылки, если точно известно, что количество купленных бутылок меньше трёх.\n",
    "\n",
    "Запишем выражение для поиска условной вероятности, согласно рассмотренной ранее формуле:\n",
    "\n",
    "$P(\\{2\\} \\mid\\{0,1,2\\})=\\frac{P(\\{2\\} \\cap\\{0,1,2\\})}{P(\\{0,1,2\\})}$\n",
    "\n",
    "В числителе нам нужна вероятность того, что одновременно было куплено две бутылки и какое-то количество из множества $\\{0,1,2\\}$. Разумеется, это то же самое, что вероятность покупки просто двух бутылок:\n",
    "\n",
    "$\\frac{P(\\{2\\} \\cap\\{0,1,2\\})}{P(\\{0,1,2\\})}=\\frac{P(\\{2\\})}{P(\\{0,1,2\\})}=\\frac{0.1}{0.9}=1 / 9$\n",
    "\n",
    "Получаем, что из тех, кто покупает меньше трёх бутылок воды, ровно две бутылки берёт один человек из девяти покупателей.\n",
    "\n",
    ">Обратите внимание, что, хотя в пересечении один исход, а в условии — три, вероятность не равна $\\frac{1}{3}$. Так получилось потому, что модель неравновероятна и ноль (то есть исход, когда человек ничего не купил) имеет существенно больший вес, чем остальные исходы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "В конференции участвуют 1000 человек: 300 мужчин и 700 женщин. Известно, что 240 мужчин и 280 женщин пьют кофе. Необходимо найти, с какой вероятностью случайно взятый человек с конференции:\n",
    "\n",
    "* пьёт кофе, если пол неизвестен;\n",
    "* пьёт кофе, если это мужчина;\n",
    "* пьёт кофе, если это женщина.\n",
    "\n",
    "Для начала опишем всё пространство элементарных исходов. Для простоты введём следующие обозначения:\n",
    "\n",
    "$\\Omega=\\{M D, M N, F D, F N\\}$\n",
    "\n",
    "$\\mathrm{M} - male \\ (мужчина)$\n",
    "\n",
    "$\\mathrm{F} - female \\ (женщина)$\n",
    "\n",
    "$\\mathrm{D} - drinks \\ (пьёт)$\n",
    "\n",
    "$\\mathrm{N} - does \\ not \\ drink \\ (не \\ пьёт)$\n",
    "\n",
    "Рассчитаем вероятности для каждого исхода:\n",
    "\n",
    "* вероятность, что это мужчина, пьющий кофе: $P(M D)=\\frac{240}{1000}=0.24$;\n",
    "* вероятность, что это мужчина, не пьющий кофе: $P(M N)=\\frac{300-240}{1000}=0.06$;\n",
    "* вероятность, что это женщина, пьющая кофе: $P(F D)=\\frac{280}{1000}=0.28$;\n",
    "* вероятность, что это женщина, не пьющая кофе: $P(F N)=\\frac{700-280}{1000}=0.42$.\n",
    "\n",
    "Тогда вероятность того, что человек (мужчина или женщина) пьёт кофе, мы можем вычислить, вспомнив правило сложения вероятностей, изученное в прошлом юните:\n",
    "\n",
    "$P(D)=P(\\{M D, F D\\})=0.24+0.28=0.52$\n",
    "\n",
    "Теперь рассчитаем условную вероятность того, что человек пьёт кофе, если мы знаем, что это мужчина:\n",
    "\n",
    "$P(D \\mid M)=P(\\{M D, F D\\} \\mid\\{M D, M N\\})= \\frac{P(\\{M D\\})}{P(\\{M D, M N\\})}=\\frac{0.24}{0.3}=0.8$\n",
    "\n",
    "То же самое делаем для женщин:\n",
    "\n",
    "$P(D \\mid F)=P(\\{M D, F D\\} \\mid\\{F D, F N\\})=\\frac{P(\\{F D\\})}{P(\\{F D, F N\\})}=\\frac{0.28}{0.7}=0.4$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Итак, мы рассчитали условные вероятности для этого примера. Теперь давайте в рамках этой же ситуации рассмотрим разницу между вероятностью пересечения событий и условной вероятностью. Для этого попробуем найти вероятности двух похожих, но всё же принципиально разных событий:\n",
    "\n",
    "* случайно взятый человек с конференции пьёт кофе и является женщиной;\n",
    "* случайно взятый человек с конференции пьёт кофе, если уже известно, что это женщина.\n",
    "\n",
    "Может показаться, что эти события похожи, однако это не так. Давайте рассчитаем вероятность сначала первого, а затем второго события.\n",
    "\n",
    "Для нахождения вероятности первого события используем правило произведения:\n",
    "\n",
    "$P(F \\cap D)=P(F D)=0.28$\n",
    "\n",
    "Для вычисления вероятности второго события используем формулу условной вероятности:\n",
    "\n",
    "$P(D \\mid F)=P(\\{M D, F D\\} \\mid\\{F D, F N\\})=\\frac{P(\\{F D\\})}{P(\\{F D, F N\\})}=\\frac{0.28}{0.7}=0.4$\n",
    "\n",
    "Можно увидеть, что результаты получились разные, так как это две принципиально разные ситуации — пожалуйста, будьте внимательны и не путайте эти случаи при решении задач."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## УСЛОВНАЯ ВЕРОЯТНОСТЬ И МАТРИЦА ОШИБОК\n",
    "\n",
    "Рассмотрим, как условная вероятность используется в машинном обучении для оценки качества классификации.\n",
    "\n",
    "Допустим, у нас есть выборка из изображений, которые мы хотим классифицировать на две группы — фотографии чихуахуа и фотографии кексов с ягодами:\n",
    "\n",
    "<img src=m7_img3.png>\n",
    "\n",
    "Мы реализовали один из алгоритмов машинного обучения (например, логистическую регрессию или KNN) и получили следующие результаты:\n",
    "\n",
    "|  | Чихуахуа (предсказание) | \tКекс (предсказание) |\n",
    "| - | - | - |\n",
    "| Чихуахуа (реальное изображение) | 450 | 100 |\n",
    "| Кекс (реальное изображение) | 150 | 550 |\n",
    "\n",
    "По столбцам мы видим предсказания алгоритма, а по строкам — реальные изображения. То есть, например, на 450 фотографиях действительно чихуахуа, и модель корректно это отразила, а вот на 100 фотографиях в реальности чихуахуа, но модель приняла собаку за кекс.\n",
    "\n",
    "?Теперь представим, что мы загружаем в алгоритм новую картинку и нам необходимо понять: если модель выдаёт, что на картинке — чихуахуа, то с какой вероятностью это действительно так?\n",
    "\n",
    "Таким образом, мы хотим найти следующую вероятность:\n",
    "\n",
    "$P(на \\ фото \\ действительно \\ чихуахуа|алгоритм \\ предсказал \\ чихуахуа \\ на \\ фото)$\n",
    "\n",
    "Ещё раз взглянем на результаты и будем рассматривать только на первый столбец, поскольку нам уже известно, что алгоритм предсказал, что на фото чихуахуа:\n",
    "\n",
    "Всего в рассматриваемом пространстве ответов 600 предсказаний.\n",
    "\n",
    "Из 600 сделанных прогнозов 450 верны, а 150 — неверны.\n",
    "\n",
    "Таким образом, условная вероятность составляет $450/600 = 3/4$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "Вероятно, вы уже отметили, что, по сути, перед вами уже знакомая вам матрица ошибок, часто используемая в машинном обучении для оценки качества классификации. Вы наверняка умеете вычислять различные метрики, и теперь пришло время осознать, что на самом деле ранее вы постоянно вычисляли условные вероятности, когда рассчитывали качество модели:\n",
    "\n",
    "$Precision = P(X предсказан как класс \\ 1 \\ и \\ действительно им является \\ | X \\ предсказан \\ как \\ класс \\ 1) = P(TP / (TP + TN))$\n",
    "\n",
    "$Recall = P(X предсказан как класс \\ 1 \\ и \\ действительно им является \\ | X \\ действительно \\ принадлежит \\ классу \\ 1) = P(TP / (TP + FP))$\n",
    "\n",
    "$Specuficity = P(X предсказан как класс \\ 0 \\ и \\ действительно им является \\ | X \\ действительно \\ принадлежит \\ классу \\ 0) = P(TN / (TN + FN))$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## НЕЗАВИСИМОСТЬ СОБЫТИЙ\n",
    "\n",
    "В применении теории вероятностей к анализу данных очень важно понятие независимости. Нам важно знать, влияет ли одно явление на другое или они не зависят друг от друга. Сейчас мы говорим о вероятности событий, поэтому и независимость рассмотрим тоже для событий.\n",
    "\n",
    ">События $A$ и $B$ называются **независимыми**, если вероятность их пересечения равна произведению вероятностей\n",
    ">\n",
    ">$P(A \\cap B)=P(A) \\cdot P(B)$\n",
    "\n",
    "Основная суть независимых событий заключается в том, что вероятность $A$ не зависит от наличия условия, связанного с $B$, то есть при наступлении события $A$ событие $B$ происходит так же часто, как и без него.\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано вероятностное пространство, которое определено следующим образом:\n",
    "\n",
    "$\\Omega=\\{1,2,3,4,5,6\\}$\n",
    "\n",
    "Причём появления разных чисел не равновероятны, а соответствуют следующим вероятностям:\n",
    "\n",
    "$\\begin{array}{lll}P(1)=0.3 & P(3)=0.1 & P(5)=0.1 \\\\ P(2)=0.3 & P(4)=0.05 & P(6)=0.15\\end{array}$\n",
    "\n",
    "Необходимо проверить на независимость две пары событий:\n",
    "\n",
    "$A = \\ \"нечётное\" \\ число$ ; $B = \\ \"число \\ меньше \\ 3\"$\n",
    "\n",
    "$A = \\ \"нечётное\" \\ число$ ; $C = \\ \"число \\ равное \\ 3 или 4\"$\n",
    "\n",
    "Сначала разберёмся с первой парой — найдём благоприятные исходы для каждого события и для их пересечения:\n",
    "\n",
    "$A=\\{1,3,5\\}, B=\\{1,2\\}$\n",
    "\n",
    "$A \\cap B=\\{1,3,5\\} \\cap\\{1,2\\}=\\{1\\}$\n",
    "\n",
    "Далее рассчитаем необходимые вероятности:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(A \\cap B)=P(\\{1\\})=0.3$\n",
    "\n",
    "$P(A) \\cdot P(B)=P(\\{1,3,5\\}) \\cdot P(\\{1,2\\})=0.5 \\cdot 0.6=0.3$\n",
    "\n",
    "Получаем равенство:\n",
    "\n",
    "$P(A \\cap B)=P(A) \\cdot P(B)$\n",
    "\n",
    "Так как выполняется условие о том, что вероятность пересечения событий $A$ и $B$ совпадает с произведением вероятностей событий $A$ и $B$, то можно сделать вывод, что события $A$ и $B$ независимы.\n",
    "\n",
    "Теперь рассмотрим вторую пару событий.\n",
    "\n",
    "$P(A \\cap C)=P(\\{3\\})=0.1$\n",
    "\n",
    "$P(A) \\cdot P(C)=P(\\{1,3,5\\}) \\cdot P(\\{3,4\\})=0.5 \\cdot 0.15=0.075$\n",
    "\n",
    "Получаем, что равенство не выполнено:\n",
    "\n",
    "$P(A \\cap C) \\neq P(A) \\cdot P(C)$\n",
    "\n",
    "Это значит, что события $A$ и $C$ являются зависимыми."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Полная вероятность <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Прежде чем разобраться с тем, что это такое, необходимо вспомнить понятие **несовместных**, или взаимоисключающих событий, то есть таких, которые не могут произойти в одно и то же время. Если случится одно, **другое не произойдёт**.\n",
    "\n",
    "К примеру, если событие $A$ заключается в том, что сегодня выходной день, а событие $B$ — что будний, то данные события являются взаимоисключающими, так как не может быть, чтобы у человека был одновременно и рабочий день, и выходной. Также, например, не может одновременно выпасть нечётное и чётное число очков на кубике, покупатель не может одновременно купить товар и не купить его и т.д.\n",
    "\n",
    "Отсюда вытекает понятие **разбиения**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Разбиение вероятностного пространства** — это взаимоисключающие и совместно исчерпывающие события. Проще говоря, это события, которые не пересекаются (т. е. не имеют общих исходов), но в объединении дают все возможные исходы.\n",
    "\n",
    "Давайте рассмотрим пример разбиения вероятностного пространства ↓\n",
    "\n",
    "Пусть у нас есть собственная кондитерская, в которой мы продаём пирожные. Каждый клиент обычно покупает равновероятно от 1 до 6 пирожных (получается, что для каждого количества вероятность равна $\\frac{1}{6}$), то есть пространство всех элементарных исходов задаётся следующим образом:\n",
    "\n",
    "$\\Omega=\\{1,2,3,4,5,6\\}$\n",
    "\n",
    "Рассмотрим следующие события:\n",
    "\n",
    "$A=\\{1,2\\}, \\ B=\\{3\\}, \\ C=\\{4,5,6\\}$\n",
    "\n",
    "* $A$ — клиент купил одно или два пирожных;\n",
    "* $B$ — клиент купил три пирожных;\n",
    "* $C$ — клиент купил от четырёх до шести пирожных.\n",
    "\n",
    "Эти события являются взаимоисключающими, так как у них нет общих исходов:\n",
    "\n",
    "$A \\cap B=\\varnothing, B \\cap C=\\varnothing, A \\cap C=\\varnothing$\n",
    "\n",
    "При этом их объединение даёт все возможные элементарные исходы:\n",
    "\n",
    "$A \\cup B \\cup C=\\{1,2,3,4,5,6\\}=\\Omega$\n",
    "\n",
    "Получается, что эти события образуют разбиение вероятностного пространства.\n",
    "\n",
    "Рассмотрим ещё один пример в контексте истории с пирожными. Теперь события будут следующими:\n",
    "\n",
    "$A=\\{1,2\\}, \\ B=\\{3,4\\}, \\ C=\\{4,5,6\\}$\n",
    "\n",
    "Такой набор событий не будет образовывать разбиение, так как у событий есть общие исходы, а значит, они не являются взаимоисключающими:\n",
    "\n",
    "$B \\cap C=\\{4\\} \\neq \\varnothing$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Задание 4.2**\n",
    "\n",
    "Среди студентов-первокурсников онлайн-магистратуры SkillFactory 30 % устроились на работу в первый месяц обучения, а остальные — позже. Среди тех, кто устроился на работу в первый месяц, 70 % получили повышение в течение года, а среди тех, кто устроился позже, — 50 %.\n",
    "\n",
    "1. Какие значения удобнее использовать в качестве разбиения в этой задаче?\n",
    "\n",
    ">Студенты, которые устроились на работу в первый месяц, и студенты, которые устроились позже.\n",
    "\n",
    "2. Какая доля первокурсников SkillFactory устроилась на работу в первый месяц обучения и получила повышение в течение первого года работы?\n",
    "\n",
    ">0.21\n",
    "\n",
    "3. Найдите вероятность того, что случайный первокурсник SkillFactory получил повышение на работе в течение года.\n",
    "\n",
    "> 0.56"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Теперь мы можем перейти к **формуле полной вероятности**, которая как раз основана на идее разбиения вероятностного пространства.\n",
    "\n",
    "Теорема полной вероятности очень полезна в случаях, когда мы ищем вероятность возникновения события, которое является суммой двух (или более) событий из разных частей разбиения.\n",
    "\n",
    ">Чтобы идея была более понятной, рассмотрим её на примере: если мы хотим найти число пьющих кофе людей, то мы можем сделать это, сложив количество пьющих кофе мужчин и пьющих кофе женщин, если нам известны эти значения.\n",
    ">\n",
    ">Та же самая идея на языке вероятностей звучит следующим образом: вероятность, что случайно выбранный человек пьёт кофе, равна сумме вероятности, что человек пьёт кофе и является мужчиной, и вероятности, что человек пьет кофе и является женщиной.\n",
    "\n",
    "Искать вероятности отдельно для мужчин и женщин — часто более выгодная стратегия, так как обычно поиск более простых вероятностей (для отдельных элементарных исходов, а не для всего события сразу) намного проще.\n",
    "\n",
    "Давайте рассмотрим применение этой теоремы на примере, а уже после изучим её математическую формулировку ↓\n",
    "\n",
    "Вы являетесь владельцем кафе и знаете, что в дни, когда нет дождя, вы получаете необходимую выручку с вероятностью $0.5$. Если в городе дождь, то люди скорее заказывают еду с доставкой и не приходят к вам в кафе — в такие дни вы получаете нужный доход с вероятностью $0.3$.\n",
    "\n",
    "На основе исторических данных известно, что в случайный день с вероятностью $0.6$ в городе нет дождя.\n",
    "\n",
    "Какова вероятность, что завтра вы получите необходимый доход?\n",
    "\n",
    "Давайте построим схему. У нас есть два варианта: нет дождя или есть дождь с вероятностями $0.6$ и $0.4$ $(1-0.6)$ соответственно:\n",
    "\n",
    "<img src=m7_img4.png width=300>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем, что если дождя нет, то хорошая выручка будет с вероятностью $0.5$. Значит, плохая выручка тоже будет с вероятностью $0.5$:\n",
    "\n",
    "<img src=m7_img5.png width=600>\n",
    "\n",
    "Также мы знаем, что если идёт дождь, мы получим хорошую выручку с вероятностью $0.3$. Соответственно, плохая выручка у нас получается с вероятностью $1-0.3 = 0.7$:\n",
    "\n",
    "<img src=m7_img6.png width=600>\n",
    "\n",
    "Нас интересуют те комбинации событий, которые приводят к хорошей выручке:\n",
    "\n",
    "<img src=m7_img7.png width=600>\n",
    "\n",
    "То есть нам необходимо рассчитать вероятности для двух событий:\n",
    "\n",
    "* когда нет дождя и получилась хорошая выручка;\n",
    "\n",
    "* когда есть дождь и получилась хорошая выручка."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из предыдущего юнита вы наверняка помните соотношение, которым мы сейчас и воспользуемся:\n",
    "\n",
    "$P(A \\ и \\ B)=P(A) \\times P(B \\mid A)$\n",
    "\n",
    "* Рассчитаем вероятность для «ветки» с отсутствием дождя: $0.6*0.5=0.3$.\n",
    "\n",
    "* Рассчитаем вероятность для «ветки» с дождём: $0.4*0.3=0.12$.\n",
    "\n",
    "Так как нам подойдёт либо первый вариант, либо второй, то по правилу сложения мы просто складываем эти вероятности:\n",
    "\n",
    "$0.3+0.12=0.42$\n",
    "\n",
    "Итак, мы вычислили вероятность получить хорошую выручку — она равна $0.42$ — и решили задачу с помощью теоремы полной вероятности.\n",
    "\n",
    "Наверняка алгоритм решения вам уже понятен, но всё же приведём математическую формулировку теоремы:\n",
    "\n",
    "$P(B)=\\sum_{i=1}^{n} P\\left(B \\mid A_{i}\\right) P\\left(A_{i}\\right)$\n",
    "\n",
    "В данной формуле:\n",
    "\n",
    "* $P(B)$ — вероятность наступления события $B$;\n",
    "\n",
    "* $P(A_i)$ — вероятность наступления события $A_i$, которое является условием для события $B$;\n",
    "\n",
    "* $P(B|A_i)$— условная вероятность наступления события $B$, если известно, что произошло событие $A_i$.\n",
    "\n",
    "Давайте разберём ещё несколько примеров решения задач на использование данной формулы ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Предположим, что два производителя, $A$ и $Б$, поставляют двигатели для гоночных автомобилей `Formula 1` со следующими характеристиками:\n",
    "\n",
    "* 99 % двигателей завода $А$ служат более 5 000 км;\n",
    "\n",
    "* завод $B$ производит двигатели, которые прослужат более 5 000 км с вероятностью 95 %;\n",
    "\n",
    "* 70 % двигателей произведены заводом $А$, а остальные — заводом $Б$.\n",
    "\n",
    "Найдите вероятность того, что двигатель прослужит более 5 000 км.\n",
    "\n",
    "Попробуем снова нарисовать дерево вероятностей, которым мы пользовались в предыдущем примере:\n",
    "\n",
    "<img src=m7_img8.png width=600>\n",
    "\n",
    "Так как нас интересуют те события, где двигатель прослужит более 5 000 км, то нужные нам ветви будут следующими:\n",
    "\n",
    "<img src=m7_img9.png width=600>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось только выполнить необходимые расчёты:\n",
    "\n",
    "* Вероятность, что двигатель с завода $А$ и прослужит более 5 000 км, равна $0.7*0.99=0.693$.\n",
    "\n",
    "* Вероятность, что двигатель с завода $Б$ и прослужит более 5 000 км, равна $0.3*0.95=0.285$.\n",
    "\n",
    "Осталось вычислить итоговую вероятность:\n",
    "\n",
    "$0.693+0.285=0.978$\n",
    "\n",
    "Получается, что случайно выбранный двигатель прослужит более 5 000 км с вероятностью $0.978$.\n",
    "\n",
    "Разумеется, мы могли бы найти ответ не с помощью дерева вероятностей, а уже с использованием  формулы полной вероятности. Тогда решение выглядело бы следующим образом:\n",
    "\n",
    "$P(двигатель \\ прослужит \\ более \\ 5000 \\ км) =$\n",
    "\n",
    "$P(двигатель \\ прослужит \\ более \\ 5000 \\ км \\ \\mid \\ двигатель \\ с \\ завода \\ А) * P(двигатель \\ с \\ завода \\ А) +$\n",
    "\n",
    "$+  P(двигатель \\ прослужит \\ более \\ 5000 \\ км \\ \\mid \\ двигатель \\ с \\ завода \\ Б) * P(двигатель \\ с \\ завода \\ Б) =$\n",
    "\n",
    "$= 0.7*0.99 + 0.3*0.95 = 0.693 +   0.285 = 0.978$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "`1 %` клиентов постоянно жалуются на сервис — из них `60 %` уйдут. Ещё `10 %` клиентов периодически жалуются на сервис — из них `10 %` уйдут. Оставшиеся `89 %` клиентов никогда не жалуются на сервис — из них `3 %` уйдут.\n",
    "\n",
    "Найдите:\n",
    "\n",
    "* долю уходящих клиентов каждого типа от всех клиентов;\n",
    "* долю уходящих клиентов от всех клиентов;\n",
    "* долю каждого типа клиентов среди уходящих клиентов.\n",
    "\n",
    "Для удобства введём обозначения событий:\n",
    "\n",
    "* `CUC` — Constantly Unhappy Customer (постоянно недовольный);\n",
    "* `DC` — Dissatisfied Customer (недовольный);\n",
    "* `CSC` — Completely Satisfied Customer (довольный);\n",
    "* `C` — Churn (ушедший).\n",
    "\n",
    "Рассчитаем вероятности для событий, которые касаются характеристик клиентов:\n",
    "\n",
    "* вероятность того, что клиент постоянно недоволен: $P(C U C)=0.01$;\n",
    "* вероятность того, что клиент периодически недоволен: $P(D C)=0.1$;\n",
    "* вероятность того, что клиент доволен: $P(C S C)=0.89$.\n",
    "\n",
    "Теперь рассчитаем условные вероятности, которые характеризуют то, с какой вероятностью уйдёт клиент в зависимости от его типа:\n",
    "\n",
    "* вероятность того, что клиент уйдёт, если он постоянно недоволен: $P(C|C U C)=0.6$;\n",
    "* вероятность того, что клиент уйдёт, если он периодически недоволен: $P(C|D C)=0.1$;\n",
    "* вероятность того, что клиент уйдёт, если он доволен: $P(C|C S C)=0.03$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем доли (вероятности)  уходящих клиентов для каждого типа клиентов:\n",
    "\n",
    "* вероятность того, что клиент постоянно недоволен и уйдёт: $P(C \\cap C U C) = P(C \\mid CUC) \\cdot P(CUC) = 0.6 \\cdot 0.01 = 0.006$;\n",
    "* вероятность того, что клиент периодически недоволен и уйдёт: $P(C \\cap D C)=0.1 \\cdot 0.1 = 0.01$;\n",
    "* вероятность того, что доволен и уйдёт: $P(C \\cap C S C)=0.03 \\cdot 0.89 = 0.0267$.\n",
    "\n",
    "Теперь мы можем найти долю уходящих клиентов для всех их клиентов. По сути, доля — это и есть вероятность, так что просто применяем формулу полной вероятности:\n",
    "\n",
    "$P(C) = P(C \\mid CUC) \\cdot P(CUC) + P(C \\mid DC) \\cdot P(DC) + P(C \\mid CSC) \\cdot P(CSC) =$\n",
    "\n",
    "$= 0.01 \\cdot 0.6 + 0.1 \\cdot 0.1 + 0.89 \\cdot 0.03 = 0.0427$\n",
    "\n",
    "Также мы можем найти долю каждого типа клиентов среди уходящих клиентов:\n",
    "\n",
    "* доля постоянно недовольных клиентов среди ушедших: $P(CUC \\mid C) = \\frac{P(C \\cap CUC)}{P(C)} = \\frac{0.006}{0.0427} \\approx 0.14$;\n",
    "* доля периодически недовольных клиентов среди ушедших: $P(DC \\mid C) = \\frac{P(C \\cap DC)}{P(C)} = \\frac{0.01}{0.0427} \\approx 0.23$;\n",
    "* доля довольных клиентов среди ушедших: $P(CSC \\mid C) = \\frac{P(C \\cap CSC)}{P(C)} = \\frac{0.0267}{0.0427} \\approx 0.63$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Теорема Байеса <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "Возможно, вы сталкивались с тем, что в ответ на какие-то ваши запросы в интернете выводится не ровно то, что вы ищете, а какие-то ассоциации с поисковым запросом. Например, если вы будете искать информацию про красную и синюю таблетку, то, скорее всего, в выдаче результатов у вас будет фильм «Матрица». Как поисковая система смогла «понять», что вам может быть нужен именно этот фильм? Разумеется, она его не смотрела и не умеет намеренно искать по кратким содержаниям. Однако, имея багаж знаний в виде множества других поисковых запросов, она знает, что вы вероятнее всего ищете. Эта вероятность вычисляется с помощью **теоремы (формулы) Байеса**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теорема Байеса используется во многих методах машинного обучения, например в спам-фильтрах, чтобы определять, является ли электронное письмо спамом, учитывая слова в этом письме. Кроме того, многие задачи в статистике, например, связанные с интерпретацией медицинских результатов, лучше всего описываются с использованием теоремы Байеса.\n",
    "\n",
    ">**Идея теоремы Байеса** заключается в том, что если у нас есть одна условная вероятность (например, $B$ при условии $A$), а мы хотим найти другую ($A$ при условии $B$), то мы можем получить из одной вероятности другую по определённому правилу. \n",
    "\n",
    "Если мы посмотрим на две условных вероятности, то увидим, что они связаны общим числителем:\n",
    "\n",
    "$P(B \\mid A) = \\frac{P(A \\cap B)}{P(A)}$ и $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "Это значит, что их можно без проблем выразить друг через друга.\n",
    "\n",
    "Давайте попробуем сделать это, то есть, по сути, **попробуем доказать теорему Байеса ↓**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Она записывается следующим образом:\n",
    ">\n",
    ">$P(A \\mid B)=\\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$\n",
    ">\n",
    ">Запомним это, а теперь запишем формулу для вероятности события $A$ при условии $B$:\n",
    ">\n",
    ">$P(B \\mid A)=\\frac{P(A \\cap B)}{P(A)}$\n",
    ">\n",
    ">Если мы домножим в этой формуле обе части на $P(A)$, то она примет следующий вид:\n",
    ">\n",
    ">$P(A \\cap B)=P(B \\mid A) \\cdot P(A)$\n",
    ">\n",
    ">Теперь возьмём формулу условной вероятности для вероятности события $A$ при условии $B$\n",
    ">\n",
    ">$P(A \\mid B)=\\frac{P(A \\cap B)}{P(B)}$\n",
    ">\n",
    ">и подставим в числитель правой части соотношение, выведенное ранее:\n",
    ">\n",
    ">$P(A \\cap B)=P(B \\mid A) \\cdot P(A)$\n",
    ">\n",
    ">Тогда получим:\n",
    ">\n",
    ">$P(A \\mid B)=\\frac{P(B \\mid A) \\cdot P(A)}{P(B)}$\n",
    ">\n",
    ">Это ровно то, что нам нужно. Таким образом, мы только что доказали теорему Байеса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте на конкретном **примере** рассмотрим, как теорема Байеса помогает в решении задач. Начнём с уже известного по предыдущему юниту кейса про отток клиентов ↓\n",
    "\n",
    "? 1 %  клиентов постоянно жалуется на сервис — из них 60 % уйдут. Ещё 10 % клиентов периодически жалуются на сервис — из них 10 % уйдут. Оставшиеся 89 % клиентов никогда не жалуются на сервис — из них 3 % уйдут.\n",
    "\n",
    "Найдите долю довольных клиентов среди ушедших.\n",
    "\n",
    "Мы, зная информацию об ушедших клиентах среди довольных, можем выразить долю довольных клиентов среди ушедших, то есть получить одну условную вероятность через другую.\n",
    "\n",
    "Для начала найдём общую долю оттока клиентов. В целом, мы уже делали это в предыдущем юните, так что просто повторим уже известные вам вычисления:\n",
    "\n",
    "$P(C) = P(C \\mid CUC) \\cdot P(CUC) + P(C \\mid DC) \\cdot P(DC) + P(C \\mid CSC) \\cdot P(CSC) =$\n",
    "\n",
    "$= 0.6 \\cdot 0.01 + 0.1 \\cdot 0.1 + 0.03 \\cdot 0.89 = 0.0427$\n",
    "\n",
    "Если мы говорим про отток довольных клиентов, то в общей формуле можно найти слагаемое, в котором вычисляется именно доля оттока довольных клиентов:\n",
    "\n",
    "$P(C) = P(C \\mid CUC) \\cdot P(CUC) + P(C \\mid DC) \\cdot P(DC)$ $\\overline{+ P(C \\mid CSC) \\cdot P(CSC)}$\n",
    "\n",
    "Тогда получаем, что доля довольных клиентов среди всех ушедших равна отношению доли ушедших и довольных клиентов к доле всех ушедших:\n",
    "\n",
    "$P(C S C \\mid C)=\\frac{P(C \\mid C S C) P(C S C)}{P(C)}=\\frac{0.03 \\cdot 0.89}{0.0427} \\approx 0.63$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Получается, что больше всего денег мы потеряем из-за тех клиентов, которые были довольны и не жаловались. Это является контринтуитивным предположением, но теория вероятности в том числе нужна для того, чтобы выстраивать стратегию принятия решений на основе чётких доказательств, ведь наше мышление и интуиция часто нас подводят.\n",
    "\n",
    "Теперь нам необходимо ввести два новых понятия: **априорные вероятности** и **апостериорные вероятности**.\n",
    "\n",
    ">Под **априорными вероятностями** понимаются безусловные вероятности, то есть они фиксированы и не зависят от вероятностей наступления других событий.\n",
    "\n",
    "В нашей задаче это следующие вероятности:\n",
    "\n",
    "* $P(CUC)= 0.01$\n",
    "\n",
    "* $P(DC) = 0.1$\n",
    "\n",
    "* $P(CSC) = 0.89$\n",
    "\n",
    ">Апостериорные вероятности, напротив, обусловлены вероятностями наступления каких-то ещё случайных событий.\n",
    "\n",
    "В рамках нашей задачи такой вероятностью является $P(CSC \\mid C)$.\n",
    "\n",
    "Очень часто формулу Байеса применяют для оценки результатов медицинских тестов, поэтому давайте рассмотрим ещё один пример в таком контексте ↓\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Редкое заболевание встречается у 1 % людей. Тест ошибочно показывает наличие болезни у здоровых людей с вероятностью 2 % и ошибочно показывает отсутствие болезни у больных с вероятностью 3 %.\n",
    "\n",
    "Найдите вероятность, что человек на самом деле болен, если тест на заболевание положителен.\n",
    "\n",
    "Введём обозначения, чтобы было проще записывать решение:\n",
    "\n",
    "* $S$ — sick (болен);\n",
    "* $H$ — healthy (здоров);\n",
    "* $P$ — positive (тест на заболевание положительный);\n",
    "* $N$ — negative (тест на заболевание отрицательный).\n",
    "\n",
    "Теперь найдём априорные вероятности для событий «человек болен» и «человек здоров»:\n",
    "\n",
    "$P(S)=0.01$\n",
    "\n",
    "$P(H)=0.99$\n",
    "\n",
    "Также найдём условные вероятности, которые понадобятся нам при решении задачи:\n",
    "\n",
    "* вероятность того, что тест показывает положительный результат, если человек здоров: $P(P \\mid H) = 0.02$;\n",
    "* вероятность того, что тест показывает отрицательный результат, если человек здоров: $P(N \\mid H) = 0.98$;\n",
    "* вероятность того, что тест показывает положительный результат, если человек болен: $P(P \\mid S) = 0.97$;\n",
    "* вероятность того, что тест показывает отрицательный результат, если человек болен: $P(N \\mid S) = 0.03$.\n",
    "\n",
    "Для удобства обобщим эти результаты в виде таблицы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Положительный тест\t| Отрицательный тест |\n",
    "| - | - | - |\n",
    "| Здоров | 0.02 | 0.98 |\n",
    "| Болен | 0.97 | 0.03 |\n",
    "\n",
    "Пока человек не прошёл медицинский тест, мы считаем его здоровым с вероятностью 99 % и больным — с вероятностью 1 %. Но когда он пройдет тест, у нас появится новая информация и вероятности изменятся.\n",
    "\n",
    "Давайте найдём полную вероятность, которая складывается из вероятности двух событий:\n",
    "\n",
    "* человек болен и получил положительный тест: $P(P \\mid S) P(S)$;\n",
    "* человек здоров и получил положительный тест: $P(P \\mid H) P(H)$.\n",
    "\n",
    "Вычисляем результат:\n",
    "\n",
    "$P(P)=P(P \\mid S) P(S)+P(P \\mid H) P(H)=0.97 \\cdot 0.01+0.02 \\cdot 0.99=0.0295$ \n",
    "\n",
    "Теперь вычислим условную вероятность, пользуясь формулой Байеса:\n",
    "\n",
    "$P(S \\mid P)=\\frac{P(P \\mid S) P(S)}{P(P)}=\\frac{0.97 \\cdot 0.01}{0.0295} \\approx 0.3288$\n",
    "\n",
    ">Итак, вероятность того, что человек болен, если получил положительный тест, — всего $0.33$. Задумайтесь об этом: этот результат, как и в прошлом примере, может показаться противоречащим интуиции. Это в очередной раз подчёркивает мощность теоремы Байеса: она помогает определять истинные значения вероятностей там, где невозможно оценить их просто по интуиции или из соображений здравого смысла. Теорема Байеса позволяет принимать безошибочные решения на основе вероятностных данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## БАЙЕСОВСКАЯ СТАТИСТИКА\n",
    "\n",
    "При разборе задач этого юнита вы могли заметить, что теорема Байеса помогает «пересчитывать» априорные вероятности с учётом каких-то дополнительных обстоятельств. Эта её особенность настолько полезна и часто применима, что дала начало новой ветви математической статистики — **байесовской статистике**.\n",
    "\n",
    ">**Байесовская статистика** предоставляет математические инструменты для обновления представлений о случайных событиях в свете появления новых данных или свидетельств об этих событиях.\n",
    "\n",
    "Это контрастирует с другой формой статистического вывода, известной как классическая, или частотная статистика, которая предполагает, что вероятности — это частота конкретных случайных событий, происходящих в длительном цикле повторяющихся испытаний.\n",
    "\n",
    "В частотной статистике мы считаем, что случайную величину можно оценить, только если будет проведено большое количество экспериментов. В байесовском подходе случайная величина — это детерминированный процесс, который можно просчитать даже без экспериментов, если знать значение всех влияющих на процесс факторов. Конечно же, узнать их невозможно, поэтому мы будем корректировать оценки после каждой новой порции информации.\n",
    "\n",
    "Например, если нас попросят найти вероятность того, что в день $X$ будет конец света, частотная статистика потребует много раз прожить день $X$, посчитать процент дней, когда конец света случился, и после этого даст оценку вероятности. Байесовский же подход сможет обойтись и без экспериментов, если удастся просчитать все факторы, влияющие на конец света."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Пусть у нас есть монетка, которая является «шулерской», то есть одна из её сторон выпадает чаще другой. Рассмотрим различия в оценке вероятностей выпадения решки и орла в классической парадигме и при байесовском подходе.\n",
    ">\n",
    ">В классическом подходе вероятность получить орёл при подбрасывании «нечестной» монеты — долгосрочная относительная частота появления орла при повторных подбрасываниях монеты. Таким образом, чем больше мы подбрасываем монету, тем больше число выпавших орлов в процентах от общего количества подбрасываний стремится к «истинной» вероятности того, что на монете выпадет орёл.\n",
    ">\n",
    ">>Философия байесовской статистики такова, что до первого подбрасывания мы считаем, что монета «честная», то есть по умолчанию используем априорную вероятность.\n",
    ">>\n",
    ">>Допустим, после нескольких бросков монета постоянно выпадает орлом. Тогда мы модифицируем исходную вероятность: добавляем информацию о том, что у нас выпало несколько орлов подряд, и постепенно наши оценки «честности» монеты меняются. Таким образом, предыдущее убеждение о «честности» монеты модифицируется. Апостериорное убеждение в итоге будет сильно изменено по сравнению с априорным убеждением о «честной» монете."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## ДОПОЛНИТЕЛЬНО\n",
    "\n",
    "Байесовская статистика, по сути, представляет собой отдельную философию внутри теории вероятностей и математической статистики. Это очень объёмная тема, чтобы говорить о ней сейчас даже с минимальными подробностями. Если она вас заинтересовала, рекомендуем прочитать следующие статьи:\n",
    "\n",
    "* [ \"Are you a Bayesian or a Frequentist? (Or Bayesian Statistics 101)\"](https://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html) (о различиях частотной и байесовской статистики)\n",
    "\n",
    "* [«Скажи Байесу \"да!\". Забудь про интуицию — просто думай, как Байес завещал»](https://nauka.tass.ru/sci/6815287)\n",
    "\n",
    "* [«Частотный и байесовский подходы к A/B тестированию: подробное сравнение | Урок 7»](https://vc.ru/u/1174886-koptelnya/411293-chastotnyy-i-bayesovskiy-podhody-k-a-b-testirovaniyu-podrobnoe-sravnenie-urok-7)\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Наивный бейсовский классификатор: практика <a class=\"anchor\" id=6></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Наивный байесовский классификатор** (**НБК**, англ. `Naive Bayes Classifier`, `NBC`) решает задачу классификации объектов по типам. Большим преимуществом этого алгоритма является его простота, как идейная, так и алгоритмическая.\n",
    "\n",
    "Наивная байесовская классификация — это достаточно простой вероятностный алгоритм, основанный на том, что все признаки модели независимы.\n",
    "\n",
    "Если, например, мы говорим про задачу классификации спам-писем и обычных писем, то в этом контексте мы считаем, что каждое слово в сообщении не зависит от всех других слов, то есть каждое слово мы учитываем, не обращая внимания на контекст.\n",
    "\n",
    "Алгоритм классификации выдаёт вероятность того, является письмо спамом или нет, основываясь на наборе слов в письме. Расчёт этой вероятности основан на формуле Байеса, а компоненты формулы рассчитываются на основе частот слов во всём наборе сообщений.\n",
    "\n",
    "Давайте разберёмся, как работает алгоритм ↓\n",
    "\n",
    "Прежде всего, возьмём формулу Байеса и применим её к нашей задаче:\n",
    "\n",
    "$P(Спам \\mid w_1, w_2, ..., w_n) \\propto P(Спам) \\cdot \\prod^n_{i = 1} P(w_i \\mid Спам)$\n",
    "\n",
    "Вероятность того, что письмо является спамом при условии, что в нём есть определённые слова (которые мы обозначили), пропорциональна произведению двух значений:\n",
    "\n",
    "* вероятности получения спама в целом (по сути, это доля спама в выборке);\n",
    "\n",
    "* произведения вероятностей, что в письме есть некоторое слово , если письмо является спамом, для всех слов выборки.\n",
    "\n",
    "Давайте разберёмся с этим подробнее. Для каждого слова в сообщении мы рассчитываем вероятность того, что это слово окажется в спаме. В рамках нашей задачи рассматриваем следующие значения:\n",
    "\n",
    "* $P(not \\ spam)$ — вероятность, что случайно взятое письмо будет спамом (также это доля спам-сообщений в нашем наборе данных);\n",
    "\n",
    "* $P(w_i \\mid spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо является спамом.\n",
    "\n",
    "По той же логике можем определить:\n",
    "\n",
    "* $P(not \\ spam)$ — доля сообщений, которые не являются спамом;\n",
    "\n",
    "* $P(w_i \\mid not \\ spam)$ — вероятность того, что в сообщении будет определённое слово, если это письмо не является спамом.\n",
    "\n",
    "Теперь необходимо понять, как рассчитать вероятности каждого слова. Для этого в алгоритме используется следующая формула:\n",
    "\n",
    "$P\\left(w_{i} \\mid S p a m\\right)=\\frac{N_{w_{i} \\mid S p a m}+\\alpha}{N_{S p a m}+\\alpha \\cdot N_{\\text {Vocabulary }}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой формуле:\n",
    "\n",
    "* $N_{Vocabulary}$ — количество уникальных слов во всём наборе данных;\n",
    "\n",
    "* $N_{Spam}$  — общее количество слов в спам-сообщениях;\n",
    "\n",
    "* $N_{w_i \\mid Spam}$  — количество повторов слова во всех спам-сообщениях;\n",
    "\n",
    "* $\\alpha$  — коэффициент для случаев, когда слово в сообщении отсутствует в нашем наборе данных.\n",
    "\n",
    "Кратко это можно объяснить так: вероятность того, что это слово встретится в спам сообщении, — это частота этого слова в «спамовой части» нашего набора данных (но с добавлением «сглаживания», чтобы учитывать ситуации, когда попадаются слова, которых не было в обучающей выборке).\n",
    "\n",
    "Также эта же формула (но с другими значениями) верна для вероятности того, что слово принадлежит не спам-сообщениям."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Файл \"НаивныйБайес.ipynb\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плюсы:\n",
    "\n",
    "* Алгоритм не только прост для понимания и реализации, но также даёт достаточно точные оценки и быстро работает.\n",
    "* Наивный Байес имеет низкую вычислительную сложность.\n",
    "* Он может эффективно работать с большим набором данных.\n",
    "* Его можно использовать с задачами прогнозирования нескольких классов, то есть в задачах мультиклассовой классификации.\n",
    "* Если выполнено предположение о независимости признаков, то НБК даёт более высокое качество, чем логистическая регрессия и многие другие модели.\n",
    "\n",
    "### Минусы\n",
    "\n",
    "* Предположение о независимых признаках не выполняется на практике практически никогда.\n",
    "* Если нет обучающего набора данных для какого-то из классов, это приводит к нулевой апостериорной вероятности и модель не может сделать прогноза."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разумеется, при решении реальных задач мы не будем каждый раз самостоятельно прописывать алгоритм  — можно использовать готовые методы. В библиотеке sklearn есть несколько байесовских классификаторов:\n",
    "\n",
    "* [GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) — самый простой вариант, работает с непрерывными признаками;\n",
    "* [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)  — работает с категориальными признаками, текстами и несбалансированными выборками;\n",
    "* [ComplementNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.ComplementNB.html) — улучшенная версия MultinomialNB, стабильно показывает более высокое качество в задачах классификации текстов;\n",
    "* [BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html) — версия для работы с бинарными признаками;\n",
    "* [CategoricalNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB) — работает с категориальными признаками, предполагает кодировку данных через OrdinalEncoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Случайная величина и её характеристики <a class=\"anchor\" id=7></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Дискретные распределения <a class=\"anchor\" id=8></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Неприрывные распределения <a class=\"anchor\" id=9></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Итоги <a class=\"anchor\" id=10></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
