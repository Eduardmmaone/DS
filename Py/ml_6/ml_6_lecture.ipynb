{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-6 Отбор и селекция признаков\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "- [1. Введение](#1)\n",
    "- [2. Способы представления данных](#2)\n",
    "- [3. Кодирование признаков](#3)\n",
    "- [4. Обработка пропусков и выбросов](#4)\n",
    "- [5. Масштабирование признаков](#5)\n",
    "- [6. Трансформации распределений признаков](#6)\n",
    "- [7. Даты и расстояния](#7)\n",
    "- [8. Отбор признаков: Мотивация](#8)\n",
    "- [9. Отбор признаков: Классификация методов](#9)\n",
    "- [10. Практика](#10)\n",
    "- [11. Итоги ](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Способы представления данных <a class=\"anchor\" id=2></a>\n",
    "\n",
    "1. Числа\n",
    "\n",
    "2. Не числа (их нахуй)\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Кодирование признаков <a class=\"anchor\" id=3></a>\n",
    "\n",
    "## Можно посмотреть файл `codding.ipynb`\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://www.dropbox.com/s/64ol9q9ssggz6f1/data_ford_price.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data_ford_price.xlsx') \n",
    "y = data['price']\n",
    "x = data.drop(columns='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем применить линейную регрессию на «сырых» данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3993/2705597199.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'clean'"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получим ошибку с комментарием о том, что не удалось превратить строковое значение в число с плавающей точкой (`float`).\n",
    "\n",
    "Чтобы этой ошибки не возникало, необходимо **закодировать данные.**\n",
    "\n",
    "<img src=ml6_img1.png>\n",
    "\n",
    "В таблице ниже представлено сравнение данных способов кодировки:\n",
    "\n",
    "<img src=ml6_img2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации данных методов мы использовали библиотеку [category_encoders](https://contrib.scikit-learn.org/category_encoders/). Однако вы уже знаете и такой мощный инструмент, как [scikit-learn](https://scikit-learn.org/). Данная библиотека содержит набор реализованных алгоритмов машинного обучения, метрик для оценки их качества, а также  класс preprocessing для предобработки данных, в частности — для кодирования категориальных признаков.\n",
    "\n",
    "Представленная ниже таблица показывает соответствие типа кодирования классу в `sklearn.processing`.\n",
    "\n",
    "<img src=ml6_img3.png>\n",
    "\n",
    "Преимущество использования одной библиотеки состоит в типичности методов. Например, вы знаете, что для обучения модели в sklearn используется метод `fit()`. При кодировании признаков здесь также применяют `fit()` для подгонки кодировщика под выборку и `transform()` — для преобразования данных в числа.\n",
    "\n",
    "<img src=ml6_img4.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из предыдущих модулей мы знаем, что при решении задач машинного обучения данные разбираются на обучающую (`train`) и валидационную (`validation`) выборки (последняя также может быть тестовой (`test`) выборкой). По аналогии подгонка кодировщика происходит на обучающей выборке, а трансформация — на обучающей и на тестовой.\n",
    "\n",
    "Почему так? Потому что наша обученная модель не должна видеть данные, которые подаются в неё на тесте. Только так мы можем судить о том, что модель обучена качественно. То же самое и с кодировкой.\n",
    "\n",
    "Давайте посмотрим на кодирование признака Образование способом **«один-против-всех»** (`one vs all`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "категории: ['BSc' 'MSc' 'PhD' 'начальное' 'нет' 'среднее']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing  import LabelBinarizer\n",
    " \n",
    "lb = LabelBinarizer()\n",
    " \n",
    "education = ['нет', 'начальное', 'среднее', 'BSc', 'MSc', 'начальное', 'PhD']\n",
    " \n",
    "lb.fit(education)\n",
    " \n",
    "print('категории:', lb.classes_)\n",
    " \n",
    "lb.transform(['нет', 'MSc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У класса `LabelBinarizer`, как и у двух остальных, есть атрибут `classes_`, который выводит список уникальных значений признака.\n",
    "\n",
    "Вернёмся к нашей выборке. В ней присутствуют следующие категориальные признаки: `condition`, `cylinders`, `title_status`, `transmission`, `drive`, `size`.\n",
    "\n",
    "При этом, признаки: \n",
    "* `condition` и `cylinders` — **числовые**\n",
    "\n",
    "*  `title_status`, `transmission`, `drive`, `size` —**текстовые**.\n",
    "\n",
    "<img src=ml6_img5.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Важно производить кодирование номинальных признаков, даже если они уже представлены в числовом формате, так как, в отличие от порядковых признаков, **категории номинальных являются независимыми**. В случае порядкового кодирования таких признаков мы вносим искусственные закономерности в данные (например, чем больше числовой код цилиндров, тем лучше, хотя это необязательно так)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на число уникальных значений номинальных признаков `title_status`, `transmission`, `drive`, `size` и `cylinders`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число уникальных значений признака cylinders:  6\n",
      "Число уникальных значений признака title_status:  5\n",
      "Число уникальных значений признака transmission:  3\n",
      "Число уникальных значений признака drive:  3\n",
      "Число уникальных значений признака size:  4\n"
     ]
    }
   ],
   "source": [
    "columns_to_change = ['cylinders', 'title_status', 'transmission', 'drive', 'size']\n",
    " \n",
    "for column in columns_to_change:\n",
    " print('Число уникальных значений признака {}: '.format(column), data[column].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, нам подходит однократное кодирование. Применим его к выбранным столбцам. Так как у нас нет отдельной тестовой выборки, то мы используем только один метод — `fit_transform()`. В качестве аргумента передаём таблицу с выбранными для преобразования признаками.\n",
    "\n",
    "С помощью метода `get_feature_names()` получим список новых названий колонок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OneHotEncoder' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3993/173259531.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# запишем полученные названия новых колонок в отдельную переменную\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_to_change\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OneHotEncoder' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "one_hot_encoder = OneHotEncoder()\n",
    " \n",
    "# 'учим' и сразу применяем преобразование к выборке, результат переводим в массив\n",
    "data_onehot = one_hot_encoder.fit_transform(data[columns_to_change]).toarray()\n",
    " \n",
    "# запишем полученные названия новых колонок в отдельную переменную\n",
    "column_names = one_hot_encoder.get_feature_names(columns_to_change)\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7017, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new = pd.get_dummies(data)\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обработка пропусков и выбросов <a class=\"anchor\" id=4></a>\n",
    "\n",
    "[к содержанию](#0)\n",
    "\n",
    "## Можно посмотреть `NaNs.ipynb`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price              0\n",
       "year               0\n",
       "condition          0\n",
       "cylinders          0\n",
       "odometer           0\n",
       "title_status       0\n",
       "transmission       0\n",
       "drive            391\n",
       "size            1564\n",
       "lat                0\n",
       "long               0\n",
       "weather          180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data_ford_price.xlsx') \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43900</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>43500</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>36.471500</td>\n",
       "      <td>-82.483400</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15490</td>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>98131</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>40.468826</td>\n",
       "      <td>-74.281734</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2495</td>\n",
       "      <td>2002</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>201803</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>42.477134</td>\n",
       "      <td>-82.949564</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>170305</td>\n",
       "      <td>rebuilt</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>40.764373</td>\n",
       "      <td>-82.349503</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6995</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>167662</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>45.518031</td>\n",
       "      <td>-122.578752</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>22500</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>23500</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>32.680700</td>\n",
       "      <td>-117.169800</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>5975</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>38.213303</td>\n",
       "      <td>-85.785762</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>9999</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>161514</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full-size</td>\n",
       "      <td>37.609783</td>\n",
       "      <td>-120.995406</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>10900</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>164000</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>43.140600</td>\n",
       "      <td>-93.385000</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>18000</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>104000</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>37.987200</td>\n",
       "      <td>-84.178900</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6837 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  year  condition  cylinders  odometer title_status transmission  \\\n",
       "0     43900  2016          4          6     43500        clean    automatic   \n",
       "1     15490  2009          2          8     98131        clean    automatic   \n",
       "2      2495  2002          2          8    201803        clean    automatic   \n",
       "3      1300  2000          1          8    170305      rebuilt    automatic   \n",
       "5      6995  2003          3          8    167662        clean    automatic   \n",
       "...     ...   ...        ...        ...       ...          ...          ...   \n",
       "7012  22500  2015          3          6     23500        clean    automatic   \n",
       "7013   5975  2005          2          8         0        clean    automatic   \n",
       "7014   9999  2006          3          8    161514        clean    automatic   \n",
       "7015  10900  2011          2          8    164000        clean    automatic   \n",
       "7016  18000  2010          2          8    104000        clean    automatic   \n",
       "\n",
       "     drive       size        lat        long  weather  \n",
       "0      4wd  full-size  36.471500  -82.483400     59.0  \n",
       "1      4wd  full-size  40.468826  -74.281734     52.0  \n",
       "2      4wd  full-size  42.477134  -82.949564     45.0  \n",
       "3      4wd  full-size  40.764373  -82.349503     49.0  \n",
       "5      4wd  full-size  45.518031 -122.578752     50.0  \n",
       "...    ...        ...        ...         ...      ...  \n",
       "7012   rwd  full-size  32.680700 -117.169800     59.0  \n",
       "7013   rwd  full-size  38.213303  -85.785762     50.0  \n",
       "7014   NaN  full-size  37.609783 -120.995406     59.0  \n",
       "7015   4wd  full-size  43.140600  -93.385000     47.0  \n",
       "7016   4wd  full-size  37.987200  -84.178900     50.0  \n",
       "\n",
       "[6837 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим, что будет, если просто убрать все строки с пропусками в столбце weather:\n",
    "data[~data['weather'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Символ `~ `(тильда) означает, что мы выбираем все строки датасета data, где не выполняется условие `data['weather'].isna()`, то есть где нет пропусков в столбце 'weather'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Какая доля строк в датасете останется, если убрать пропуски в столбце size? Ответ округлите до двух знаков после точки-разделителя\n",
    "round(data[~data['size'].isna()].shape[0] / data.shape[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=ml6_img6.png>\n",
    "\n",
    ">Первым делом воспользуемся методом удаления строк с пропусками. Плюс данного метода состоит в том, что модель, обученная с удалением всех пропущенных значений, является надёжной, то есть имеет сравнительно хорошее качество на тесте. Среди минусов — потеря большого количества информации, а также плохое качество работы, если процент отсутствующих значений слишком велик по сравнению с полным набором данных.\n",
    "\n",
    "В качестве регрессора воспользуемся линейной моделью, а качество оценим с помощью коэффициента детерминации. Также нам потребуется разделить модель на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "x = data.drop(columns='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим данные с пропусками:\n",
    "x = x.dropna()\n",
    "\n",
    "# Выберем все оставшиеся индексы таблицы x с помощью метода index(), \n",
    "# а затем используем .iloc[], чтобы получить подгруппу целевых значений, соответствующую полученным индексам.\n",
    "y = y.iloc[x.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим выборку на тренировочную и тестовую в соотношении 80/20:\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведём кодирование OneHot-методом категориальных переменных.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Зададим имена признаков\n",
    "columns_to_change = ['cylinders', 'title_status', 'transmission', 'drive', 'size']\n",
    "\n",
    "# Обучаем энкодер и сразу применяем преобразование к выборке. Результат переводим в массив:\n",
    "X_train_onehot = one_hot_encoder.fit_transform(X_train[columns_to_change]).toarray()\n",
    "\n",
    "\n",
    "# Затем применяем полученное преобразование к тестовой выборке. Результат переводим в массив:\n",
    "X_test_onehot = one_hot_encoder.transform(X_test[columns_to_change]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_onehot_df = pd.DataFrame(X_train_onehot)\n",
    "X_test_onehot_df = pd.DataFrame(X_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица `X_train` содержит рандомные индексы, так как мы разделили выборку на `train` и `test`. Если просто соединить `X_train` и `X_train_onehot_df`, то получится таблица, полная пропусков по причине несовпадения индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
    "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
    " \n",
    "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
    "y_test = y_test.reset_index().drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
    "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
    " \n",
    "X_train_new = X_train_new.drop(columns=columns_to_change)\n",
    "X_test_new = X_test_new.drop(columns=columns_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1041 entries, 0 to 1040\n",
      "Data columns (total 27 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   year       1041 non-null   int64  \n",
      " 1   condition  1041 non-null   int64  \n",
      " 2   odometer   1041 non-null   int64  \n",
      " 3   lat        1041 non-null   float64\n",
      " 4   long       1041 non-null   float64\n",
      " 5   weather    1041 non-null   float64\n",
      " 6   0          1041 non-null   float64\n",
      " 7   1          1041 non-null   float64\n",
      " 8   2          1041 non-null   float64\n",
      " 9   3          1041 non-null   float64\n",
      " 10  4          1041 non-null   float64\n",
      " 11  5          1041 non-null   float64\n",
      " 12  6          1041 non-null   float64\n",
      " 13  7          1041 non-null   float64\n",
      " 14  8          1041 non-null   float64\n",
      " 15  9          1041 non-null   float64\n",
      " 16  10         1041 non-null   float64\n",
      " 17  11         1041 non-null   float64\n",
      " 18  12         1041 non-null   float64\n",
      " 19  13         1041 non-null   float64\n",
      " 20  14         1041 non-null   float64\n",
      " 21  15         1041 non-null   float64\n",
      " 22  16         1041 non-null   float64\n",
      " 23  17         1041 non-null   float64\n",
      " 24  18         1041 non-null   float64\n",
      " 25  19         1041 non-null   float64\n",
      " 26  20         1041 non-null   float64\n",
      "dtypes: float64(24), int64(3)\n",
      "memory usage: 219.7 KB\n"
     ]
    }
   ],
   "source": [
    "X_test_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведём названия признаков к типу str (иначе модель выкидывает ошибку)\n",
    "X_train_new.columns = X_train_new.columns.astype(str)\n",
    "X_test_new.columns = X_test_new.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.647\n",
      "Test R^2: 0.693\n"
     ]
    }
   ],
   "source": [
    "# Настало время обучить модель. Для этого создаём объект класса LinearRegression.\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "#Обучаем модель по МНК:\n",
    "lr_model.fit(X_train_new, y_train)\n",
    "\n",
    "#Делаем предсказание для тренировочной выборки:\n",
    "y_train_predict = lr_model.predict(X_train_new)\n",
    "\n",
    "#Делаем предсказание для тестовой выборки:\n",
    "y_test_predict = lr_model.predict(X_test_new)\n",
    "print(\"Train R^2: {:.3f}\".format(r2_score(y_train, y_train_predict)))\n",
    "print(\"Test R^2: {:.3f}\".format(r2_score(y_test, y_test_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Теперь давайте попробуем заполнить пропуски константными значениями и обучить модель заново. Плюс такого подхода состоит в том, что мы предотвращаем потерю данных, которая происходит при удалении строк или столбцов. Основной минус — в снижении разброса (разнообразия) признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним числовой столбец средним значением, округлив его до целого числа:\n",
    "import numpy as np\n",
    " \n",
    "X_train['weather'] = X_train['weather'].fillna(np.round(np.mean(X_train['weather']),0))\n",
    "X_test['weather'] = X_test['weather'].fillna(np.round(np.mean(X_train['weather']),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты воспользуемся заполнением наиболее частым значением категориальных признаков. Для этого сначала определим их в наших признаках, использовав комбинацию методов value_counts() и head():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4wd    0.736602\n",
       "Name: drive, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['drive'].value_counts(True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full-size    0.830089\n",
       "Name: size, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['size'].value_counts(True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['size'] = X_train['size'].fillna('full-size')\n",
    "X_train['drive'] = X_train['drive'].fillna('4wd')\n",
    " \n",
    "X_test['size'] = X_test['size'].fillna('full-size')\n",
    "X_test['drive'] = X_test['drive'].fillna('4wd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### После обучения модели получился следующий результат:\n",
    "### Train R^2: 0.649\n",
    "### Test R^2: 0.465\n",
    "\n",
    ">Напомним: модели с коэффициентом детерминации выше 0.8 можно признать достаточно хорошими. Равенство коэффициента детерминации 1 означает, что объясняемая переменная в точности описывается рассматриваемой моделью.\n",
    "\n",
    "Приведённые методы обработки отсутствующих значений не учитывают корреляционную связь признака, содержащего пропуски, с остальными. Признаки, не имеющие NaN, можно использовать для прогнозирования пропущенных значений. Строится модель регрессии или классификации в зависимости от характера (категорийного или непрерывного) признака, имеющего пропущенное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data_ford_price.xlsx') \n",
    "y = data['price']\n",
    "x = data.drop(columns='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "data = x.copy()\n",
    " \n",
    "test_data = data[data['weather'].isnull()]\n",
    "data.dropna(inplace=True)\n",
    " \n",
    "y_train = data['weather']\n",
    "X_train = data.drop(['size','weather','drive'], axis=1)\n",
    "X_test = test_data.drop(['size','weather','drive'], axis=1)\n",
    " \n",
    "one_hot_encoder = OneHotEncoder()\n",
    "categorial_cols = ['cylinders', 'title_status', 'transmission']\n",
    " \n",
    "X_train_onehot = one_hot_encoder.fit_transform(X_train[categorial_cols]).toarray()\n",
    "X_test_onehot = one_hot_encoder.transform(X_test[categorial_cols]).toarray()\n",
    " \n",
    "columns = one_hot_encoder.get_feature_names_out(categorial_cols)\n",
    "X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
    "X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)\n",
    " \n",
    "X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
    "X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
    "y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
    " \n",
    "X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
    "X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
    " \n",
    "X_train_new = X_train_new.drop(columns=categorial_cols)\n",
    "X_test_new = X_test_new.drop(columns=categorial_cols)\n",
    " \n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train_new, y_train)\n",
    " \n",
    "y_pred = model.predict(X_test_new)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные предсказания есть не что иное, как замена пропусков в столбце `weather`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3337/3939650608.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['weather'].loc[ni] = y_pred[i]\n"
     ]
    }
   ],
   "source": [
    "for i, ni in enumerate(test_data.index[:len(x)]):\n",
    "             x['weather'].loc[ni] = y_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['weather'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7017 entries, 0 to 7016\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   year          7017 non-null   int64  \n",
      " 1   condition     7017 non-null   int64  \n",
      " 2   cylinders     7017 non-null   int64  \n",
      " 3   odometer      7017 non-null   int64  \n",
      " 4   title_status  7017 non-null   object \n",
      " 5   transmission  7017 non-null   object \n",
      " 6   drive         6626 non-null   object \n",
      " 7   size          5453 non-null   object \n",
      " 8   lat           7017 non-null   float64\n",
      " 9   long          7017 non-null   float64\n",
      " 10  weather       7017 non-null   float64\n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 603.1+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный признак является категориальным. Следовательно, понадобится классификатор для заполения пропусков в нем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x.copy()\n",
    " \n",
    "test_data = data[data['size'].isnull()]\n",
    "data.dropna(inplace=True)\n",
    " \n",
    "y_train = data['size']\n",
    "X_train = data.drop(['size', 'drive'], axis=1)\n",
    "X_test = test_data.drop(['size','drive'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция которая делает хуй знает что\n",
    "def encode_cat_features(columns_to_change, X_train, X_test, y_train):\n",
    "  one_hot_encoder = OneHotEncoder()\n",
    "  X_train_onehot = one_hot_encoder.fit_transform(X_train[columns_to_change]).toarray()\n",
    "  X_test_onehot = one_hot_encoder.transform(X_test[columns_to_change]).toarray()\n",
    "\n",
    "  columns = one_hot_encoder.get_feature_names_out(columns_to_change)\n",
    "  \n",
    "  X_train_onehot_df = pd.DataFrame(X_train_onehot, columns=columns)\n",
    "  X_test_onehot_df = pd.DataFrame(X_test_onehot, columns=columns)\n",
    "\n",
    "  X_train = X_train.reset_index().drop(['index'], axis = 1)\n",
    "  X_test = X_test.reset_index().drop(['index'], axis = 1)\n",
    "  y_train = y_train.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "  X_train_new = pd.concat([X_train, X_train_onehot_df], axis=1)\n",
    "  X_test_new = pd.concat([X_test, X_test_onehot_df], axis=1)\n",
    "  \n",
    "  X_train_new = X_train_new.drop(columns=columns_to_change)\n",
    "  X_test_new = X_test_new.drop(columns=columns_to_change)\n",
    "\n",
    "  return X_train_new, X_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new = encode_cat_features(categorial_cols, X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubakirov/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/tmp/ipykernel_3337/1298508494.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x['size'].loc[ni] = y_pred[i]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_new, y_train)\n",
    " \n",
    "y_pred = model.predict(X_test_new)\n",
    "\n",
    "for i, ni in enumerate(test_data.index[:len(x)]):\n",
    "             x['size'].loc[ni] = y_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7017 entries, 0 to 7016\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   year          7017 non-null   int64  \n",
      " 1   condition     7017 non-null   int64  \n",
      " 2   cylinders     7017 non-null   int64  \n",
      " 3   odometer      7017 non-null   int64  \n",
      " 4   title_status  7017 non-null   object \n",
      " 5   transmission  7017 non-null   object \n",
      " 6   drive         6626 non-null   object \n",
      " 7   size          7017 non-null   object \n",
      " 8   lat           7017 non-null   float64\n",
      " 9   long          7017 non-null   float64\n",
      " 10  weather       7017 non-null   float64\n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 603.1+ KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РАБОТА С ВЫБРОСАМИ\n",
    "\n",
    "Помимо пропусков, на пути анализа данных всплывает ещё один подводный камень — выбросы (аномалии).\n",
    "\n",
    ">Выбросы могут искажать статистические показатели и распределения данных. Удаление выбросов из обучающих данных перед моделированием может привести к росту качества прогнозов.\n",
    ">\n",
    ">К счастью, существуют автоматические, основанные на моделях методы выявления выбросов, которые уже имплементированы в  `sklearn`.\n",
    "\n",
    "Посмотрим, как обработка выбросов влияет на качество модели регрессии. В качестве метрики воспользуемся MAE.\n",
    "\n",
    "Для начала сформируем baseline-модель. Проведём следующую предобработку: для простоты уберём категориальные столбцы из данных и затем удалим строки с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>odometer</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>43500</td>\n",
       "      <td>36.471500</td>\n",
       "      <td>-82.483400</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>98131</td>\n",
       "      <td>40.468826</td>\n",
       "      <td>-74.281734</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>8</td>\n",
       "      <td>201803</td>\n",
       "      <td>42.477134</td>\n",
       "      <td>-82.949564</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>170305</td>\n",
       "      <td>40.764373</td>\n",
       "      <td>-82.349503</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>8</td>\n",
       "      <td>167662</td>\n",
       "      <td>45.518031</td>\n",
       "      <td>-122.578752</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  cylinders  odometer        lat        long  weather\n",
       "0  2016          6     43500  36.471500  -82.483400     59.0\n",
       "1  2009          8     98131  40.468826  -74.281734     52.0\n",
       "2  2002          8    201803  42.477134  -82.949564     45.0\n",
       "3  2000          8    170305  40.764373  -82.349503     49.0\n",
       "5  2003          8    167662  45.518031 -122.578752     50.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data_ford_price.xlsx') \n",
    "data = data[['price', 'year', 'cylinders', 'odometer' ,'lat', 'long', 'weather']]\n",
    "data.dropna(inplace = True)\n",
    " \n",
    "y = data['price']\n",
    "x = data.drop(columns='price')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4856.318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=30)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Первый алгоритм, который мы применим, — `Isolation Forest`, или `iForest`. Это алгоритм обнаружения аномалий на основе дерева.\n",
    "\n",
    ">Данный метод стремится изолировать аномалии, которые немногочисленны и различаются по пространству признаков.\n",
    "\n",
    "Библиотека `scikit`-`learn` предоставляет реализацию `Isolation` `Forest` в классе `IsolationForest`.\n",
    "\n",
    "Одним из основных гиперпараметров модели является `contamination` («загрязнение»), который используется для оценки количества выбросов в наборе данных. Его значение находится в диапазоне от 0.0 до 0.5 и по умолчанию равно 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubakirov/.local/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4307, 6) (4307,)\n",
      "MAE: 4751.723\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.ensemble import IsolationForest\n",
    " \n",
    "# ищем выбросы в обучающей выборке\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "y_predicted = iso.fit_predict(X_train)\n",
    " \n",
    "# выберем все строки, которые не являются выбросами\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Следующий метод — `Local` `Outlier` `Factor`, или `LOF`. Это метод, который пытается использовать идею ближайших соседей для обнаружения выбросов.\n",
    "\n",
    ">Каждому примеру присваивается оценка того, насколько он изолирован от его локальных соседей. Примеры, которые наиболее отдалены от соседей, скорее всего, будут являться выбросами.\n",
    "\n",
    "Библиотека `scikit`-`learn` обеспечивает реализацию этого подхода в классе `LocalOutlierFactor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4019, 6) (4019,)\n",
      "MAE: 4762.499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    " \n",
    "lof = LocalOutlierFactor()\n",
    "y_predicted = lof.fit_predict(X_train)\n",
    "\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Напоследок рассмотрим `Minimum` `Covariance` `Determinant`, или `MCD`.\n",
    "\n",
    "Если входные переменные имеют гауссово распределение, то для обнаружения выбросов можно использовать простые статистические методы.\n",
    "\n",
    "Например, если набор данных имеет две входные переменные и обе они являются гауссовыми, то пространство признаков образует многомерную гауссовскую зависимость, и знание этого распределения можно использовать для определения значений, далёких от распределения.\n",
    "\n",
    ">Этот подход можно обобщить, определив гиперсферу (эллипсоид), которая покрывает нормальные данные, а данные, выходящие за пределы этой формы, считаются выбросами. Эффективная реализация этого метода для многомерных данных известна как детерминант минимальной ковариации (`MCD`).\n",
    "\n",
    "Библиотека `scikit`-`learn` предоставляет доступ к этому методу через класс `EllipticEnvelope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3978, 6) (3978,)\n",
      "MAE: 4779.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    " \n",
    "ee = EllipticEnvelope(contamination=0.01)\n",
    "y_predicted = ee.fit_predict(X_train)\n",
    "\n",
    "mask = y_predicted != -1\n",
    "X_train, y_train = X_train[mask], y_train[mask]\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "y_predicted = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Данные алгоритмы носят стохастический характер, поэтому результаты метрики могут отличатся **от прогона к прогону**.\n",
    "\n",
    "Мы видим, что оптимальный результат достигается с помощью древовидного алгоритма Isolation Forest, тогда как пространственные методы LOF и MCD принимают за выбросы больше данных, что приводит к ухудшению качества. Тем не менее, все три метода превосходят baseline.\n",
    "\n",
    "Ниже приведено визуальное сравнение трёх методов на «игрушечных» данных:\n",
    "\n",
    "<img src=ml6_img7.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Масштабирование признаков <a class=\"anchor\" id=5></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Трансформации распределений признаков <a class=\"anchor\" id=6></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Даты и расстояния <a class=\"anchor\" id=7></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Отбор признаков: Мотивация <a class=\"anchor\" id=8></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Отбор признаков: Классификация методов <a class=\"anchor\" id=9></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Практика <a class=\"anchor\" id=10></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Итоги <a class=\"anchor\" id=11></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
