{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH&ML-2 Линейная алгебра в констекте линейных методов. Часть2\n",
    "###  Содержание <a class=\"anchor\" id=0></a>\n",
    "\n",
    "- [2. Неоднородные СЛАУ](#2)\n",
    "- [3. Линейная регрессия МНК](#3)\n",
    "- [4. Стандартизация векторов и матрица корреляции](#4)\n",
    "- [5. Практика. Лин.регрессия МНК](#5)\n",
    "- [6. Полиноминальная регрессия](#6)\n",
    "- [7. Регуляция](#7)\n",
    "- [8. Практика. Полиноминальная регрессия и регуляция](#8)\n",
    "- [9. Итоги](#9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Неоднородные СЛАУ <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Совокупность уравнений первой степени, в которых каждая переменная и коэффициенты в ней являются вещественными числами, называется **системой линейных алгебраических уравнений** (`СЛАУ`) и в общем случае записывается как:\n",
    ">\n",
    ">$\\left\\{ \\begin{array}{c} a_{11}x_1+a_{12}x_2+\\dots +a_{1m}x_m=b_1 \\\\ a_{21}x_1+a_{22}x_2+\\dots +a_{2m}x_m=b_2 \\\\ \\dots \\\\ a_{n1}x_1+a_{n2}x_2+\\dots +a_{nm}x_m=b_n \\end{array} \\right.\\ (1),$\n",
    ">\n",
    ">где\n",
    ">\n",
    ">* $n$— количество уравнений;\n",
    ">\n",
    ">* $m$ — количество переменных;\n",
    ">\n",
    ">* $x_i$ — неизвестные переменные системы;\n",
    ">\n",
    ">* $a_{ij}$ — коэффициенты системы;\n",
    ">\n",
    ">* $b_i$ — свободные члены системы.\n",
    ">\n",
    ">\n",
    ">\n",
    ">СЛАУ (1) называется **однородной**, если все свободные члены системы равны 0 $b_1=b_2=⋯=b_n=0$:\n",
    ">\n",
    ">$\\textrm{С}\\textrm{Л}\\textrm{А}\\textrm{У}-\\textrm{о}\\textrm{д}\\textrm{н}\\textrm{о}\\textrm{р}\\textrm{о}\\textrm{д}\\textrm{н}\\textrm{а}\\textrm{я},\\ \\textrm{е}\\textrm{с}\\textrm{л}\\textrm{и}\\ \\forall b_i=0$\n",
    ">\n",
    ">\n",
    ">\n",
    ">СЛАУ (1) называется **неоднородной**, если хотя бы один из свободных членов системы отличен от 0:\n",
    ">\n",
    ">$\\textrm{С}\\textrm{Л}\\textrm{А}\\textrm{У}- \\textrm{н}\\textrm{е}\\textrm{о}\\textrm{д}\\textrm{н}\\textrm{о}\\textrm{р}\\textrm{о}\\textrm{д}\\textrm{н}\\textrm{а}\\textrm{я},\\ \\textrm{е}\\textrm{с}\\textrm{л}\\textrm{и}\\ \\exists b_i\\neq 0$\n",
    ">\n",
    ">\n",
    ">\n",
    ">**Решением** СЛАУ (1) называется такой набор значений неизвестных переменных $x_1,x_2,…,x_n$ при котором каждое уравнение системы превращается в равенство.\n",
    ">\n",
    ">\n",
    ">\n",
    ">СЛАУ (1) называется **определённой**, если она имеет только одно решение, и **неопределённой**, если возможно больше одного решения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним, что СЛАУ можно записать в матричном виде:\n",
    "\n",
    "$A\\overrightarrow{x}=\\overrightarrow{b}$\n",
    "\n",
    "$\\left( \\begin{array}{cccc} a_{11} & a_{12} & \\dots & a_{1m} \\\\ a_{21} & a_{22} & \\dots & a_{2m} \\\\ \\dots & \\dots & \\dots & \\dots \\\\ a_{n1} & a_{n2} & \\dots & a_{nm} \\end{array} \\right) \\cdot \\left( \\begin{array}{c} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_m \\end{array} \\right)=\\left( \\begin{array}{c} b_1 \\\\ b_2 \\\\ \\dots \\\\ b_n \\end{array} \\right)$\n",
    "\n",
    "где $A$ — матрица системы, $\\overrightarrow{x}$ — вектор неизвестных коэффициентов, а $b$ — вектор свободных коэффициентов. \n",
    "\n",
    "Давайте введём новое для нас определение.\n",
    "\n",
    ">**Расширенной матрицей системы $(A|b)$ неоднородных СЛАУ** называется матрица, составленная из исходной матрицы и вектора свободных коэффициентов (записывается через вертикальную черту):\n",
    ">\n",
    ">$(A \\mid \\vec{b})=\\left(\\begin{array}{cccc|c} a_{11} & a_{12} & \\ldots & a_{1 m} & b_{1} \\\\ a_{21} & a_{22} & \\ldots & a_{2 m} & b_{2} \\\\ \\ldots & \\ldots & \\ldots & \\ldots & \\ldots \\\\ a_{n 1} & a_{n 2} & \\ldots & a_{n m} & b_{n} \\end{array}\\right)$\n",
    "\n",
    "Расширенная матрица системы — это обычная матрица. Черта, отделяющая коэффициенты $a_{ij}$ от свободных членов $b_i$ — чисто символическая. \n",
    "\n",
    "Над расширенной матрицей неоднородной СЛАУ можно производить те же самые действия, что и над обычной, а именно:\n",
    "\n",
    "* складывать/вычитать между собой строки/столбцы матрицы;\n",
    "* умножать строки/столбцы на константу;\n",
    "* менять строки/столбцы местами.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Приведём пример расширенной матрицы системы. Пусть исходная система будет следующей:\n",
    "\n",
    "$\\left\\{\\begin{array}{c} w_{1}+w_{2}=1 \\\\ w_{1}+2 w_{2}=2 \\end{array}\\right.$\n",
    "\n",
    "Запишем её в матричном виде:\n",
    "\n",
    "$\\left(\\begin{array}{cc} 1 & 1 \\\\ 1 & 2  \\end{array} \\right) \\cdot \\left(\\begin{array}{c} w_1 \\\\ w_2  \\end{array} \\right) = \\left(\\begin{array}{c} 1 \\\\ 2  \\end{array} \\right)$\n",
    "\n",
    "Тогда расширенная матрица системы будет иметь вид:\n",
    "\n",
    "$(A \\mid b)=\\left(\\begin{array}{cc|c} 1 & 2 & 1 \\\\ 1 & 2 & 2 \\\\ \\end{array}\\right)$\n",
    "\n",
    "***\n",
    "\n",
    "Существует три случая при решении неоднородных СЛАУ:\n",
    "\n",
    "* **«Идеальная пара»**\n",
    "\n",
    "Это так называемые определённые системы линейных уравнений, имеющие **единственные решения**.\n",
    "\n",
    "* **«В активном поиске»**\n",
    "\n",
    "Неопределённые системы, имеющие **бесконечно много решений**.\n",
    "\n",
    "* **«Всё сложно»**\n",
    "\n",
    "Это самый интересный для нас случай — переопределённые системы, которые **не имеют точных решений**.\n",
    "\n",
    ">**Примечание**. В данной классификации неоднородных СЛАУ допущено упрощение в терминологии. На самом деле неопределённые системы — это те, в которых независимых уравнений меньше, чем неизвестных. Они могут иметь бесконечно много решений (быть совместными) или ни одного решения (быть несовместными, если уравнения противоречат друг другу).\n",
    ">\n",
    ">На практике, например в обучении регрессий, этот случай практически не встречается.\n",
    ">\n",
    ">Что касается переопределённых систем, то в них, помимо несовместности (отсутствия решений), количество независимых уравнений превышает количество неизвестных — это тот самый случай, что мы видим в регрессионном анализе."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СЛУЧАЙ «ИДЕАЛЬНАЯ ПАРА»\n",
    "\n",
    ">Самый простой случай решения неоднородной СЛАУ — когда система **имеет единственное решение**. Такие системы называются **совместными**.\n",
    "\n",
    "На вопрос о том, когда СЛАУ является совместной, отвечает главная теорема СЛАУ — теорема **Кронекера — Капелли** (также её называют **критерием совместности системы**).\n",
    "\n",
    "***\n",
    "\n",
    "**Теорема Кронекера — Капелли:**\n",
    "\n",
    "Неоднородная система линейный алгебраических уравнений $A\\overrightarrow{w} = \\overrightarrow{b}$ является совместной тогда и только тогда, когда ранг матрицы системы $A$ равен рангу расширенной матрицы системы $(A|b)$ и равен количеству независимых переменных $m$:\n",
    "\n",
    "$rk(A) = rk(A|\\overrightarrow{b}) = m \\leftrightarrow \\exists ! \\overrightarrow{w} = (w_{1}, w_{2}, \\ldots w_m)^T$\n",
    "\n",
    "Причём решение системы будет равно:\n",
    "\n",
    "$\\overrightarrow{w} = A^{-1} \\overrightarrow{b}$\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Пример №1\n",
    "\n",
    "$\\left\\{\\begin{array}{c} w_{1}+w_{2}=1 \\\\ w_{1}+2 w_{2}=2 \\end{array}\\right.$\n",
    "\n",
    "где  $w_1$ и $w_2$ — неизвестные переменные.\n",
    "\n",
    "При решении системы «в лоб» получим:\n",
    "\n",
    "$\\left\\{\\begin{array}{c} w_{1}+w_{2}=1 \\\\ w_{1}+2 w_{2}=2 \\end{array}\\right. \\Rightarrow \\left\\{\\begin{array}{c} w_{1}+w_{2}=1 \\\\ w_{2}=2 \\end{array}\\right. \\Rightarrow \\left\\{\\begin{array}{c} w_{1}=0 \\\\ w_{2}=0 \\end{array}\\right.$\n",
    "\n",
    "Интерпретация:\n",
    "\n",
    "$\\left( \\begin{array}{c} 1 \\\\ 2 \\end{array}\\right) = 0 \\cdot \\left( \\begin{array}{c} 1 \\\\ 1 \\end{array}\\right) + 1 \\cdot \\left( \\begin{array}{c} 1 \\\\ 2 \\end{array}\\right)$\n",
    "\n",
    "На языке линейной алгебры это означает что вектор $(1, 2)^T$ линейно выражается через векторы коэффициентов системы $(1, 1)^T$ и $(1, 2)^T$.\n",
    "\n",
    "В матричном виде система запишется, как:\n",
    "\n",
    "$A\\overrightarrow{w}=\\overrightarrow{b} \\text{где}A = \\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & 2 \\end{array}\\right), \\overrightarrow{w}=\\left( \\begin{array}{c} w_1 \\\\ w_2 \\end{array}\\right), \\overrightarrow{b}=\\left( \\begin{array}{c} b_1 \\\\ b_2 \\end{array}\\right) $ \n",
    "\n",
    "Преобразование уравнений будем таким же, как и при преобразовании расширенной матрицы системы $(A|b)$, вычитая сначала первую строку из второй, а затем — результат из первой, получим то же решение, что и решение «в лоб».\n",
    "\n",
    "$(A|\\overrightarrow{b})=\\left(\\begin{array}{cc|c} 1 & 1 & 1  \\\\ 1 & 2 & 2 \\end{array} \\right) \\Rightarrow \\left(\\begin{array}{cc|c} 1 & 1 & 1  \\\\ 0 & 1 & 1 \\end{array} \\right) \\Rightarrow \\left(\\begin{array}{cc|c} 1 & 0 & 0  \\\\ 0 & 1 & 1 \\end{array} \\right) \\Rightarrow \\left\\{\\begin{array}{c} w_1=0  \\\\ w_2=0 \\end{array} \\right.$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Других решений у системы нет. \n",
    "\n",
    "Посмотрим на ранги матрицы $А$ и расширенной матрицы $(A|b)$ (количество ступеней в ступенчатых матрицах):\n",
    "\n",
    "$rk(A)=\\left(\\begin{array}{cc} 1 & 0 \\\\ 0 & 1\\end{array}\\right)=2$\n",
    "\n",
    "$rk(A|b)=\\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\ 0 & 1 & 1\\end{array}\\right)=2$\n",
    "\n",
    "$rk(A)=rk(A|b)$\n",
    "\n",
    "Они совпадают и равны количеству неизвестных, а это и гарантирует существование и **единственность решения**. То есть в общем случае, чтобы узнать, сколько решений существует у системы, её необязательно было бы решать — достаточно было бы найти ранги матриц $rk(A)$ и $rk(A|b)$ ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Тут возникает вопрос: «Можно ли найти решение одной формулой?»\n",
    "\n",
    "Для удобства перепишем систему без стрелок:\n",
    "\n",
    "$Aw=b$\n",
    "\n",
    "Так как матрица квадратная и невырожденная, у неё обязательно есть обратная матрица.\n",
    "\n",
    "Умножим на $A^{-1}$ слева обе части уравнения. Стоит напомнить, что произведение матриц **не перестановочно**, поэтому есть разница, с какой стороны умножать.\n",
    "\n",
    "$A^{-1} \\cdot Aw = A^{-1}\\cdot b$\n",
    "\n",
    "$w=A^{-1}\\cdot b$\n",
    "\n",
    ">**Важно**! Отсюда явно видны ограничения этого метода: его можно применять только **для квадратных невырожденных матриц** (тех, у которых определитель не равен 0).\n",
    "\n",
    "Убедимся в правильности формулы. Найдём произведение матрицы $A^{-1}$ и вектора-столбца $b$:\n",
    "\n",
    "$A^{-1}\\cdot b=\\left( \\begin{array}{cc} 1 & 1 \\\\ 1 & 2 \\end{array}\\right)^{-1} \\cdot \\left(\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right)=\\left( \\begin{array}{cc} 2 & -1 \\\\ -1 & 1 \\end{array}\\right) \\cdot \\left(\\begin{array}{c} 1 \\\\ 2 \\end{array}\\right) = \\left(\\begin{array}{c} 0 \\\\ 1 \\end{array}\\right)$ \n",
    "\n",
    "***\n",
    "\n",
    "**Резюмируем ↓**\n",
    "\n",
    "У нас есть квадратная система с $m$ неизвестных. Если ранг матрицы коэффициентов $A$ **равен** рангу расширенной матрицы $(A|b)$ и **равен** количеству переменных $(rk(A)=rk(\\overrightarrow{b}))=m$, то в системе будет ровно столько независимых уравнений, сколько и неизвестных $m$, а значит будет **единственное** решение.\n",
    "\n",
    "Вектор свободных коэффициентов $b$ при этом линейно независим со столбцами матрицы $A$, его разложение по столбцам $A$ **единственно**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2. , -1.4],\n",
       "       [-1. ,  0.8]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[4,7],[5,10]])\n",
    "np.linalg.inv(A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СЛУЧАЙ «В АКТИВНОМ ПОИСКЕ»\n",
    "\n",
    "?А что, если система **не удовлетворяет теореме Кронекера — Капелли**? То есть ранг матрицы системы равен расширенному рангу матрицы, но не равен количеству неизвестных. Неужели тогда система нерешаема?\n",
    "\n",
    "На этот вопрос отвечает первое следствие из теоремы ↓\n",
    "\n",
    "**Следствие №1** из теоремы Кронекера — Капелли:\n",
    "\n",
    "Если ранг матрицы системы $A$ равен рангу расширенной матрицы системы $(A|b)$, **но меньше**, чем количество неизвестных $m$, то система имеет бесконечное множество решений:\n",
    "\n",
    "$rk(A) = rk(A | \\vec{b}) < m  \\leftrightarrow  \\infty \\ решений$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим систему уравнений:\n",
    "\n",
    "$w_1+w_2+w_3=10$\n",
    "\n",
    "Да, уравнение одно, но формально оно является неоднородной СЛАУ.\n",
    "\n",
    "Итак, мы имеем одно уравнение на три неизвестных, значит две координаты из трёх вектора $w$ мы можем задать как угодно. Например, зададим вторую и третью как $\\alpha$ и $\\beta$. Тогда первая будет равна $10-\\alpha-\\beta$.\n",
    "\n",
    "$w=\\left( \\begin{array}{c} {10-\\alpha-\\beta} \\\\ \\alpha \\\\ \\beta \\end{array} \\right)$ где $\\alpha, \\beta \\in \\mathbb{R}$\n",
    "\n",
    "Вместо переменных $\\alpha$ и $\\beta$ мы можем подставлять любые числа и всегда будем получать равенство. \n",
    "\n",
    "Составим расширенную матрицу:\n",
    "\n",
    "$(A|b)=(\\begin{array}{} 1 & 1 & 1|10 \\end{array})$\n",
    "\n",
    "Её ранг, как и ранг $A$, равен 1, что меньше числа неизвестных $m=3$:\n",
    "\n",
    "$rk(A) = rk(A | \\vec{b}) = 1 < 3$\n",
    "\n",
    "Такая ситуация, по следствию из теоремы Кронекера — Капелли, говорит о существовании и не единственности решения, то есть решений **бесконечно много**.\n",
    "\n",
    "***\n",
    "\n",
    "**Резюмируем ↓\n",
    "**\n",
    "Если ранги матриц $A$ и $(A|b)$ всё ещё совпадают, но уже меньше количества неизвестных $(rk(A) = rk(A | \\vec{b}) < m)$, значит, уравнений не хватает для того, чтобы определить систему полностью, и решений будет бесконечно много.\n",
    "\n",
    "На языке линейной алгебры это значит, что вектор $\\overrightarrow{b}$ линейно зависим со столбцами матрицы $A$, но также и сами столбцы зависимы между собой, поэтому равнозначного разложения не получится, т. е. таких разложений может быть сколько угодно."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СЛУЧАЙ «ВСЁ СЛОЖНО»\n",
    "\n",
    "А теперь посмотрим на самый интересный для нас случай. Его формально регламентирует второе следствие из теоремы Кронекера — Капелли.\n",
    "\n",
    "**Следствие №2 из теоремы Кронекера — Капелли**:\n",
    "\n",
    "Если ранг матрицы системы $A$ меньше, чем ранг расширенной матрицы системы $(A|b)$, то система несовместна, то есть не имеет точных решений:\n",
    "\n",
    "$rk(A)  < rk(A | \\vec{b})  \\leftrightarrow  \\nexists \\ решений$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим систему уравнений:\n",
    "\n",
    "$\\left\\{\\begin{array}{c} w_1+w_2=1 \\\\ w_1+2 w_2=2 \\\\ w_1+w_2=12 \\end{array}\\right.$\n",
    "\n",
    "Посмотрим на первое и третье уравнение — очевидно, что такая система не имеет решений, так как данные уравнения противоречат друг другу.\n",
    "\n",
    "Но давайте обоснуем это математически. Для этого запишем расширенную матрицу системы:\n",
    "\n",
    "$(A|b)=\\left(\\begin{array}{cc|c} 1 & 1 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 1 & 12 \\end{array}\\right)$\n",
    "\n",
    "Посчитаем ранги матриц $A$ и $(A|b)$:\n",
    "\n",
    "$rk(A)=rk\\left(\\begin{array}{cc} 1 & 1  \\\\ 1 & 2 \\\\ 1 & 1 \\end{array}\\right) \\Rightarrow I-III \\Rightarrow rk\\left(\\begin{array}{cc} 1 & 1  \\\\ 1 & 2 \\end{array}\\right) \\Rightarrow II-I \\Rightarrow rk\\left(\\begin{array}{cc} 1 & 1  \\\\ 0 & 1 \\end{array}\\right)=2$\n",
    "\n",
    "$rk(A|b)=rk\\left(\\begin{array}{ccc} 1 & 1 & 1 \\\\ 1 & 2 & 2 \\\\ 1 & 1 & 12 \\end{array}\\right) \\Rightarrow III-I, II-I \\Rightarrow rk\\left(\\begin{array}{cc} 1 & 1 & 1 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 12\\end{array}\\right)=3$\n",
    "\n",
    "Итак, $rk(A)=2$, в то время как $rk(A|b)=3$. Это и есть критерий **переопределённости системы уравнений**: ранг матрицы системы меньше ранга расширенной матрицы системы.\n",
    "\n",
    "Получается, что идеальное решение найти нельзя, но чуть позже мы увидим, что такие системы возникают в задачах регрессии практически всегда, а значит нам всё-таки хотелось бы каким-то образом её решать. Можно попробовать найти приблизительное решение — вопрос лишь в том, какое из всех этих решений лучшее."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем наилучшее приближение для $w_1$, $w_2$, если:\n",
    "\n",
    "$\\left\\{\\begin{array}{c} w_1+w_2=1 \\\\ w_1+2 w_2=2 \\\\ w_1+w_2=12 \\end{array}\\right. \\Rightarrow \\left(\\begin{array}{cc} 1 & 1  \\\\ 1 & 2 \\\\ 1 & 1 \\end{array}\\right)\\cdot \\left(\\begin{array}{c} w  \\\\ w \\end{array}\\right)=\\left(\\begin{array}{c} 1 \\\\ 2 \\\\ 12 \\end{array}\\right)$\n",
    "\n",
    "Обозначим приближённое решение как $\\hat{w}$. Приближением для вектора $b$ будет $\\hat{b}=A \\hat{w}$. Также введём некоторый вектор ошибок $e=b-\\hat{b}=b-A \\hat{w}$.\n",
    "\n",
    ">**Примечание**. Здесь мы снова опустили стрелки у векторов $b$, $\\hat{b}$ и $\\hat{w}$ для наглядности.\n",
    "\n",
    "Например, если мы возьмём в качестве вектора $\\hat{w}$ вектор $\\hat{w_1}=(1,1)^T$, то получим:\n",
    "\n",
    "$\\hat{b}=A\\hat{w_1}=\\left(\\begin{array}{cc} 1 & 1 \\\\ 1 & 2 \\\\ 1 & 1\\end{array}\\right)\\cdot\\left(\\begin{array}{c} 1 \\\\ 1  \\end{array}\\right)=\\left(\\begin{array}{c} 2 \\\\ 3 \\\\ 2 \\end{array}\\right)$\n",
    "\n",
    "$e_1=b-A\\hat{w_1}=\\left(\\begin{array}{c} 1 \\\\ 2 \\\\ 12\\end{array}\\right) - \\left(\\begin{array}{c} 2 \\\\ 3 \\\\ 2\\end{array}\\right)=\\left(\\begin{array}{c} -1 \\\\ -1 \\\\ 10 \\end{array}\\right)$\n",
    "\n",
    "Теперь возьмём в качестве вектора $\\hat{w_2}=(4, -1)^T$, получим:\n",
    "\n",
    "$\\hat{b}=A\\hat{w_2}=\\left(\\begin{array}{cc} 1 & 1 \\\\ 1 & 2 \\\\ 1 & 1\\end{array}\\right)\\cdot\\left(\\begin{array}{c} 4 \\\\ -1  \\end{array}\\right)=\\left(\\begin{array}{c} 3 \\\\ 2 \\\\ 3 \\end{array}\\right)$\n",
    "\n",
    "$e_2=b-A\\hat{w_2}=\\left(\\begin{array}{c} 1 \\\\ 2 \\\\ 12\\end{array}\\right) - \\left(\\begin{array}{c} 3 \\\\ 2 \\\\ 3\\end{array}\\right)=\\left(\\begin{array}{c} -2 \\\\ -1 \\\\ 9 \\end{array}\\right)$\n",
    "\n",
    ">Конечно, нам хотелось бы, чтобы ошибка была поменьше. Но какая из них поменьше? Векторы сами по себе сравнить нельзя, **но зато можно сравнить их длины**.\n",
    "\n",
    "$\\left\\|e_1 \\right\\| = \\sqrt{(-1)^2 + (-1)^2 + (10)^2} = \\sqrt{102}$\n",
    "\n",
    "$\\left\\|e_2 \\right\\| = \\sqrt{(-2)^2 + 0^2 + 9^2} = \\sqrt{85}$\n",
    "\n",
    ">Видно, что вторая ошибка всё-таки меньше, соответственно, приближение лучше. Но в таком случае из всех приближений нам нужно выбрать то, у которого длина вектора ошибок минимальна, если, конечно, это возможно.\n",
    ">\n",
    ">$||e||\\rightarrow min$\n",
    ">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    ">**Примечание**. Проблема поиска оптимальных приближённых решений неоднородных переопределённых СЛАУ стояла у математиков вплоть до XIX века. До этого времени математики использовали частные решения, зависящие от вида уравнений и размерности. Впервые данную задачу для общего случая решил Гаусс, опубликовав метод решения этой задачи, который впоследствии будет назван методом наименьших квадратов (МНК). В дальнейшем Лаплас прибавил к данному методу теорию вероятности и доказал оптимальность МНК-оценок с точки зрения статистики.\n",
    "\n",
    "Сейчас мы почувствуем себя настоящими математиками и попробуем решить эту задачу самостоятельно с помощью простой геометрии и знакомых нам операций над матрицами.\n",
    "\n",
    "Вспомним, что на языке линейной алгебры неразрешимость системы\n",
    "\n",
    "$\\left(\\begin{array}{cc} 1 & 1  \\\\ 1 & 2 \\\\ 1 & 1 \\end{array}\\right)\\cdot \\left(\\begin{array}{c} w  \\\\ w \\end{array}\\right)=\\left(\\begin{array}{c} 1 \\\\ 2 \\\\ 12 \\end{array}\\right)$\n",
    "\n",
    "означает, что попытка выразить вектор $(1,2,12)^T$ через $(1,1,1)^T$ и $(1,2,1)^T$ не будет успешной, так как они **линейно независимы**.\n",
    "\n",
    "Геометрически это означает, что вектор свободных коэффициентов $\\textcolor{brown}{b}$ (коричневый) не лежит в одной плоскости со столбцами матрицы $\\textcolor{blue}{A}$ (синие векторы).\n",
    "\n",
    "<img src=m2_img1.png>\n",
    "\n",
    "Идея состояла в том, что наилучшим приближением для коричневого вектора будет ортогональная проекция на синюю плоскость — $\\textcolor{cyan}{голубой}$ вектор. Так происходит потому, что наименьший по длине вектор ошибок — $\\textcolor{red}{красный}$ — должен быть перпендикулярен к синей плоскости:\n",
    "\n",
    "$e=b-\\hat{b}$\n",
    "\n",
    "В прошлом модуле мы производили расчёты интуитивно, а теперь настала пора вывести формулу.\n",
    "\n",
    "Давайте умножим наши уравнения слева на $A^T$:\n",
    "\n",
    "$A^T\\cdot\\textcolor{cyan}{A\\hat{w}}=A^T\\cdot\\textcolor{brown}{b}$\n",
    "\n",
    "Идея заключается в следующем: справа мы найдём скалярное произведение столбцов матрицы $A$ на вектор $b$, а слева — произведение столбцов $A$ на приближённый вектор $\\hat{b}$ (по сути, на голубую проекцию).\n",
    "\n",
    "Упростим уравнение, перемножив всё, что содержит только числа. В левой части умножим $A^T$ на $A$, в правой — умножим $A^T$ на $b$. Тогда слева получим матрицу 2×2 — это не что иное, как матрица Грама столбцов $A$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Столбцы $A$ линейно независимы, а это значит, что, по свойству матрицы Грама, $A^T\\cdot A$  — невырожденная квадратная матрица (её определитель не равен нулю, и для неё существует обратная матрица). Получившаяся система — один в один случай «идеальная пара» (ранг матрицы, как и ранг расширенной матрицы, равен 2, в чём несложно убедиться), а это значит, что теперь мы можем её решить.\n",
    "\n",
    "$\\left(\\begin{array}{} 3 & 4 \\\\ 4 & 6 \\end{array}\\right)\\cdot\\left(\\begin{array}{} \\hat{w} \\\\ \\hat{w} \\end{array}\\right) = \\left(\\begin{array}{} 15 \\\\ 17 \\end{array}\\right)$\n",
    "\n",
    "$\\left(\\begin{array}{} 3 & 4 \\\\ 4 & 6 \\end{array}\\right)$ - матрица Грамма столбцов $A$\n",
    "\n",
    "$A^T\\cdot A=Gram(\\left(\\begin{array}{} 1 \\\\ 1 \\\\ 1 \\end{array}\\right),\\left(\\begin{array}{} 1 \\\\ 2 \\\\ 1 \\end{array}\\right))$\n",
    "\n",
    "Но ведь мы не могли решить изначальную задачу, так как она была переопределена, а эту — можем. **Как так получилось**?\n",
    "\n",
    "Мы потребовали, чтобы у приближения $\\hat{b}$ были с векторами $(1,1,1)^T$ и $(1,2,1)^T$ такие же скалярные произведения, как у $b$. Это и означает что $\\hat{b}$ — ортогональная проекция на нашу синюю плоскость, в которой лежат столбцы матрицы $A$, и в этой плоскости мы можем найти коэффициенты.\n",
    "\n",
    "Мы с вами отлично умеем решать системы типа «Идеальная пара». Для этого нам нужно найти обратную матрицу $(A^T\\cdot A)^{-1}$ и умножить на неё слева всё уравнение. Так мы и получим наше приближение:\n",
    "\n",
    "$(A^TA)\\cdot\\hat{w}=A^Tb$\n",
    "\n",
    "Находим определитель матрицы $(A^TA)$: \n",
    "\n",
    "$\\mathbb{det}(A^TA) = 3\\cdot6-4\\cdot4=2$\n",
    "\n",
    "Находим обратную матрицу $(A^TA)^{-1}$:\n",
    "\n",
    "$(A^TA)^{-1}=\\left(\\begin{array}{cc} 3 & 4 \\\\ 4 & 6\\end{array}\\right)^{-1}=\\frac{1}{2}\\left(\\begin{array}{cc} 6 & -4 \\\\ -4 & 3\\end{array}\\right)=\\left(\\begin{array}{cc} 3 & -2 \\\\ -2 & 1.5\\end{array}\\right)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Умножаем всё уравнение на обратную матрицу слева:\n",
    "\n",
    "$(A^TA)^{-1}\\cdot(A^TA)\\cdot\\hat{w}=(A^TA)^{-1}\\cdot A^T\\cdot b$\n",
    "\n",
    "$\\hat{w}=(A^TA)^{-1}\\cdot A^T\\cdot b$\n",
    "\n",
    "И, наконец, вот он — долгожданный приближённый вектор $\\hat{w}$:\n",
    "\n",
    "$\\hat{w}=\\left(\\begin{array}{cc} 3 & -2 \\\\ -2 & 1.5\\end{array}\\right)\\cdot\\left(\\begin{array}{} 15 \\\\ 17\\end{array}\\right)=\\left(\\begin{array}{} 11 \\\\ -4.5\\end{array}\\right)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "⭐ **Пришло время открытий!**\n",
    "\n",
    "Только что мы геометрическим образом вывели формулу оценки решения методом наименьших квадратов (`МНК` или `OLS`, Ordinary Least Squares).\n",
    "\n",
    ">**Примечание**. Стоит отметить, что полученная матричная формула не зависит от размерностей и конкретных значений, а значит применима не только в нашем локальном случае, но и в общем.\n",
    "\n",
    "Нам осталось выполнить проверку полученных результатов, чтобы убедиться в верности решения.\n",
    "\n",
    "Вычислим голубой вектор $\\hat{b}$. Для этого возьмём линейную комбинацию столбцов матрицы $А$ с найденными нами коэффициентами $\\hat{w_1}$ и $\\hat{w_2}$\n",
    "\n",
    "$\\hat{b}=A\\hat{w}=\\hat{w_1}\\cdot\\left(\\begin{array}{} 1\\\\1\\\\1\\end{array}\\right)+\\hat{w_2}\\cdot\\left(\\begin{array}{} 1\\\\2\\\\1\\end{array}\\right)=11\\cdot\\left(\\begin{array}{} 1\\\\1\\\\1\\end{array}\\right)-4.5\\cdot\\left(\\begin{array}{} 1\\\\2\\\\1\\end{array}\\right)=\\left(\\begin{array}{} 6.5\\\\2\\\\6.5\\end{array}\\right)$\n",
    "\n",
    "Вычислим вектор ошибок $e$:\n",
    "\n",
    "$e=b-\\hat{b}=b-A\\hat{w}=\\left(\\begin{array}{} 1\\\\2\\\\12\\end{array}\\right)-\\left(\\begin{array}{} 6.5\\\\2\\\\6.5\\end{array}\\right)=\\left(\\begin{array}{} -5.5\\\\0\\\\5.5\\end{array}\\right)$\n",
    "\n",
    "Убедимся, что данный вектор действительно ортогонален столбцам матрицы $А$. Для этого найдём их скалярные произведения:\n",
    "\n",
    "$(e,A_1)=e^T\\cdot A_1=(-5.5, 0, 5.5) \\cdot \\left(\\begin{array}{} 1\\\\1\\\\1\\end{array}\\right) = 0$\n",
    "\n",
    "$(e,A_2)=e^T\\cdot A_2=(-5.5, 0, 5.5) \\cdot \\left(\\begin{array}{} 1\\\\2\\\\1\\end{array}\\right) = 0$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скалярные произведения равны 0, а это означает, что вектор ошибок $\\textcolor{red}e$ действительно ортогонален всей синей плоскости, а голубой вектор $\\textcolor{cyan}{\\hat{b}}$ приближённого значения является ортогональной проекцией коричневого вектора $\\textcolor{brown}b$.\n",
    "\n",
    ">**Примечание**. Прежде чем перейти к выводам, стоит отметить, что обычно `OLS`-оценку выводят немного иначе, а именно минимизируя в явном виде длину вектора ошибок по коэффициентам $\\hat{w}$, вернее, даже квадрат длины для удобства вычисления производных.\n",
    ">\n",
    ">$||\\overrightarrow{e}||\\rightarrow min$\n",
    ">\n",
    ">$||\\overrightarrow{e}||^2\\rightarrow min$\n",
    ">\n",
    ">$||\\overrightarrow{b}-A\\overrightarrow{w}||^2\\rightarrow min$\n",
    ">\n",
    ">Формула получится точно такой же, какая есть у нас, просто способ вычислений будет не геометрический, а аналитический. Мы вернёмся к этому способу, когда будем обсуждать оптимизацию функции многих переменных в разделе по математическому анализу.\n",
    "\n",
    "Наконец, мы может подвести итоги для случая «Всё сложно»."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Резюмируем ↓**\n",
    "\n",
    "Если ранг матрицы $A$ меньше ранга расширенной системы $(A|b)$, то независимых уравнений больше, чем переменных $(rkA<(A|b)<m)$, а значит некоторые из них будут противоречить друг другу, то есть решений у системы нет.\n",
    "\n",
    "Говоря на языке линейной алгебры, вектор $b$ линейно независим со столбцами матрицы $A$, а значит его нельзя выразить в качестве их линейной комбинации.\n",
    "\n",
    "Однако можно получить приближённые решения по методу наименьших квадратов (`OLS` - оценка - $\\hat{b}=(A^TA)^{-1}\\cdot A^Tb$), идеей которого является ортогональная проекция вектора $b$ на столбцы матрицы $A$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Линейная регрессия МНК <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Стандартизация векторов и матрица корреляции <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Практика. Лин.регрессия МНК <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Полиноминальная регрессия <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Регуляция <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Практика. Полиноминальная регрессия и регуляция <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Итоги <a class=\"anchor\" id=2></a>\n",
    "\n",
    "[к содержанию](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3380a37b4678e1f5e651331348d62bc6038aef0d5f414da260f404a34792558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
